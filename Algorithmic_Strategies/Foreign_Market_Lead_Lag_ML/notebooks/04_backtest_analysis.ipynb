{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreign Market Lead-Lag ML Strategy\n",
    "## Notebook 4: Backtest Analysis\n",
    "\n",
    "This notebook performs comprehensive backtesting:\n",
    "- Generate daily predictions for all S&P 500 stocks\n",
    "- Construct long/short portfolio (top 5% long, bottom 5% short)\n",
    "- Simulate portfolio performance with transaction costs\n",
    "- Calculate risk-adjusted performance metrics\n",
    "- Compare to benchmark (S&P 500)\n",
    "- Analyze failure modes and risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from feature_engineering import FeatureEngineering\n",
    "from ml_models import MultiStockPredictor\n",
    "from portfolio_constructor import PortfolioSimulator\n",
    "from backtester import Backtester\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load data\n",
    "sp500_returns = pd.read_csv('../data/sp500_daily_returns.csv', index_col=0, parse_dates=True)\n",
    "foreign_returns = pd.read_csv('../data/foreign_weekly_returns.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "print(f\"Data loaded: {sp500_returns.shape}\")\n",
    "print(f\"Date range: {sp500_returns.index[0]} to {sp500_returns.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Models for All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for all stocks\n",
    "print(\"Preparing features for all stocks...\")\n",
    "feature_eng = FeatureEngineering(config)\n",
    "stock_data = feature_eng.prepare_all_stocks(foreign_returns, sp500_returns)\n",
    "\n",
    "print(f\"Prepared data for {len(stock_data)} stocks\")\n",
    "\n",
    "# Train models\n",
    "print(\"\\nTraining models (this may take several minutes)...\")\n",
    "predictor = MultiStockPredictor(config)\n",
    "validation_results = predictor.train_all_stocks(stock_data, validate=False)\n",
    "\n",
    "print(f\"Trained {len(predictor.stock_models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Daily Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix for all dates\n",
    "print(\"Creating feature matrix...\")\n",
    "lagged_features = feature_eng.create_lagged_features(foreign_returns)\n",
    "lagged_features = feature_eng.winsorize_features(lagged_features)\n",
    "lagged_features = feature_eng.standardize_features(lagged_features)\n",
    "\n",
    "# Align with daily frequency\n",
    "features_daily = lagged_features.reindex(sp500_returns.index, method='ffill')\n",
    "\n",
    "# Generate predictions\n",
    "print(\"\\nGenerating daily predictions...\")\n",
    "predictions_list = []\n",
    "\n",
    "for i, date in enumerate(features_daily.index):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"  Progress: {i}/{len(features_daily)} days\")\n",
    "    \n",
    "    if date not in features_daily.dropna().index:\n",
    "        continue\n",
    "    \n",
    "    features_row = features_daily.loc[date:date]\n",
    "    \n",
    "    try:\n",
    "        predictions = predictor.predict_all_stocks(features_row)\n",
    "        predictions.name = date\n",
    "        predictions_list.append(predictions)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions_list)\n",
    "print(f\"\\nGenerated predictions for {len(predictions_df)} days\")\n",
    "print(f\"Average stocks predicted per day: {predictions_df.count(axis=1).mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construct and Simulate Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run portfolio simulation\n",
    "print(\"Running portfolio simulation...\")\n",
    "simulator = PortfolioSimulator(config)\n",
    "results_df = simulator.simulate(predictions_df, sp500_returns)\n",
    "\n",
    "print(f\"\\nSimulation complete: {len(results_df)} trading days\")\n",
    "print(f\"\\nPortfolio Summary:\")\n",
    "print(f\"  Initial Value: ${config['backtesting']['initial_capital']:,.0f}\")\n",
    "print(f\"  Final Value: ${results_df['portfolio_value'].iloc[-1]:,.0f}\")\n",
    "print(f\"  Total Return: {(results_df['portfolio_value'].iloc[-1] / config['backtesting']['initial_capital'] - 1) * 100:.2f}%\")\n",
    "print(f\"  Avg Daily Turnover: {results_df['turnover'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download benchmark data\n",
    "print(\"Downloading benchmark data...\")\n",
    "benchmark = yf.download('SPY', \n",
    "                       start=config['data']['start_date'],\n",
    "                       end=config['data']['end_date'],\n",
    "                       progress=False)['Close']\n",
    "benchmark_returns = benchmark.pct_change()\n",
    "\n",
    "# Run backtest\n",
    "backtester = Backtester(config)\n",
    "metrics = backtester.calculate_metrics(results_df, benchmark_returns)\n",
    "\n",
    "# Print metrics\n",
    "backtester.print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive performance plots\n",
    "backtester.plot_performance(results_df, benchmark_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transaction Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze impact of transaction costs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gross vs Net returns\n",
    "cumulative_gross = (1 + results_df['gross_return']).cumprod()\n",
    "cumulative_net = (1 + results_df['net_return']).cumprod()\n",
    "\n",
    "axes[0].plot(cumulative_gross.index, cumulative_gross.values, \n",
    "            label='Gross Returns', linewidth=2)\n",
    "axes[0].plot(cumulative_net.index, cumulative_net.values, \n",
    "            label='Net Returns (After Costs)', linewidth=2)\n",
    "axes[0].set_title('Impact of Transaction Costs', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Cumulative Return')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cost breakdown\n",
    "total_turnover = results_df['turnover'].sum()\n",
    "commission_cost = total_turnover * config['costs']['commission']\n",
    "slippage_cost = total_turnover * config['costs']['slippage']\n",
    "total_cost = commission_cost + slippage_cost\n",
    "\n",
    "cost_breakdown = pd.Series({\n",
    "    'Commission': commission_cost,\n",
    "    'Slippage': slippage_cost\n",
    "})\n",
    "\n",
    "cost_breakdown.plot(kind='bar', ax=axes[1], color=['steelblue', 'coral'], \n",
    "                   edgecolor='black')\n",
    "axes[1].set_title('Transaction Cost Breakdown', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Cost Type')\n",
    "axes[1].set_ylabel('Total Cost (Return Impact)')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTransaction Cost Analysis:\")\n",
    "print(f\"  Total Turnover: {total_turnover:.2f}\")\n",
    "print(f\"  Commission Cost: {commission_cost:.4f} ({commission_cost * 100:.2f}%)\")\n",
    "print(f\"  Slippage Cost: {slippage_cost:.4f} ({slippage_cost * 100:.2f}%)\")\n",
    "print(f\"  Total Cost: {total_cost:.4f} ({total_cost * 100:.2f}%)\")\n",
    "print(f\"  Cost as % of Gross Return: {(total_cost / (cumulative_gross.iloc[-1] - 1)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Long vs Short Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze long vs short leg performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Number of positions over time\n",
    "axes[0].plot(results_df.index, results_df['num_long'], \n",
    "            label='Long Positions', linewidth=2, alpha=0.7)\n",
    "axes[0].plot(results_df.index, results_df['num_short'], \n",
    "            label='Short Positions', linewidth=2, alpha=0.7)\n",
    "axes[0].set_title('Number of Positions Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Number of Positions')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution of positions\n",
    "position_data = pd.DataFrame({\n",
    "    'Long': results_df['num_long'],\n",
    "    'Short': results_df['num_short']\n",
    "})\n",
    "\n",
    "position_data.boxplot(ax=axes[1], patch_artist=True)\n",
    "axes[1].set_title('Position Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Number of Positions')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPosition Statistics:\")\n",
    "print(f\"  Avg Long Positions: {results_df['num_long'].mean():.1f}\")\n",
    "print(f\"  Avg Short Positions: {results_df['num_short'].mean():.1f}\")\n",
    "print(f\"  Total Positions: {(results_df['num_long'] + results_df['num_short']).mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze risk metrics over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Rolling volatility\n",
    "rolling_vol = results_df['net_return'].rolling(252).std() * np.sqrt(252)\n",
    "axes[0, 0].plot(rolling_vol.index, rolling_vol.values, linewidth=2, color='steelblue')\n",
    "axes[0, 0].set_title('Rolling Volatility (1Y)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Annualized Volatility')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Rolling Sharpe\n",
    "rolling_returns = results_df['net_return'].rolling(252)\n",
    "rolling_sharpe = (rolling_returns.mean() * 252 - 0.02) / (rolling_returns.std() * np.sqrt(252))\n",
    "axes[0, 1].plot(rolling_sharpe.index, rolling_sharpe.values, linewidth=2, color='coral')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0, 1].set_title('Rolling Sharpe Ratio (1Y)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Worst drawdown periods\n",
    "cumulative = (1 + results_df['net_return']).cumprod()\n",
    "running_max = cumulative.expanding().max()\n",
    "drawdown = (cumulative - running_max) / running_max\n",
    "\n",
    "axes[1, 0].fill_between(drawdown.index, drawdown.values, 0, \n",
    "                       alpha=0.3, color='red')\n",
    "axes[1, 0].plot(drawdown.index, drawdown.values, color='red', linewidth=1)\n",
    "axes[1, 0].set_title('Drawdown', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Drawdown')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Return distribution by year\n",
    "yearly_returns = results_df['net_return'].resample('Y').apply(lambda x: (1 + x).prod() - 1)\n",
    "yearly_returns.plot(kind='bar', ax=axes[1, 1], color='steelblue', edgecolor='black')\n",
    "axes[1, 1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1, 1].set_title('Annual Returns', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Return')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnnual Returns:\")\n",
    "for year, ret in yearly_returns.items():\n",
    "    print(f\"  {year.year}: {ret * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "results_df.to_csv('../results/portfolio_results.csv')\n",
    "predictions_df.to_csv('../results/predictions.csv')\n",
    "pd.Series(metrics).to_csv('../results/performance_metrics.csv')\n",
    "\n",
    "print(\"Results saved to ../results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook performed comprehensive backtesting:\n",
    "- Generated daily predictions for all S&P 500 stocks\n",
    "- Constructed long/short portfolio (top 5% long, bottom 5% short)\n",
    "- Simulated performance with realistic transaction costs\n",
    "- Calculated risk-adjusted metrics\n",
    "- Compared to S&P 500 benchmark\n",
    "\n",
    "**Key Findings**:\n",
    "- Strategy shows predictive power but transaction costs are significant\n",
    "- Daily rebalancing creates high turnover\n",
    "- Performance varies across market regimes\n",
    "- Long and short legs contribute differently to returns\n",
    "\n",
    "**Risk Factors**:\n",
    "1. **Transaction Costs**: High turnover significantly erodes gross returns\n",
    "2. **Model Decay**: Predictive power may diminish over time\n",
    "3. **Liquidity Risk**: Short leg execution can be challenging\n",
    "4. **Market Regime Changes**: Performance varies across different market conditions\n",
    "\n",
    "**Recommendations**:\n",
    "- Consider reducing rebalancing frequency to lower costs\n",
    "- Implement position buffers to reduce turnover\n",
    "- Monitor RÂ²_OOS decay and retrain models regularly\n",
    "- Apply liquidity filters for short positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
