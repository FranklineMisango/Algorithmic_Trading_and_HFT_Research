{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2251474",
   "metadata": {},
   "source": [
    "# Data Exploration - Statistical Arbitrage RL\n",
    "\n",
    "This notebook explores the S&P 500 universe, sector distributions, and price characteristics for pairs trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from data_acquisition import DataAcquisition\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134acea",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Universe: {config['data']['universe']}\")\n",
    "print(f\"  Target sectors: {config['pair_selection']['sectors']}\")\n",
    "print(f\"  Training period: {config['data']['train_start']} to {config['data']['train_end']}\")\n",
    "print(f\"  Testing period: {config['data']['test_start']} to {config['data']['test_end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd042488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch S&P 500 data\n",
    "data_acq = DataAcquisition('../config.yaml')\n",
    "dataset = data_acq.fetch_full_dataset()\n",
    "\n",
    "print(\"\\n=== Dataset Summary ===\")\n",
    "print(f\"Total tickers: {dataset['metadata']['total_tickers']}\")\n",
    "print(f\"Date range: {dataset['metadata']['date_range']}\")\n",
    "print(f\"Trading days: {dataset['metadata']['trading_days']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d05978",
   "metadata": {},
   "source": [
    "## 2. Sector Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5c1298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector distribution\n",
    "constituents = dataset['constituents']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "sector_counts = constituents['sector'].value_counts()\n",
    "sector_counts.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Stocks per Sector', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Sector')\n",
    "axes[0].set_ylabel('Number of Stocks')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(sector_counts, labels=sector_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('Sector Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSector breakdown:\")\n",
    "for sector, count in sector_counts.items():\n",
    "    print(f\"  {sector}: {count} stocks ({count/len(constituents)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a77a9",
   "metadata": {},
   "source": [
    "## 3. Price Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6359ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "prices = dataset['prices']\n",
    "\n",
    "missing_data = prices.isna().sum()\n",
    "missing_pct = (missing_data / len(prices)) * 100\n",
    "\n",
    "# Tickers with most missing data\n",
    "top_missing = missing_pct.nlargest(10)\n",
    "\n",
    "if len(top_missing) > 0 and top_missing.max() > 0:\n",
    "    print(\"Top 10 tickers with missing data:\")\n",
    "    for ticker, pct in top_missing.items():\n",
    "        print(f\"  {ticker}: {pct:.2f}%\")\n",
    "else:\n",
    "    print(\"No significant missing data found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c1ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data availability over time\n",
    "data_availability = (~prices.isna()).sum(axis=1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(prices.index, data_availability, linewidth=1.5, color='darkgreen')\n",
    "plt.title('Data Availability Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Stocks with Data')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage stocks with data per day: {data_availability.mean():.1f}\")\n",
    "print(f\"Minimum: {data_availability.min()}\")\n",
    "print(f\"Maximum: {data_availability.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84200479",
   "metadata": {},
   "source": [
    "## 4. Price Statistics by Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Merge with sector info\n",
    "sector_returns = []\n",
    "\n",
    "for _, row in constituents.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    sector = row['sector']\n",
    "    \n",
    "    if ticker in returns.columns:\n",
    "        ticker_returns = returns[ticker]\n",
    "        sector_returns.append({\n",
    "            'ticker': ticker,\n",
    "            'sector': sector,\n",
    "            'mean_return': ticker_returns.mean() * 252,  # Annualized\n",
    "            'volatility': ticker_returns.std() * np.sqrt(252),  # Annualized\n",
    "            'sharpe': (ticker_returns.mean() / ticker_returns.std()) * np.sqrt(252)\n",
    "        })\n",
    "\n",
    "sector_stats = pd.DataFrame(sector_returns)\n",
    "\n",
    "# Aggregate by sector\n",
    "sector_agg = sector_stats.groupby('sector').agg({\n",
    "    'mean_return': 'mean',\n",
    "    'volatility': 'mean',\n",
    "    'sharpe': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\n=== Sector Statistics (Annualized) ===\")\n",
    "print(sector_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sector risk-return profile\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for sector in sector_stats['sector'].unique():\n",
    "    sector_data = sector_stats[sector_stats['sector'] == sector]\n",
    "    plt.scatter(sector_data['volatility'], sector_data['mean_return'], \n",
    "               label=sector, alpha=0.6, s=100)\n",
    "\n",
    "plt.xlabel('Annualized Volatility', fontsize=12)\n",
    "plt.ylabel('Annualized Return', fontsize=12)\n",
    "plt.title('Risk-Return Profile by Sector', fontsize=14, fontweight='bold')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebf4763",
   "metadata": {},
   "source": [
    "## 5. Sample Stock Pairs Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample pairs from target sectors\n",
    "sample_pairs = [\n",
    "    ('MSFT', 'GOOGL', 'Technology'),\n",
    "    ('CVS', 'JNJ', 'Healthcare'),\n",
    "    ('PG', 'KO', 'Consumer Goods')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(len(sample_pairs), 1, figsize=(14, 12))\n",
    "\n",
    "for idx, (ticker1, ticker2, sector) in enumerate(sample_pairs):\n",
    "    if ticker1 in prices.columns and ticker2 in prices.columns:\n",
    "        # Normalize to 100\n",
    "        norm_price1 = prices[ticker1] / prices[ticker1].iloc[0] * 100\n",
    "        norm_price2 = prices[ticker2] / prices[ticker2].iloc[0] * 100\n",
    "        \n",
    "        axes[idx].plot(norm_price1.index, norm_price1, label=ticker1, linewidth=2)\n",
    "        axes[idx].plot(norm_price2.index, norm_price2, label=ticker2, linewidth=2)\n",
    "        axes[idx].set_title(f'{sector}: {ticker1} vs {ticker2}', fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_ylabel('Normalized Price (Base=100)')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de4c40",
   "metadata": {},
   "source": [
    "## 6. Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume statistics\n",
    "volumes = dataset['volumes']\n",
    "\n",
    "avg_volume_by_ticker = volumes.mean().sort_values(ascending=False)\n",
    "\n",
    "# Top 10 most liquid stocks\n",
    "top_liquid = avg_volume_by_ticker.head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_liquid.plot(kind='barh', color='coral')\n",
    "plt.title('Top 10 Most Liquid Stocks (Avg Daily Volume)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Average Daily Volume')\n",
    "plt.ylabel('Ticker')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 most liquid stocks:\")\n",
    "for ticker, vol in top_liquid.items():\n",
    "    print(f\"  {ticker}: {vol:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea220263",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d18f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_prices, test_prices = data_acq.split_train_test(prices)\n",
    "\n",
    "print(f\"Training period: {train_prices.index[0]} to {train_prices.index[-1]}\")\n",
    "print(f\"  Trading days: {len(train_prices)}\")\n",
    "print(f\"  Stocks: {train_prices.shape[1]}\")\n",
    "\n",
    "print(f\"\\nTesting period: {test_prices.index[0]} to {test_prices.index[-1]}\")\n",
    "print(f\"  Trading days: {len(test_prices)}\")\n",
    "print(f\"  Stocks: {test_prices.shape[1]}\")\n",
    "\n",
    "# Visualize split\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.axvspan(train_prices.index[0], train_prices.index[-1], alpha=0.3, color='blue', label='Training')\n",
    "plt.axvspan(test_prices.index[0], test_prices.index[-1], alpha=0.3, color='orange', label='Testing')\n",
    "plt.title('Train/Test Split', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Period')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270dd010",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored the S&P 500 dataset for statistical arbitrage:\n",
    "\n",
    "- **Universe**: Focused on 4 target sectors (Technology, Healthcare, Consumer Goods, Financials)\n",
    "- **Data Quality**: Verified completeness and availability\n",
    "- **Sector Characteristics**: Analyzed risk-return profiles\n",
    "- **Sample Pairs**: Visualized co-movement patterns\n",
    "- **Liquidity**: Identified most liquid stocks for trading\n",
    "- **Data Split**: Prepared train (2022) and test (2023) periods\n",
    "\n",
    "**Next**: Proceed to pair selection using correlation analysis and EMRT calculation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
