{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c971e416",
   "metadata": {},
   "source": [
    "## Summary: Strategy vs Research Targets\n",
    "\n",
    "**Implementation Status:**\n",
    "✓ Complete implementation of market-labeled LLM sentiment strategy  \n",
    "✓ Cross-sectional market-neutral portfolio construction  \n",
    "✓ Realistic transaction costs and market impact modeling  \n",
    "✓ Comprehensive risk management framework  \n",
    "\n",
    "**Key Takeaways:**\n",
    "1. **Market-Labeled Approach**: Training BERT on abnormal returns (not human labels) directly aligns model with trading objective\n",
    "2. **Transaction Costs Critical**: 10-30bps can significantly impact performance\n",
    "3. **Signal Decay Monitoring**: Rolling Sharpe <0.5 triggers retrain/review\n",
    "4. **Survivorship Bias**: MANDATORY control using CRSP delisted returns\n",
    "\n",
    "**Research Citation:**\n",
    "\"Quant Radio: How AI Reads Market Moods to Predict Stock Success\"  \n",
    "Target: 35.56% return, 2.21 Sharpe (equal-weighted)\n",
    "\n",
    "**Production Requirements:**\n",
    "- Bloomberg/Reuters/RavenPack/Accern API access for text data\n",
    "- CRSP for survivorship-bias-free market data\n",
    "- GPU compute (A100/V100) for LLM inference\n",
    "- Factor regression data (Fama-French library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ae100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate with different cost assumptions\n",
    "cost_scenarios = {\n",
    "    'Optimistic (10bps)': 0.0010,\n",
    "    'Moderate (20bps)': 0.0020,\n",
    "    'Conservative (30bps)': 0.0030\n",
    "}\n",
    "\n",
    "cost_sensitivity = []\n",
    "for scenario, cost_bps in cost_scenarios.items():\n",
    "    # Recalculate returns with different costs\n",
    "    adjusted_returns = results_df['gross_return'] - (results_df['turnover'] * cost_bps)\n",
    "    adj_annual_return = (1 + adjusted_returns.sum()) ** (252 / len(adjusted_returns)) - 1\n",
    "    adj_sharpe = adjusted_returns.mean() / adjusted_returns.std() * np.sqrt(252)\n",
    "    cost_sensitivity.append({\n",
    "        'Scenario': scenario,\n",
    "        'Annual Return': f\"{adj_annual_return:.2%}\",\n",
    "        'Sharpe Ratio': f\"{adj_sharpe:.2f}\"\n",
    "    })\n",
    "\n",
    "cost_df = pd.DataFrame(cost_sensitivity)\n",
    "print(\"\\nTransaction Cost Sensitivity Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(cost_df.to_string(index=False))\n",
    "print(\"\\nNote: Higher costs significantly impact performance - execution critical!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d098081d",
   "metadata": {},
   "source": [
    "## 6. Transaction Cost Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3808b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling 3-month Sharpe ratio\n",
    "if len(results_df) > 63:\n",
    "    rolling_sharpe = results_df['net_return'].rolling(window=63).apply(\n",
    "        lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() > 0 else 0\n",
    "    )\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.plot(results_df['date'], rolling_sharpe, linewidth=2, color='purple')\n",
    "    ax.axhline(target_sharpe, color='green', linestyle='--', label=f'Target: {target_sharpe:.2f}')\n",
    "    ax.axhline(0.5, color='red', linestyle='--', label='Alert Threshold: 0.5')\n",
    "    ax.set_title('Rolling 3-Month Sharpe Ratio (Model Decay Detection)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Sharpe Ratio')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Model decay check\n",
    "    recent_sharpe = rolling_sharpe.iloc[-21:].mean()\n",
    "    print(f\"Recent 1-month avg Sharpe: {recent_sharpe:.2f}\")\n",
    "    print(f\"Alert if < 0.5: {'⚠️ MODEL DECAY ALERT!' if recent_sharpe < 0.5 else '✓ Normal'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97d7f0",
   "metadata": {},
   "source": [
    "## 5. Rolling Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f5a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder factor regression (requires Fama-French data)\n",
    "print(\"Factor Regression Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(\"Objective: Test for significant alpha independent of traditional factors\")\n",
    "print(\"\\nTarget Regression: Strategy ~ Mkt-RF + SMB + HML + RMW + CMA + UMD\")\n",
    "print(\"\\nData Required:\")\n",
    "print(\"- Fama-French 5 factors (Mkt-RF, SMB, HML, RMW, CMA)\")\n",
    "print(\"- Momentum factor (UMD)\")\n",
    "print(\"- Source: Kenneth French Data Library\")\n",
    "print(\"\\nExpected Results:\")\n",
    "print(\"- Significant positive alpha (p < 0.05)\")\n",
    "print(\"- Low factor loadings (|β| < 0.3 for market neutrality)\")\n",
    "print(\"\\nNote: Implement with actual Fama-French data for production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56889573",
   "metadata": {},
   "source": [
    "## 4. Factor Regression Analysis (Fama-French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03635f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key metrics\n",
    "returns = results_df['net_return'].values\n",
    "n_days = len(returns)\n",
    "n_years = n_days / 252\n",
    "\n",
    "# Annualized metrics\n",
    "total_return = (results_df['portfolio_value'].iloc[-1] / config['backtest']['initial_capital']) - 1\n",
    "annualized_return = (1 + total_return) ** (1 / n_years) - 1\n",
    "volatility = np.std(returns) * np.sqrt(252)\n",
    "sharpe = annualized_return / volatility\n",
    "sortino = annualized_return / (np.std(returns[returns < 0]) * np.sqrt(252))\n",
    "max_dd = results_df['drawdown'].max()\n",
    "calmar = annualized_return / max_dd if max_dd > 0 else 0\n",
    "win_rate = np.sum(returns > 0) / len(returns)\n",
    "avg_turnover = results_df['turnover'].mean()\n",
    "\n",
    "# Comparison table\n",
    "metrics_data = {\n",
    "    'Metric': ['Annualized Return', 'Sharpe Ratio', 'Sortino Ratio', 'Calmar Ratio', \n",
    "               'Max Drawdown', 'Win Rate', 'Ann. Turnover'],\n",
    "    'Strategy': [f\"{annualized_return:.2%}\", f\"{sharpe:.2f}\", f\"{sortino:.2f}\", f\"{calmar:.2f}\",\n",
    "                 f\"{max_dd:.2%}\", f\"{win_rate:.2%}\", f\"{avg_turnover * 252:.2%}\"],\n",
    "    'Target': [f\"{target_return:.2%}\", f\"{target_sharpe:.2f}\", 'N/A', 'N/A', \n",
    "               'N/A', 'N/A', 'N/A'],\n",
    "    'Status': [\n",
    "        '✓' if annualized_return >= target_return * 0.8 else '✗',\n",
    "        '✓' if sharpe >= target_sharpe * 0.8 else '✗',\n",
    "        'N/A', 'N/A', 'N/A', 'N/A', 'N/A'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE METRICS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"\\n* Target ±20% tolerance considered passing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc3ce2",
   "metadata": {},
   "source": [
    "## 3. Performance Metrics vs Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce47fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underwater plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.fill_between(results_df['date'], -results_df['drawdown'] * 100, 0, color='red', alpha=0.3)\n",
    "ax.plot(results_df['date'], -results_df['drawdown'] * 100, linewidth=2, color='darkred')\n",
    "ax.set_title('Strategy Drawdown (Underwater Plot)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Drawdown (%)')\n",
    "ax.axhline(-15, color='orange', linestyle='--', label='15% Stop-Loss Threshold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum Drawdown: {results_df['drawdown'].max() * 100:.2f}%\")\n",
    "print(f\"Stop-Loss Threshold: 15%\")\n",
    "print(f\"Breached: {'Yes ⚠️' if results_df['drawdown'].max() > 0.15 else 'No ✓'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec1e86",
   "metadata": {},
   "source": [
    "## 2. Drawdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be15df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative returns plot\n",
    "results_df['cumulative_return'] = (1 + results_df['net_return']).cumprod()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.plot(results_df['date'], results_df['cumulative_return'], linewidth=2.5, label='Strategy', color='darkblue')\n",
    "ax.set_title('Cumulative Returns: Sentiment-LLM Strategy', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Cumulative Return', fontsize=12)\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final portfolio value: ${results_df['portfolio_value'].iloc[-1]:,.2f}\")\n",
    "print(f\"Total return: {(results_df['portfolio_value'].iloc[-1] / config['backtest']['initial_capital'] - 1) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd8fe0",
   "metadata": {},
   "source": [
    "## 1. Cumulative Returns Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "# Load config\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load backtest results\n",
    "results_df = pd.read_csv('data/results/daily_returns.csv')\n",
    "results_df['date'] = pd.to_datetime(results_df['date'])\n",
    "print(f\"Backtest results loaded: {len(results_df)} days\")\n",
    "\n",
    "# Extract benchmarks\n",
    "target_return = config['evaluation']['benchmarks']['annualized_return']\n",
    "target_sharpe = config['evaluation']['benchmarks']['sharpe_ratio']\n",
    "print(f\"\\nTargets: {target_return:.2%} return, {target_sharpe:.2f} Sharpe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013b0f4",
   "metadata": {},
   "source": [
    "# Backtest Evaluation: Market-Labeled LLM Strategy\n",
    "\n",
    "This notebook evaluates the full backtest performance against research targets.\n",
    "\n",
    "**Research Targets (from Quant Radio paper):**\n",
    "- Annualized Return: **35.56%**\n",
    "- Sharpe Ratio: **2.21**\n",
    "- Strategy: Equal-weighted, cross-sectional market-neutral\n",
    "\n",
    "**Evaluation Framework:**\n",
    "1. Performance metrics vs benchmarks\n",
    "2. Factor regression (alpha significance)\n",
    "3. Drawdown analysis\n",
    "4. Capacity and cost sensitivity\n",
    "5. Failure modes validation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
