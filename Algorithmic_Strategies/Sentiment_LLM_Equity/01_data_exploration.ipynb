{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2416fe9",
   "metadata": {},
   "source": [
    "# Data Exploration: Sentiment-Based LLM Equity Strategy\n",
    "\n",
    "This notebook explores the text and market data used for the market-labeled sentiment strategy.\n",
    "\n",
    "**Objectives:**\n",
    "- Analyze universe composition and characteristics\n",
    "- Examine text data coverage and quality\n",
    "- Validate data integrity and timestamp alignment\n",
    "- Identify potential data issues before model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market data\n",
    "market_data_path = Path('data/market/prices.csv')\n",
    "text_data_path = Path('data/text/news_social.csv')\n",
    "\n",
    "if market_data_path.exists():\n",
    "    market_df = pd.read_csv(market_data_path)\n",
    "    market_df['date'] = pd.to_datetime(market_df['date'])\n",
    "    print(f\"Market data loaded: {len(market_df):,} rows\")\n",
    "    print(f\"Date range: {market_df['date'].min()} to {market_df['date'].max()}\")\n",
    "    print(f\"Unique stocks: {market_df['ticker'].nunique()}\")\n",
    "else:\n",
    "    print(\"Market data not found. Run data acquisition first.\")\n",
    "    market_df = pd.DataFrame()\n",
    "\n",
    "if text_data_path.exists():\n",
    "    text_df = pd.read_csv(text_data_path)\n",
    "    text_df['date'] = pd.to_datetime(text_df['date'])\n",
    "    print(f\"\\nText data loaded: {len(text_df):,} rows\")\n",
    "    print(f\"Date range: {text_df['date'].min()} to {text_df['date'].max()}\")\n",
    "    print(f\"Unique stocks: {text_df['ticker'].nunique()}\")\n",
    "else:\n",
    "    print(\"\\nText data not found. Run data acquisition first.\")\n",
    "    text_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8252ab",
   "metadata": {},
   "source": [
    "## 5. Summary and Next Steps\n",
    "\n",
    "**Key Findings:**\n",
    "1. Universe size and sector distribution validated\n",
    "2. Text data coverage and quality assessed\n",
    "3. Missing values identified and quantified\n",
    "4. Data ready for sentiment model training\n",
    "\n",
    "**Next Steps:**\n",
    "- Proceed to `02_sentiment_analysis.ipynb` for model predictions analysis\n",
    "- Address any data quality issues before training\n",
    "- Ensure survivorship bias control in production (use CRSP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc78c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticker coverage: how many stocks have text data each day\n",
    "if not market_df.empty and not text_df.empty:\n",
    "    market_coverage = market_df.groupby('date')['ticker'].nunique().reset_index()\n",
    "    market_coverage.columns = ['date', 'market_tickers']\n",
    "    \n",
    "    text_coverage = text_df.groupby('date')['ticker'].nunique().reset_index()\n",
    "    text_coverage.columns = ['date', 'text_tickers']\n",
    "    \n",
    "    coverage = market_coverage.merge(text_coverage, on='date', how='outer').fillna(0)\n",
    "    coverage['coverage_pct'] = (coverage['text_tickers'] / coverage['market_tickers'] * 100).round(1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(coverage['date'], coverage['coverage_pct'], linewidth=2, color='darkblue')\n",
    "    ax.set_title('Text Data Coverage (%)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('% of Stocks with Text Data')\n",
    "    ax.set_ylim([0, 105])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average text coverage: {coverage['coverage_pct'].mean():.1f}%\")\n",
    "    print(f\"Days with <50% coverage: {(coverage['coverage_pct'] < 50).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ec7428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"Missing Values in Market Data:\")\n",
    "print(\"=\"*50)\n",
    "if not market_df.empty:\n",
    "    missing = market_df.isnull().sum()\n",
    "    missing_pct = (missing / len(market_df) * 100).round(2)\n",
    "    missing_df = pd.DataFrame({'Count': missing, 'Percentage': missing_pct})\n",
    "    print(missing_df[missing_df['Count'] > 0])\n",
    "else:\n",
    "    print(\"No market data loaded\")\n",
    "\n",
    "print(\"\\n\\nMissing Values in Text Data:\")\n",
    "print(\"=\"*50)\n",
    "if not text_df.empty:\n",
    "    missing_text = text_df.isnull().sum()\n",
    "    missing_text_pct = (missing_text / len(text_df) * 100).round(2)\n",
    "    missing_text_df = pd.DataFrame({'Count': missing_text, 'Percentage': missing_text_pct})\n",
    "    print(missing_text_df[missing_text_df['Count'] > 0])\n",
    "else:\n",
    "    print(\"No text data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e353d19",
   "metadata": {},
   "source": [
    "## 4. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fecc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text examples\n",
    "if not text_df.empty and 'text' in text_df.columns:\n",
    "    print(\"Sample Text Data:\")\n",
    "    print(\"=\"*80)\n",
    "    for idx, row in text_df.head(5).iterrows():\n",
    "        print(f\"\\nTicker: {row['ticker']} | Date: {row['date']}\")\n",
    "        print(f\"Text: {row['text'][:200]}...\")\n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e06d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length distribution\n",
    "if not text_df.empty and 'text' in text_df.columns:\n",
    "    text_df['text_length'] = text_df['text'].str.len()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.hist(text_df['text_length'], bins=50, edgecolor='black', alpha=0.7, color='purple')\n",
    "    ax.set_title('Text Length Distribution', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Characters')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.axvline(512, color='red', linestyle='--', label='BERT Max Tokens (~512 chars)')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nText Length Stats:\")\n",
    "    print(f\"Mean: {text_df['text_length'].mean():.0f} characters\")\n",
    "    print(f\"Median: {text_df['text_length'].median():.0f} characters\")\n",
    "    print(f\"Max: {text_df['text_length'].max():.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text volume over time\n",
    "if not text_df.empty:\n",
    "    text_volume = text_df.groupby('date').size().reset_index()\n",
    "    text_volume.columns = ['date', 'n_articles']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(text_volume['date'], text_volume['n_articles'], linewidth=2, color='darkgreen')\n",
    "    ax.set_title('Text Data Volume Over Time', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of Articles/Mentions')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average daily articles: {text_volume['n_articles'].mean():.0f}\")\n",
    "    print(f\"Total articles: {len(text_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64ba34",
   "metadata": {},
   "source": [
    "## 3. Text Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274555f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price and market cap distributions\n",
    "if not market_df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Price distribution\n",
    "    axes[0, 0].hist(market_df['Close'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_title('Price Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Price ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].axvline(5, color='red', linestyle='--', label='$5 Filter')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Market cap distribution (log scale)\n",
    "    if 'market_cap' in market_df.columns:\n",
    "        market_cap_clean = market_df['market_cap'].dropna()\n",
    "        market_cap_clean = market_cap_clean[market_cap_clean > 0]\n",
    "        axes[0, 1].hist(np.log10(market_cap_clean), bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "        axes[0, 1].set_title('Market Cap Distribution (Log Scale)', fontsize=12, fontweight='bold')\n",
    "        axes[0, 1].set_xlabel('Log10(Market Cap)')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Price over time (median)\n",
    "    price_over_time = market_df.groupby('date')['Close'].median().reset_index()\n",
    "    axes[1, 0].plot(price_over_time['date'], price_over_time['Close'], linewidth=2, color='navy')\n",
    "    axes[1, 0].set_title('Median Price Over Time', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Date')\n",
    "    axes[1, 0].set_ylabel('Median Price ($)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Volume over time (median)\n",
    "    if 'Volume' in market_df.columns:\n",
    "        volume_over_time = market_df.groupby('date')['Volume'].median().reset_index()\n",
    "        axes[1, 1].plot(volume_over_time['date'], volume_over_time['Volume'], linewidth=2, color='orange')\n",
    "        axes[1, 1].set_title('Median Volume Over Time', fontsize=12, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Date')\n",
    "        axes[1, 1].set_ylabel('Median Volume')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPrice Stats:\")\n",
    "    print(f\"Mean: ${market_df['Close'].mean():.2f}\")\n",
    "    print(f\"Median: ${market_df['Close'].median():.2f}\")\n",
    "    print(f\"Stocks below $5: {(market_df['Close'] < 5).sum() / len(market_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf08a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sector distribution (GICS Level 1)\n",
    "if not market_df.empty and 'sector' in market_df.columns:\n",
    "    latest_date = market_df['date'].max()\n",
    "    latest_data = market_df[market_df['date'] == latest_date]\n",
    "    \n",
    "    sector_dist = latest_data['sector'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Pie chart\n",
    "    ax1.pie(sector_dist.values, labels=sector_dist.index, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.set_title('Sector Distribution (Latest Date)', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Bar chart\n",
    "    sector_dist.plot(kind='bar', ax=ax2, color='steelblue')\n",
    "    ax2.set_title('Number of Stocks by Sector', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Sector')\n",
    "    ax2.set_ylabel('Number of Stocks')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nSector Distribution:\")\n",
    "    print(sector_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universe composition over time\n",
    "if not market_df.empty:\n",
    "    universe_size = market_df.groupby('date')['ticker'].nunique().reset_index()\n",
    "    universe_size.columns = ['date', 'n_stocks']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(universe_size['date'], universe_size['n_stocks'], linewidth=2)\n",
    "    ax.set_title('Universe Size Over Time', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of Stocks')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average universe size: {universe_size['n_stocks'].mean():.0f} stocks\")\n",
    "    print(f\"Min: {universe_size['n_stocks'].min()}, Max: {universe_size['n_stocks'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c70bf",
   "metadata": {},
   "source": [
    "## 2. Market Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ecbdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Strategy:\", config['strategy']['name'])\n",
    "print(\"Target Annual Return:\", config['evaluation']['benchmarks']['annualized_return'])\n",
    "print(\"Target Sharpe Ratio:\", config['evaluation']['benchmarks']['sharpe_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f242f5",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
