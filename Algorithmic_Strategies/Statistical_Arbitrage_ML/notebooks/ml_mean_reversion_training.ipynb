{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Mean Reversion Strategy - Model Training\n",
    "## Russell 3000 Short-Term Mean Reversion with QPI and ML Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate 3-Day QPI (Quantitative Pressure Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qpi_3day(df):\n",
    "    \"\"\"Calculate 3-day QPI: proprietary oversold indicator\"\"\"\n",
    "    # Price momentum components\n",
    "    df['ret_1d'] = df['Close'].pct_change(1)\n",
    "    df['ret_3d'] = df['Close'].pct_change(3)\n",
    "    \n",
    "    # Volume pressure\n",
    "    df['vol_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "    \n",
    "    # Volatility-adjusted pressure\n",
    "    df['volatility'] = df['ret_1d'].rolling(20).std()\n",
    "    \n",
    "    # QPI formula: normalized pressure index (0-100 scale)\n",
    "    # Lower values = more oversold\n",
    "    raw_qpi = 50 + (df['ret_3d'] / (df['volatility'] + 1e-6)) * 10 - (df['vol_ratio'] - 1) * 5\n",
    "    df['qpi_3day'] = raw_qpi.clip(0, 100)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create ML features for mean reversion prediction\"\"\"\n",
    "    df = calculate_qpi_3day(df)\n",
    "    \n",
    "    # Price features\n",
    "    df['rsi_14'] = calculate_rsi(df['Close'], 14)\n",
    "    df['bb_position'] = (df['Close'] - df['Close'].rolling(20).mean()) / (df['Close'].rolling(20).std() + 1e-6)\n",
    "    \n",
    "    # Volume features\n",
    "    df['volume_surge'] = df['Volume'] / df['Volume'].rolling(5).mean()\n",
    "    \n",
    "    # Momentum features\n",
    "    for period in [5, 10, 20]:\n",
    "        df[f'mom_{period}'] = df['Close'].pct_change(period)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_rsi(series, period=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / (loss + 1e-6)\n",
    "    return 100 - (100 / (1 + rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Definition: 6-Day Forward Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(df, horizon=6):\n",
    "    \"\"\"Create binary target: 1 if positive return in next 6 days\"\"\"\n",
    "    df['forward_return'] = df['Close'].pct_change(horizon).shift(-horizon)\n",
    "    df['target_long'] = (df['forward_return'] > 0).astype(int)\n",
    "    df['target_short'] = (df['forward_return'] < 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Models (Long and Short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training on a few Russell 3000 stocks\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'JPM', 'BAC', 'WMT', 'XOM', 'CVX']\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "all_data = []\n",
    "for symbol in symbols:\n",
    "    try:\n",
    "        df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
    "        df = create_features(df)\n",
    "        df = create_target(df)\n",
    "        df['symbol'] = symbol\n",
    "        all_data.append(df)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "combined_df = pd.concat(all_data)\n",
    "print(f\"Total samples: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "feature_cols = ['qpi_3day', 'rsi_14', 'bb_position', 'volume_surge', 'mom_5', 'mom_10', 'mom_20', 'vol_ratio']\n",
    "train_df = combined_df.dropna(subset=feature_cols + ['target_long', 'target_short'])\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y_long = train_df['target_long']\n",
    "y_short = train_df['target_short']\n",
    "\n",
    "# Split: 80% train, 20% test\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_long_train, y_long_test = y_long[:split_idx], y_long[split_idx:]\n",
    "y_short_train, y_short_test = y_short[:split_idx], y_short[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Long Model\n",
    "model_long = GradientBoostingClassifier(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "model_long.fit(X_train, y_long_train)\n",
    "\n",
    "y_long_pred_proba = model_long.predict_proba(X_test)[:, 1]\n",
    "print(f\"Long Model - Accuracy: {accuracy_score(y_long_test, y_long_pred_proba > 0.6):.3f}\")\n",
    "print(f\"Long Model - AUC: {roc_auc_score(y_long_test, y_long_pred_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Short Model\n",
    "model_short = GradientBoostingClassifier(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "model_short.fit(X_train, y_short_train)\n",
    "\n",
    "y_short_pred_proba = model_short.predict_proba(X_test)[:, 1]\n",
    "print(f\"Short Model - Accuracy: {accuracy_score(y_short_test, y_short_pred_proba > 0.6):.3f}\")\n",
    "print(f\"Short Model - AUC: {roc_auc_score(y_short_test, y_short_pred_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models for LEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_long, '../models/ml_mean_reversion_long.pkl')\n",
    "joblib.dump(model_short, '../models/ml_mean_reversion_short.pkl')\n",
    "joblib.dump(feature_cols, '../models/feature_columns.pkl')\n",
    "print(\"Models saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Long model\n",
    "axes[0].barh(feature_cols, model_long.feature_importances_)\n",
    "axes[0].set_title('Long Model Feature Importance')\n",
    "axes[0].set_xlabel('Importance')\n",
    "\n",
    "# Short model\n",
    "axes[1].barh(feature_cols, model_short.feature_importances_)\n",
    "axes[1].set_title('Short Model Feature Importance')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
