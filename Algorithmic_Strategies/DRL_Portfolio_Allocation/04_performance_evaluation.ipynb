{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1e7c90",
   "metadata": {},
   "source": [
    "# Performance Evaluation for DRL Portfolio\n",
    "\n",
    "This notebook compares DRL agent to benchmarks (Markowitz, 60/40, Equal Weight) and performs statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b82ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_acquisition import DataAcquisition\n",
    "from portfolio_env import PortfolioEnv\n",
    "from rl_agent import DRLAgent\n",
    "from benchmark import MarkowitzOptimizer, Classic6040, EqualWeight, BenchmarkBacktester\n",
    "from backtester import Backtester\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea1134",
   "metadata": {},
   "source": [
    "## 1. Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_acq = DataAcquisition('config.yaml')\n",
    "dataset = data_acq.fetch_full_dataset()\n",
    "\n",
    "test_prices = dataset['test']['prices']\n",
    "test_returns = dataset['test']['returns']\n",
    "\n",
    "print(f\"Test period: {test_prices.index[0]} to {test_prices.index[-1]}\")\n",
    "print(f\"Test days: {len(test_prices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained DRL agent\n",
    "# Note: This assumes you've run training first\n",
    "test_env = PortfolioEnv(test_prices, test_returns)\n",
    "agent = DRLAgent(test_env, algorithm='ppo')\n",
    "\n",
    "# Try to load best model\n",
    "try:\n",
    "    agent.load('models/best_model')\n",
    "    print(\"\\nLoaded best model from training\")\n",
    "except:\n",
    "    print(\"\\nWarning: Could not load trained model. Using untrained agent.\")\n",
    "    print(\"Run 'python main.py --mode train' first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4c966",
   "metadata": {},
   "source": [
    "## 2. Backtest All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest DRL agent\n",
    "print(\"Backtesting DRL agent...\")\n",
    "backtester = Backtester()\n",
    "drl_results = backtester.run_backtest(agent, test_prices, test_returns)\n",
    "print(\"✓ DRL complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd412266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest benchmarks\n",
    "print(\"\\nBacktesting benchmarks...\")\n",
    "benchmark_backtester = BenchmarkBacktester()\n",
    "\n",
    "# Markowitz\n",
    "print(\"  - Markowitz MVO...\")\n",
    "mvo_results = benchmark_backtester.backtest_markowitz(test_prices, test_returns)\n",
    "mvo_df = pd.DataFrame({\n",
    "    'portfolio_value': mvo_results['portfolio_history'][1:],\n",
    "    'returns': test_returns.values @ np.array(mvo_results['weights_history'][:-1]).T\n",
    "}, index=test_returns.index)\n",
    "mvo_metrics = backtester.calculate_metrics(mvo_df)\n",
    "\n",
    "# 60/40\n",
    "print(\"  - 60/40...\")\n",
    "classic = Classic6040()\n",
    "classic_results = benchmark_backtester.backtest_static(test_prices, test_returns, classic)\n",
    "classic_df = pd.DataFrame({\n",
    "    'portfolio_value': classic_results['portfolio_history'][1:],\n",
    "    'returns': test_returns.values @ classic.get_weights()\n",
    "}, index=test_returns.index)\n",
    "classic_metrics = backtester.calculate_metrics(classic_df)\n",
    "\n",
    "# Equal Weight\n",
    "print(\"  - Equal Weight...\")\n",
    "equal = EqualWeight(n_assets=4)\n",
    "equal_results = benchmark_backtester.backtest_static(test_prices, test_returns, equal)\n",
    "equal_df = pd.DataFrame({\n",
    "    'portfolio_value': equal_results['portfolio_history'][1:],\n",
    "    'returns': test_returns.values @ equal.get_weights()\n",
    "}, index=test_returns.index)\n",
    "equal_metrics = backtester.calculate_metrics(equal_df)\n",
    "\n",
    "print(\"✓ All backtests complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4dae2",
   "metadata": {},
   "source": [
    "## 3. Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b589409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison\n",
    "all_results = {\n",
    "    'DRL': {'results_df': drl_results['results_df'], 'metrics': drl_results['metrics']},\n",
    "    'Markowitz': {'results_df': mvo_df, 'metrics': mvo_metrics},\n",
    "    '60/40': {'results_df': classic_df, 'metrics': classic_metrics},\n",
    "    'Equal Weight': {'results_df': equal_df, 'metrics': equal_metrics}\n",
    "}\n",
    "\n",
    "comparison_df = backtester.compare_strategies(all_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df)\n",
    "\n",
    "# Save to CSV\n",
    "comparison_df.to_csv('results/comparison.csv')\n",
    "print(\"\\n✓ Comparison saved to results/comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f33cd1c",
   "metadata": {},
   "source": [
    "## 4. Portfolio Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8adf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "for strategy, results in all_results.items():\n",
    "    portfolio_values = results['results_df']['portfolio_value'].values\n",
    "    ax.plot(results['results_df'].index, portfolio_values, linewidth=2, label=strategy)\n",
    "\n",
    "ax.set_title('Portfolio Value Evolution (All Strategies)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Portfolio Value', fontsize=12)\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90ea661",
   "metadata": {},
   "source": [
    "## 5. Drawdown Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate drawdowns\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "for strategy, results in all_results.items():\n",
    "    portfolio_values = results['results_df']['portfolio_value'].values\n",
    "    cummax = np.maximum.accumulate(portfolio_values)\n",
    "    drawdowns = (cummax - portfolio_values) / cummax\n",
    "    \n",
    "    ax.plot(results['results_df'].index, -drawdowns * 100, linewidth=2, label=strategy)\n",
    "\n",
    "ax.set_title('Drawdown Evolution (All Strategies)', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Drawdown (%)', fontsize=12)\n",
    "ax.legend(fontsize=12, loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=-15, color='red', linestyle='--', alpha=0.5, label='Circuit Breaker (-15%)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8a3c5",
   "metadata": {},
   "source": [
    "## 6. DRL Weight Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b98691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DRL weight evolution\n",
    "if 'weights_history' in drl_results:\n",
    "    weights_array = np.array(drl_results['weights_history'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    symbols = test_prices.columns\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        ax.plot(drl_results['results_df'].index, weights_array[:, i], linewidth=2, label=symbol)\n",
    "    \n",
    "    ax.set_title('DRL Agent - Weight Evolution', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Weight', fontsize=12)\n",
    "    ax.legend(fontsize=12, loc='best')\n",
    "    ax.axhline(y=0.4, color='red', linestyle='--', alpha=0.5, label='Max Weight Constraint')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22eea9",
   "metadata": {},
   "source": [
    "## 7. Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform statistical tests\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL TESTS (DRL vs Benchmarks)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "drl_returns = all_results['DRL']['results_df']['returns'].values\n",
    "\n",
    "for benchmark in ['Markowitz', '60/40', 'Equal Weight']:\n",
    "    benchmark_returns = all_results[benchmark]['results_df']['returns'].values\n",
    "    \n",
    "    test_results = backtester.statistical_tests(drl_returns, benchmark_returns)\n",
    "    \n",
    "    print(f\"\\nDRL vs {benchmark}:\")\n",
    "    print(f\"  Mean return difference: {test_results['mean_diff']:.6f}\")\n",
    "    print(f\"  T-statistic: {test_results['t_statistic']:.3f}\")\n",
    "    print(f\"  P-value: {test_results['p_value']:.4f}\")\n",
    "    print(f\"  Statistically significant (p<0.05): {'Yes ✓' if test_results['is_significant'] else 'No ✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25cd17c",
   "metadata": {},
   "source": [
    "## 8. Return Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot return distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (strategy, results) in enumerate(all_results.items()):\n",
    "    ax = axes[idx]\n",
    "    returns = results['results_df']['returns'].values\n",
    "    \n",
    "    ax.hist(returns, bins=50, alpha=0.7, edgecolor='black', density=True)\n",
    "    ax.axvline(np.mean(returns), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(returns):.6f}')\n",
    "    ax.set_title(f'{strategy} - Return Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Daily Return', fontsize=10)\n",
    "    ax.set_ylabel('Density', fontsize=10)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3042d92",
   "metadata": {},
   "source": [
    "## 9. Risk-Return Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-return scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for strategy, results in all_results.items():\n",
    "    metrics = results['metrics']\n",
    "    \n",
    "    # Extract annualized return and volatility\n",
    "    ret = metrics['annualized_return'] * 100\n",
    "    vol = metrics['volatility'] * 100\n",
    "    \n",
    "    ax.scatter(vol, ret, s=200, alpha=0.7, label=strategy)\n",
    "    ax.annotate(strategy, (vol, ret), fontsize=11, ha='right')\n",
    "\n",
    "ax.set_title('Risk-Return Profile', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Annualized Volatility (%)', fontsize=12)\n",
    "ax.set_ylabel('Annualized Return (%)', fontsize=12)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab916be",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1168a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESEARCH SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Research Objective:\")\n",
    "print(\"   - Test if DRL can outperform Markowitz MVO by +10% return, -15% volatility\")\n",
    "\n",
    "print(\"\\n2. Methodology:\")\n",
    "print(\"   - Agent: PPO with Actor-Critic architecture [128, 128]\")\n",
    "print(\"   - State: Current weights + 20-day features + correlations\")\n",
    "print(\"   - Action: Target portfolio weights (0-40% per asset)\")\n",
    "print(\"   - Reward: Log return - 0.5*volatility - transaction costs\")\n",
    "\n",
    "print(\"\\n3. Results:\")\n",
    "print(comparison_df)\n",
    "\n",
    "print(\"\\n4. Key Findings:\")\n",
    "drl_sharpe = all_results['DRL']['metrics']['sharpe_ratio']\n",
    "mvo_sharpe = all_results['Markowitz']['metrics']['sharpe_ratio']\n",
    "\n",
    "if drl_sharpe > mvo_sharpe:\n",
    "    improvement = (drl_sharpe - mvo_sharpe) / mvo_sharpe * 100\n",
    "    print(f\"   ✓ DRL achieved {improvement:.1f}% higher Sharpe ratio vs Markowitz\")\n",
    "else:\n",
    "    print(\"   ✗ DRL did not outperform Markowitz (may need more training)\")\n",
    "\n",
    "print(\"\\n5. Limitations:\")\n",
    "print(\"   - Overfitting risk (test on out-of-sample data)\")\n",
    "print(\"   - Non-stationarity (market regime changes)\")\n",
    "print(\"   - Transaction costs (real-world implementation gap)\")\n",
    "print(\"   - Black box nature (addressed via SHAP/LIME explainability)\")\n",
    "\n",
    "print(\"\\n6. Next Steps:\")\n",
    "print(\"   - Run full training (500k timesteps)\")\n",
    "print(\"   - Hyperparameter optimization (Optuna)\")\n",
    "print(\"   - Stress testing (2008, 2020, 2022 crises)\")\n",
    "print(\"   - Explainability analysis (SHAP feature importance)\")\n",
    "print(\"   - Ablation studies (reward functions, architectures)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
