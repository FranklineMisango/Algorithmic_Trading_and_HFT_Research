{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efda23a",
   "metadata": {},
   "source": [
    "# Environment Validation for DRL Portfolio\n",
    "\n",
    "This notebook validates the custom Gymnasium environment (PortfolioGym-v0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_acquisition import DataAcquisition\n",
    "from portfolio_env import PortfolioEnv\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da3c4e",
   "metadata": {},
   "source": [
    "## 1. Load Data and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_acq = DataAcquisition('config.yaml')\n",
    "dataset = data_acq.fetch_full_dataset()\n",
    "\n",
    "# Create environment with training data\n",
    "env = PortfolioEnv(\n",
    "    prices=dataset['train']['prices'],\n",
    "    returns=dataset['train']['returns']\n",
    ")\n",
    "\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Observation space: {env.observation_space}\")\n",
    "print(f\"State dimension: {env.state_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d94c03b",
   "metadata": {},
   "source": [
    "## 2. Test Reset and Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reset\n",
    "obs, info = env.reset()\n",
    "\n",
    "print(f\"Initial observation shape: {obs.shape}\")\n",
    "print(f\"Initial weights: {env.current_weights}\")\n",
    "print(f\"Weights sum to: {np.sum(env.current_weights):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2739a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test step with random action\n",
    "action = env.action_space.sample()\n",
    "print(f\"\\nRandom action (raw): {action}\")\n",
    "\n",
    "obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "print(f\"\\nAfter step:\")\n",
    "print(f\"  Reward: {reward:.6f}\")\n",
    "print(f\"  Portfolio value: {info['portfolio_value']:.6f}\")\n",
    "print(f\"  Portfolio return: {info['portfolio_return']:.6f}\")\n",
    "print(f\"  Volatility: {info['volatility']:.6f}\")\n",
    "print(f\"  Cost: {info['cost']:.6f}\")\n",
    "print(f\"  New weights: {env.current_weights}\")\n",
    "print(f\"  Weights sum to: {np.sum(env.current_weights):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b50429",
   "metadata": {},
   "source": [
    "## 3. Random Policy Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run episode with random policy\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "step_count = 0\n",
    "max_steps = 100\n",
    "\n",
    "while not done and step_count < max_steps:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    step_count += 1\n",
    "\n",
    "print(f\"Episode completed in {step_count} steps\")\n",
    "print(f\"Final portfolio value: ${env.portfolio_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio evolution\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Portfolio value\n",
    "ax1.plot(env.portfolio_history, linewidth=2)\n",
    "ax1.set_title('Random Policy - Portfolio Value', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Step', fontsize=12)\n",
    "ax1.set_ylabel('Portfolio Value', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Weights evolution\n",
    "weights_array = np.array(env.weights_history)\n",
    "for i, symbol in enumerate(dataset['train']['prices'].columns):\n",
    "    ax2.plot(weights_array[:, i], label=symbol, linewidth=2)\n",
    "\n",
    "ax2.set_title('Random Policy - Weight Evolution', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Step', fontsize=12)\n",
    "ax2.set_ylabel('Weight', fontsize=12)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0e72",
   "metadata": {},
   "source": [
    "## 4. Reward Function Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different actions and observe rewards\n",
    "test_actions = [\n",
    "    np.array([0.25, 0.25, 0.25, 0.25]),  # Equal weight\n",
    "    np.array([0.4, 0.4, 0.1, 0.1]),      # Concentrated\n",
    "    np.array([0.6, 0.2, 0.1, 0.1]),      # Aggressive SPY\n",
    "    np.array([0.0, 0.6, 0.2, 0.2])       # Conservative AGG\n",
    "]\n",
    "\n",
    "action_labels = ['Equal', 'Concentrated', 'Aggressive', 'Conservative']\n",
    "\n",
    "for action, label in zip(test_actions, action_labels):\n",
    "    env.reset()\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Action: {action}\")\n",
    "    print(f\"  Reward: {reward:.6f}\")\n",
    "    print(f\"  Return: {info['portfolio_return']:.6f}\")\n",
    "    print(f\"  Volatility: {info['volatility']:.6f}\")\n",
    "    print(f\"  Cost: {info['cost']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d0a258",
   "metadata": {},
   "source": [
    "## 5. Constraint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ff65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test constraint enforcement\n",
    "print(\"Testing constraint enforcement:\\n\")\n",
    "\n",
    "# Test 1: Weights sum to 1.0\n",
    "env.reset()\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    weight_sum = np.sum(env.current_weights)\n",
    "    \n",
    "    if not np.isclose(weight_sum, 1.0, atol=1e-6):\n",
    "        print(f\"WARNING: Weights sum to {weight_sum:.8f}\")\n",
    "\n",
    "print(\"✓ All weights sum to 1.0\")\n",
    "\n",
    "# Test 2: Weights within bounds\n",
    "min_bound = env.min_weight\n",
    "max_bound = env.max_weight\n",
    "\n",
    "env.reset()\n",
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, _, _, info = env.step(action)\n",
    "    \n",
    "    if np.any(env.current_weights < min_bound - 1e-6) or np.any(env.current_weights > max_bound + 1e-6):\n",
    "        print(f\"WARNING: Weights out of bounds: {env.current_weights}\")\n",
    "\n",
    "print(f\"✓ All weights within [{min_bound}, {max_bound}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec259129",
   "metadata": {},
   "source": [
    "## 6. Circuit Breaker Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a647447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test circuit breaker (15% drawdown)\n",
    "print(\"Testing circuit breaker (15% drawdown threshold):\\n\")\n",
    "\n",
    "env.reset()\n",
    "max_drawdown = 0\n",
    "circuit_breaker_triggered = False\n",
    "\n",
    "for step in range(200):\n",
    "    # Use aggressive random action\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    max_drawdown = max(max_drawdown, info['drawdown'])\n",
    "    \n",
    "    if truncated:\n",
    "        circuit_breaker_triggered = True\n",
    "        print(f\"Circuit breaker triggered at step {step}\")\n",
    "        print(f\"Drawdown: {info['drawdown']:.2%}\")\n",
    "        break\n",
    "    \n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "if not circuit_breaker_triggered:\n",
    "    print(f\"Circuit breaker not triggered. Max drawdown: {max_drawdown:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
