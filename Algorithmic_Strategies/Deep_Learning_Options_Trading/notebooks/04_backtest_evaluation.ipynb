{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b0c15b",
   "metadata": {},
   "source": [
    "# Deep Learning Options Trading - Backtest Evaluation\n",
    "\n",
    "This notebook evaluates the LSTM model's backtesting performance:\n",
    "- Performance metrics and risk analysis\n",
    "- Benchmark comparisons (buy-and-hold, momentum, mean-reversion)\n",
    "- Factor attribution and capacity analysis\n",
    "- Stress testing and robustness checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def314c",
   "metadata": {},
   "source": [
    "## 1. Load Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load backtest results\n",
    "try:\n",
    "    with open('../results/backtest_results.json', 'r') as f:\n",
    "        backtest_results = json.load(f)\n",
    "    \n",
    "    print(\"Backtest results loaded successfully\")\n",
    "    print(f\"Backtest period: {backtest_results.get('dates', [None, None])[0]} to {backtest_results.get('dates', [None, None])[-1]}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Backtest results not found. Run backtesting first.\")\n",
    "    backtest_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5284f",
   "metadata": {},
   "source": [
    "## 2. Performance Metrics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41964a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_results:\n",
    "    # Extract key metrics\n",
    "    metrics = {\n",
    "        'Total Return': backtest_results.get('total_return', 0),\n",
    "        'Annual Return': backtest_results.get('annual_return', 0),\n",
    "        'Annual Volatility': backtest_results.get('annual_volatility', 0),\n",
    "        'Sharpe Ratio': backtest_results.get('sharpe_ratio', 0),\n",
    "        'Max Drawdown': backtest_results.get('max_drawdown', 0),\n",
    "        'Win Rate': backtest_results.get('win_rate', 0),\n",
    "        'Total Trades': backtest_results.get('total_trades', 0),\n",
    "        'Avg Daily Turnover': backtest_results.get('avg_daily_turnover', 0)\n",
    "    }\n",
    "    \n",
    "    # Display metrics\n",
    "    print(\"=== LSTM STRATEGY PERFORMANCE ===\\n\")\n",
    "    for metric, value in metrics.items():\n",
    "        if 'Rate' in metric or 'Return' in metric:\n",
    "            print(f\"{metric}: {value:.2%}\")\n",
    "        elif 'Ratio' in metric:\n",
    "            print(f\"{metric}: {value:.2f}\")\n",
    "        elif 'Trades' in metric:\n",
    "            print(f\"{metric}: {int(value)}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.2f}\")\n",
    "    \n",
    "    # Check against research targets (if available)\n",
    "    target_sharpe = 2.0  # Example target from research\n",
    "    if metrics['Sharpe Ratio'] >= target_sharpe:\n",
    "        print(f\"\\n Sharpe ratio ({metrics['Sharpe Ratio']:.2f}) meets or exceeds target ({target_sharpe:.2f})\")\n",
    "    else:\n",
    "        print(f\"\\n Sharpe ratio ({metrics['Sharpe Ratio']:.2f}) below target ({target_sharpe:.2f})\")\n",
    "    \n",
    "    # Risk-adjusted return analysis\n",
    "    print(\"\\nRisk-Adjusted Return Analysis:\")\n",
    "    print(f\"Return/MaxDD Ratio: {metrics['Total Return'] / abs(metrics['Max Drawdown']):.2f}\")\n",
    "    print(f\"Sharpe/Volatility: {metrics['Sharpe Ratio'] / metrics['Annual Volatility']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_results:\n",
    "    # Portfolio value and returns visualization\n",
    "    portfolio_values = backtest_results.get('portfolio_values', [])\n",
    "    daily_returns = backtest_results.get('daily_returns', [])\n",
    "    dates = pd.to_datetime(backtest_results.get('dates', []))\n",
    "    \n",
    "    if portfolio_values and dates.any():\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Portfolio value over time\n",
    "        axes[0,0].plot(dates, portfolio_values, linewidth=2, color='blue')\n",
    "        axes[0,0].set_title('Portfolio Value Over Time')\n",
    "        axes[0,0].set_xlabel('Date')\n",
    "        axes[0,0].set_ylabel('Portfolio Value ($)')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Drawdown chart\n",
    "        cumulative = pd.Series(portfolio_values) / portfolio_values[0]\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdowns = (cumulative - running_max) / running_max\n",
    "        \n",
    "        axes[0,1].fill_between(range(len(drawdowns)), 0, drawdowns, color='red', alpha=0.3)\n",
    "        axes[0,1].set_title('Portfolio Drawdown')\n",
    "        axes[0,1].set_xlabel('Time')\n",
    "        axes[0,1].set_ylabel('Drawdown (%)')\n",
    "        axes[0,1].set_ylim(bottom=-0.5, top=0)\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Daily returns distribution\n",
    "        if daily_returns:\n",
    "            axes[1,0].hist(daily_returns, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "            axes[1,0].axvline(np.mean(daily_returns), color='red', linestyle='--', \n",
    "                            label=f'Mean: {np.mean(daily_returns):.4%}')\n",
    "            axes[1,0].set_title('Daily Returns Distribution')\n",
    "            axes[1,0].set_xlabel('Daily Return')\n",
    "            axes[1,0].set_ylabel('Frequency')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rolling Sharpe ratio\n",
    "        if daily_returns:\n",
    "            rolling_window = 252  # 1 year\n",
    "            rolling_sharpe = (pd.Series(daily_returns).rolling(rolling_window).mean() / \n",
    "                            pd.Series(daily_returns).rolling(rolling_window).std()) * np.sqrt(252)\n",
    "            \n",
    "            axes[1,1].plot(dates, rolling_sharpe, linewidth=1, color='purple')\n",
    "            axes[1,1].axhline(y=backtest_results.get('sharpe_ratio', 0), color='red', linestyle='--', \n",
    "                            alpha=0.7, label=f'Overall: {backtest_results.get(\"sharpe_ratio\", 0):.2f}')\n",
    "            axes[1,1].set_title(f'Rolling Sharpe Ratio ({rolling_window} days)')\n",
    "            axes[1,1].set_xlabel('Date')\n",
    "            axes[1,1].set_ylabel('Sharpe Ratio')\n",
    "            axes[1,1].legend()\n",
    "            axes[1,1].grid(True, alpha=0.3)\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c2f0",
   "metadata": {},
   "source": [
    "## 3. Benchmark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e86a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_results:\n",
    "    # Load benchmark results\n",
    "    benchmarks = backtest_results.get('benchmarks', {})\n",
    "    \n",
    "    if benchmarks:\n",
    "        print(\"=== BENCHMARK COMPARISON ===\\n\")\n",
    "        \n",
    "        # Create comparison table\n",
    "        comparison_data = {\n",
    "            'Strategy': ['LSTM Model'] + list(benchmarks.keys()),\n",
    "            'Sharpe Ratio': [backtest_results.get('sharpe_ratio', 0)] + \n",
    "                          [benchmarks[name].get('sharpe_ratio', 0) for name in benchmarks.keys()],\n",
    "            'Total Return': [backtest_results.get('total_return', 0)] + \n",
    "                          [benchmarks[name].get('total_return', 0) for name in benchmarks.keys()],\n",
    "            'Max Drawdown': [backtest_results.get('max_drawdown', 0)] + \n",
    "                          [benchmarks[name].get('max_drawdown', 0) for name in benchmarks.keys()],\n",
    "            'Win Rate': [backtest_results.get('win_rate', 0)] + \n",
    "                          [benchmarks[name].get('win_rate', 0) for name in benchmarks.keys()]\n",
    "        }\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        print(comparison_df.to_string(index=False, float_format='%.2f'))\n",
    "        \n",
    "        # Statistical significance test (Diebold-Mariano)\n",
    "        print(\"\\nDiebold-Mariano Test Results:\")\n",
    "        lstm_returns = np.array(backtest_results.get('daily_returns', []))\n",
    "        \n",
    "        for bench_name, bench_results in benchmarks.items():\n",
    "            bench_returns = np.array(bench_results.get('daily_returns', []))\n",
    "            \n",
    "            if len(lstm_returns) == len(bench_returns) and len(lstm_returns) > 0:\n",
    "                # Simplified DM test (actual implementation would use statsmodels)\n",
    "                diff = lstm_returns - bench_returns\n",
    "                dm_stat = np.mean(diff) / np.std(diff) * np.sqrt(len(diff))\n",
    "                p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "                \n",
    "                print(f\"LSTM vs {bench_name}: DM stat = {dm_stat:.2f}, p-value = {p_value:.4f}\")\n",
    "                if p_value < 0.05:\n",
    "                    print(f\"  â†’ Significant difference at 5% level\")\n",
    "                else:\n",
    "                    print(f\"  â†’ No significant difference at 5% level\")\n",
    "            else:\n",
    "                print(f\"LSTM vs {bench_name}: Cannot perform test (unequal lengths)\")\n",
    "    else:\n",
    "        print(\"No benchmark results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_results and benchmarks:\n",
    "    # Benchmark comparison visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Sharpe ratio comparison\n",
    "    strategies = ['LSTM'] + list(benchmarks.keys())\n",
    "    sharpe_ratios = [backtest_results.get('sharpe_ratio', 0)] + \\\n",
    "                   [benchmarks[name].get('sharpe_ratio', 0) for name in benchmarks.keys()]\n",
    "    \n",
    "    bars = axes[0,0].bar(strategies, sharpe_ratios, color=['blue'] + ['gray'] * len(benchmarks))\n",
    "    axes[0,0].set_title('Sharpe Ratio Comparison')\n",
    "    axes[0,0].set_ylabel('Sharpe Ratio')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight LSTM bar\n",
    "    bars[0].set_color('darkblue')\n",
    "    \n",
    "    # Total return comparison\n",
    "    total_returns = [backtest_results.get('total_return', 0)] + \\\n",
    "                   [benchmarks[name].get('total_return', 0) for name in benchmarks.keys()]\n",
    "    \n",
    "    bars = axes[0,1].bar(strategies, total_returns, color=['blue'] + ['gray'] * len(benchmarks))\n",
    "    axes[0,1].set_title('Total Return Comparison')\n",
    "    axes[0,1].set_ylabel('Total Return (%)')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    bars[0].set_color('darkblue')\n",
    "    \n",
    "    # Maximum drawdown comparison\n",
    "    max_drawdowns = [backtest_results.get('max_drawdown', 0)] + \\\n",
    "                   [benchmarks[name].get('max_drawdown', 0) for name in benchmarks.keys()]\n",
    "    \n",
    "    bars = axes[1,0].bar(strategies, max_drawdowns, color=['red'] + ['lightcoral'] * len(benchmarks))\n",
    "    axes[1,0].set_title('Maximum Drawdown Comparison')\n",
    "    axes[1,0].set_ylabel('Max Drawdown (%)')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    bars[0].set_color('darkred')\n",
    "    \n",
    "    # Win rate comparison\n",
    "    win_rates = [backtest_results.get('win_rate', 0)] + \\\n",
    "               [benchmarks[name].get('win_rate', 0) for name in benchmarks.keys()]\n",
    "    \n",
    "    bars = axes[1,1].bar(strategies, win_rates, color=['green'] + ['lightgreen'] * len(benchmarks))\n",
    "    axes[1,1].set_title('Win Rate Comparison')\n",
    "    axes[1,1].set_ylabel('Win Rate (%)')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    bars[0].set_color('darkgreen')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5278e63",
   "metadata": {},
   "source": [
    "## 4. Capacity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc890f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity analysis - test performance with increasing capital\n",
    "if backtest_results:\n",
    "    print(\"=== CAPACITY ANALYSIS ===\\n\")\n",
    "    \n",
    "    # Simulate different capital levels\n",
    "    capital_levels = [1e6, 5e6, 10e6, 50e6, 100e6]  # $1M to $100M\n",
    "    capacity_results = []\n",
    "    \n",
    "    base_sharpe = backtest_results.get('sharpe_ratio', 0)\n",
    "    base_return = backtest_results.get('total_return', 0)\n",
    "    \n",
    "    for capital in capital_levels:\n",
    "        # Simplified capacity decay model\n",
    "        # In practice, this would require re-running backtest with different position sizes\n",
    "        \n",
    "        # Assume Sharpe decays with sqrt(capital) due to market impact\n",
    "        decay_factor = np.sqrt(capital_levels[0] / capital)  # Relative to $1M\n",
    "        decayed_sharpe = base_sharpe * decay_factor\n",
    "        \n",
    "        # Assume returns decay linearly with market impact\n",
    "        impact_cost = 0.01 * np.log(capital / 1e6)  # 1% impact per log capital increase\n",
    "        decayed_return = base_return * (1 - impact_cost)\n",
    "        \n",
    "        capacity_results.append({\n",
    "            'capital': capital,\n",
    "            'sharpe_ratio': decayed_sharpe,\n",
    "            'total_return': decayed_return,\n",
    "            'annual_return': (1 + decayed_return) ** (252 / len(backtest_results.get('daily_returns', []))) - 1\n",
    "        })\n",
    "    \n",
    "    capacity_df = pd.DataFrame(capacity_results)\n",
    "    print(\"Capacity Analysis Results:\")\n",
    "    print(capacity_df.to_string(index=False, float_format='%.2f'))\n",
    "    \n",
    "    # Plot capacity decay\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    axes[0].plot(capacity_df['capital'], capacity_df['sharpe_ratio'], 'bo-', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Capital ($)')\n",
    "    axes[0].set_ylabel('Sharpe Ratio')\n",
    "    axes[0].set_title('Sharpe Ratio vs Capital')\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(capacity_df['capital'], capacity_df['annual_return'], 'ro-', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Capital ($)')\n",
    "    axes[1].set_ylabel('Annual Return (%)')\n",
    "    axes[1].set_title('Annual Return vs Capital')\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estimate optimal capital\n",
    "    optimal_idx = np.argmax(capacity_df['sharpe_ratio'])\n",
    "    optimal_capital = capacity_df.loc[optimal_idx, 'capital']\n",
    "    optimal_sharpe = capacity_df.loc[optimal_idx, 'sharpe_ratio']\n",
    "    \n",
    "    print(f\"\\nEstimated optimal capital: ${optimal_capital:,.0f}\")\n",
    "    print(f\"Optimal Sharpe ratio: {optimal_sharpe:.2f}\")\n",
    "    print(f\"Capacity limit reached at: ${capacity_df.loc[capacity_df['sharpe_ratio'] < 1.0, 'capital'].min():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ba3fe",
   "metadata": {},
   "source": [
    "## 5. Stress Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4250a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress testing during market crises\n",
    "if backtest_results and dates.any():\n",
    "    print(\"=== STRESS TESTING ===\\n\")\n",
    "    \n",
    "    daily_returns = pd.Series(backtest_results.get('daily_returns', []), index=dates)\n",
    "    \n",
    "    # Define stress periods\n",
    "    stress_periods = {\n",
    "        'COVID-19 Crash': ('2020-02-01', '2020-04-30'),\n",
    "        'Financial Crisis': ('2008-09-01', '2009-03-31'),\n",
    "        'Tech Bubble': ('2000-03-01', '2000-10-31')\n",
    "    }\n",
    "    \n",
    "    stress_results = []\n",
    "    \n",
    "    for period_name, (start_date, end_date) in stress_periods.items():\n",
    "        try:\n",
    "            period_returns = daily_returns[start_date:end_date]\n",
    "            \n",
    "            if len(period_returns) > 0:\n",
    "                period_sharpe = (period_returns.mean() / period_returns.std()) * np.sqrt(252)\n",
    "                period_return = (1 + period_returns).prod() - 1\n",
    "                max_dd = (1 - (1 + period_returns).cumprod() / (1 + period_returns).cumprod().expanding().max()).min()\n",
    "                \n",
    "                stress_results.append({\n",
    "                    'period': period_name,\n",
    "                    'sharpe_ratio': period_sharpe,\n",
    "                    'total_return': period_return,\n",
    "                    'max_drawdown': max_dd,\n",
    "                    'days': len(period_returns)\n",
    "                })\n",
    "                \n",
    "                print(f\"{period_name}:\")\n",
    "                print(f\"  Sharpe Ratio: {period_sharpe:.2f}\")\n",
    "                print(f\"  Total Return: {period_return:.2%}\")\n",
    "                print(f\"  Max Drawdown: {max_dd:.2%}\")\n",
    "                print(f\"  Days: {len(period_returns)}\")\n",
    "                print()\n",
    "            else:\n",
    "                print(f\"{period_name}: No data available\\n\")\n",
    "                \n",
    "        except KeyError:\n",
    "            print(f\"{period_name}: Period not in backtest data\\n\")\n",
    "    \n",
    "    # Overall stress test summary\n",
    "    if stress_results:\n",
    "        stress_df = pd.DataFrame(stress_results)\n",
    "        \n",
    "        print(\"Stress Test Summary:\")\n",
    "        print(f\"Worst Sharpe ratio: {stress_df['sharpe_ratio'].min():.2f} ({stress_df.loc[stress_df['sharpe_ratio'].idxmin(), 'period']})\")\n",
    "        print(f\"Worst drawdown: {stress_df['max_drawdown'].min():.2%} ({stress_df.loc[stress_df['max_drawdown'].idxmin(), 'period']})\")\n",
    "        print(f\"Average stress Sharpe: {stress_df['sharpe_ratio'].mean():.2f}\")\n",
    "        \n",
    "        # Check if strategy survives stress periods\n",
    "        surviving_periods = stress_df[stress_df['sharpe_ratio'] > 0]['period'].tolist()\n",
    "        failing_periods = stress_df[stress_df['sharpe_ratio'] <= 0]['period'].tolist()\n",
    "        \n",
    "        print(f\"\\nSurviving periods: {', '.join(surviving_periods) if surviving_periods else 'None'}\")\n",
    "        print(f\"Failing periods: {', '.join(failing_periods) if failing_periods else 'None'}\")\n",
    "    else:\n",
    "        print(\"No stress periods available for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf6287",
   "metadata": {},
   "source": [
    "## 6. Transaction Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction cost sensitivity analysis\n",
    "if backtest_results:\n",
    "    print(\"=== TRANSACTION COST ANALYSIS ===\\n\")\n",
    "    \n",
    "    # Test different cost levels\n",
    "    cost_levels = [0.005, 0.01, 0.02, 0.05]  # 0.5% to 5%\n",
    "    cost_sensitivity = []\n",
    "    \n",
    "    base_sharpe = backtest_results.get('sharpe_ratio', 0)\n",
    "    base_turnover = backtest_results.get('avg_daily_turnover', 0)\n",
    "    \n",
    "    for cost_pct in cost_levels:\n",
    "        # Estimate cost drag on Sharpe ratio\n",
    "        # Simplified: assume costs reduce returns proportionally to turnover\n",
    "        cost_drag = base_turnover * cost_pct\n",
    "        adjusted_sharpe = base_sharpe * (1 - cost_drag / base_sharpe) if base_sharpe > 0 else 0\n",
    "        \n",
    "        cost_sensitivity.append({\n",
    "            'cost_pct': cost_pct,\n",
    "            'adjusted_sharpe': adjusted_sharpe,\n",
    "            'cost_drag': cost_drag\n",
    "        })\n",
    "        \n",
    "        print(f\"Cost level {cost_pct:.1%}: Adjusted Sharpe = {adjusted_sharpe:.2f}\")\n",
    "    \n",
    "    # Plot cost sensitivity\n",
    "    cost_df = pd.DataFrame(cost_sensitivity)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(cost_df['cost_pct'] * 100, cost_df['adjusted_sharpe'], 'ro-', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=base_sharpe, color='blue', linestyle='--', alpha=0.7, \n",
    "                label=f'Base Sharpe: {base_sharpe:.2f}')\n",
    "    plt.xlabel('Transaction Cost (% of trade value)')\n",
    "    plt.ylabel('Adjusted Sharpe Ratio')\n",
    "    plt.title('Sharpe Ratio vs Transaction Costs')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Breakeven analysis\n",
    "    breakeven_cost = base_sharpe / base_turnover if base_turnover > 0 else float('inf')\n",
    "    print(f\"\\nBreakeven cost level: {breakeven_cost:.2%}\")\n",
    "    print(f\"Current cost assumption: {config['backtest']['transaction_cost_per_contract'] * 100:.1f}Â¢ per contract\")\n",
    "    \n",
    "    if breakeven_cost > 0.01:  # 1%\n",
    "        print(\" Strategy robust to typical transaction costs\")\n",
    "    else:\n",
    "        print(\" Strategy sensitive to transaction costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa40c59",
   "metadata": {},
   "source": [
    "## 7. Backtest Evaluation Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65527ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive evaluation summary\n",
    "if backtest_results:\n",
    "    print(\"=== BACKTEST EVALUATION SUMMARY ===\\n\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    sharpe_ratio = backtest_results.get('sharpe_ratio', 0)\n",
    "    total_return = backtest_results.get('total_return', 0)\n",
    "    max_drawdown = backtest_results.get('max_drawdown', 0)\n",
    "    \n",
    "    print(\"Strategy Performance:\")\n",
    "    print(f\"- Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(f\"- Total Return: {total_return:.2%}\")\n",
    "    print(f\"- Max Drawdown: {max_drawdown:.2%}\")\n",
    "    print(f\"- Win Rate: {backtest_results.get('win_rate', 0):.2%}\")\n",
    "    \n",
    "    # Benchmark comparison\n",
    "    if benchmarks:\n",
    "        best_benchmark_sharpe = max([bench.get('sharpe_ratio', 0) for bench in benchmarks.values()])\n",
    "        outperformance = sharpe_ratio - best_benchmark_sharpe\n",
    "        print(f\"\\nBenchmark Outperformance: {outperformance:.2f} Sharpe points\")\n",
    "        \n",
    "        if outperformance > 0.5:\n",
    "            print(\" Strong outperformance vs benchmarks\")\n",
    "        elif outperformance > 0:\n",
    "            print(\" Moderate outperformance vs benchmarks\")\n",
    "        else:\n",
    "            print(\" Underperformance vs benchmarks\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    return_to_dd = abs(total_return / max_drawdown) if max_drawdown != 0 else float('inf')\n",
    "    print(f\"\\nRisk Metrics:\")\n",
    "    print(f\"- Return/MaxDD Ratio: {return_to_dd:.2f}\")\n",
    "    print(f\"- Annual Turnover: {backtest_results.get('avg_daily_turnover', 0) * 252:.2f}\")\n",
    "    \n",
    "    # Capacity assessment\n",
    "    if 'capacity_df' in locals():\n",
    "        optimal_capital = capacity_df.loc[capacity_df['sharpe_ratio'].idxmax(), 'capital']\n",
    "        print(f\"\\nCapacity Estimate: ${optimal_capital:,.0f} optimal capital\")\n",
    "    \n",
    "    # Stress test results\n",
    "    if 'stress_df' in locals() and not stress_df.empty:\n",
    "        stress_survival_rate = (stress_df['sharpe_ratio'] > 0).mean()\n",
    "        print(f\"\\nStress Test Survival Rate: {stress_survival_rate:.1%}\")\n",
    "    \n",
    "    # Overall recommendation\n",
    "    print(\"\\n=== FINAL ASSESSMENT ===\")\n",
    "    \n",
    "    score = 0\n",
    "    if sharpe_ratio > 1.5: score += 1\n",
    "    if return_to_dd > 1.0: score += 1\n",
    "    if outperformance > 0: score += 1\n",
    "    if stress_survival_rate > 0.5: score += 1\n",
    "    \n",
    "    if score >= 3:\n",
    "        print(\"ðŸŸ¢ RECOMMEND: Strong candidate for live trading\")\n",
    "    elif score >= 2:\n",
    "        print(\"ðŸŸ¡ CAUTION: Moderate performance, further testing recommended\")\n",
    "    else:\n",
    "        print(\" REJECT: Insufficient performance or risk-adjusted returns\")\n",
    "    \n",
    "    print(\"\\n=== EVALUATION COMPLETE ===\")\n",
    "else:\n",
    "    print(\"Backtest results not available for evaluation.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
