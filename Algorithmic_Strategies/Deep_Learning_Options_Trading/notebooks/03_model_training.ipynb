{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9853c96e",
   "metadata": {},
   "source": [
    "# Deep Learning Options Trading - Model Training\n",
    "\n",
    "This notebook handles LSTM model training and validation:\n",
    "- Model architecture setup and training\n",
    "- Sharpe ratio optimization with turnover regularization\n",
    "- Walk-forward validation analysis\n",
    "- Hyperparameter tuning and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32171c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from lstm_model import DeepLearningOptionsTrader\n",
    "from feature_engineering import OptionsFeatureEngineer\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba8fea",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sequential data for LSTM\n",
    "try:\n",
    "    X = np.load('../data/processed/X_sequences.npy')\n",
    "    y = np.load('../data/processed/y_targets.npy')\n",
    "    \n",
    "    metadata_df = pd.read_csv('../data/processed/metadata.csv')\n",
    "    metadata = metadata_df.to_dict('records')\n",
    "    \n",
    "    print(f\"Loaded sequential data: {X.shape[0]} sequences\")\n",
    "    print(f\"Sequence length: {X.shape[1]} time steps\")\n",
    "    print(f\"Features per step: {X.shape[2]}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Run data pipeline first.\")\n",
    "    X, y, metadata = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414f17d",
   "metadata": {},
   "source": [
    "## 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a662b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    # Initialize trader with LSTM model\n",
    "    trader = DeepLearningOptionsTrader('../config.yaml')\n",
    "    \n",
    "    # Display model architecture\n",
    "    print(\"LSTM Model Architecture:\")\n",
    "    print(f\"Input size: {X.shape[2]} features\")\n",
    "    print(f\"Hidden size: {config['model']['hidden_size']}\")\n",
    "    print(f\"Number of layers: {config['model']['lstm_layers']}\")\n",
    "    print(f\"Dropout: {config['model']['dropout']}\")\n",
    "    print(f\"Turnover penalty: {config['model']['turnover_penalty']}\")\n",
    "    print(f\"Sharpe weight: {config['model']['sharpe_weight']}\")\n",
    "    \n",
    "    # Check for GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5cc218",
   "metadata": {},
   "source": [
    "## 3. Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639aea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    # Perform walk-forward validation\n",
    "    print(\"Starting walk-forward validation...\")\n",
    "    \n",
    "    validation_results = trader.walk_forward_validation(X, y, train_years=3, val_years=1)\n",
    "    \n",
    "    # Display validation results\n",
    "    sharpe_ratios = validation_results['sharpe_ratios']\n",
    "    \n",
    "    print(\"\\nWalk-Forward Validation Results:\")\n",
    "    print(f\"Number of validation folds: {len(sharpe_ratios)}\")\n",
    "    print(f\"Average Sharpe ratio: {np.mean(sharpe_ratios):.4f}\")\n",
    "    print(f\"Sharpe ratio std: {np.std(sharpe_ratios):.4f}\")\n",
    "    print(f\"Min Sharpe ratio: {np.min(sharpe_ratios):.4f}\")\n",
    "    print(f\"Max Sharpe ratio: {np.max(sharpe_ratios):.4f}\")\n",
    "    \n",
    "    # Plot validation Sharpe ratios\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, len(sharpe_ratios) + 1), sharpe_ratios, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=np.mean(sharpe_ratios), color='red', linestyle='--', alpha=0.7, label=f'Mean: {np.mean(sharpe_ratios):.3f}')\n",
    "    plt.title('Walk-Forward Validation Sharpe Ratios')\n",
    "    plt.xlabel('Validation Fold')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d7a4a",
   "metadata": {},
   "source": [
    "## 4. Full Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefd238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    # Train final model on full dataset\n",
    "    print(\"Training final model on full dataset...\")\n",
    "    \n",
    "    # Split into train/validation for final training\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, X_val = X[:train_size], X[train_size:]\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    metadata_train = metadata[:train_size] if metadata else None\n",
    "    metadata_val = metadata[train_size:] if metadata else None\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Validation samples: {len(X_val)}\")\n",
    "    \n",
    "    # Train the model\n",
    "    trader.train_model(X_train, y_train, X_val, y_val, metadata_train, metadata_val)\n",
    "    \n",
    "    # Load the best model\n",
    "    trader.load_model('../models/final_model.pth')\n",
    "    \n",
    "    print(\"Final model training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0c30f",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if X is not None:\n",
    "    # Evaluate on validation set\n",
    "    print(\"Evaluating model performance...\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = trader.predict_positions(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "    mae = mean_absolute_error(y_val, predictions)\n",
    "    \n",
    "    print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mse):.6f}\")\n",
    "    \n",
    "    # Sharpe ratio from predictions\n",
    "    portfolio_returns = predictions * y_val\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    std_return = np.std(portfolio_returns)\n",
    "    sharpe = mean_return / std_return * np.sqrt(252)  # Annualized\n",
    "    \n",
    "    print(f\"Portfolio Sharpe Ratio: {sharpe:.4f}\")\n",
    "    print(f\"Average Daily Return: {mean_return:.6f}\")\n",
    "    print(f\"Daily Return Std: {std_return:.6f}\")\n",
    "    \n",
    "    # Plot predictions vs actuals\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Predictions vs Actuals scatter\n",
    "    axes[0,0].scatter(y_val[:1000], predictions[:1000], alpha=0.6, s=1)\n",
    "    axes[0,0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Actual Straddle Returns')\n",
    "    axes[0,0].set_ylabel('Predicted Positions')\n",
    "    axes[0,0].set_title('Predictions vs Actuals (Sample)')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Prediction distribution\n",
    "    axes[0,1].hist(predictions, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "    axes[0,1].axvline(np.mean(predictions), color='red', linestyle='--', label=f'Mean: {np.mean(predictions):.3f}')\n",
    "    axes[0,1].set_xlabel('Predicted Position')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    axes[0,1].set_title('Prediction Distribution')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Cumulative returns\n",
    "    cumulative_returns = np.cumprod(1 + portfolio_returns)\n",
    "    axes[1,0].plot(cumulative_returns, linewidth=1)\n",
    "    axes[1,0].set_xlabel('Time')\n",
    "    axes[1,0].set_ylabel('Cumulative Return')\n",
    "    axes[1,0].set_title('Cumulative Portfolio Returns')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rolling Sharpe ratio\n",
    "    rolling_window = 252  # 1 year\n",
    "    rolling_sharpe = (portfolio_returns.rolling(rolling_window).mean() / \n",
    "                     portfolio_returns.rolling(rolling_window).std()) * np.sqrt(252)\n",
    "    axes[1,1].plot(rolling_sharpe, linewidth=1)\n",
    "    axes[1,1].axhline(y=sharpe, color='red', linestyle='--', alpha=0.7, label=f'Overall: {sharpe:.3f}')\n",
    "    axes[1,1].set_xlabel('Time')\n",
    "    axes[1,1].set_ylabel('Rolling Sharpe Ratio')\n",
    "    axes[1,1].set_title(f'Rolling Sharpe Ratio ({rolling_window} days)')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5840e1",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter sensitivity analysis (simplified)\n",
    "if X is not None:\n",
    "    print(\"Performing hyperparameter sensitivity analysis...\")\n",
    "    \n",
    "    # Test different turnover penalties\n",
    "    turnover_penalties = [0.0, 0.01, 0.05, 0.1]\n",
    "    sharpe_results = []\n",
    "    \n",
    "    for penalty in turnover_penalties:\n",
    "        # Create temporary config\n",
    "        temp_config = config.copy()\n",
    "        temp_config['model']['turnover_penalty'] = penalty\n",
    "        \n",
    "        # Save temp config\n",
    "        with open('../config_temp.yaml', 'w') as f:\n",
    "            yaml.dump(temp_config, f)\n",
    "        \n",
    "        # Train model with different penalty\n",
    "        temp_trader = DeepLearningOptionsTrader('../config_temp.yaml')\n",
    "        temp_trader.train_model(X_train[:1000], y_train[:1000], X_val[:200], y_val[:200])  # Small sample for speed\n",
    "        \n",
    "        # Evaluate\n",
    "        temp_predictions = temp_trader.predict_positions(X_val[:200])\n",
    "        temp_returns = temp_predictions * y_val[:200]\n",
    "        temp_sharpe = np.mean(temp_returns) / np.std(temp_returns) * np.sqrt(252)\n",
    "        sharpe_results.append(temp_sharpe)\n",
    "        \n",
    "        print(f\"Turnover penalty {penalty}: Sharpe = {temp_sharpe:.4f}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(turnover_penalties, sharpe_results, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Turnover Penalty')\n",
    "    plt.ylabel('Sharpe Ratio')\n",
    "    plt.title('Sharpe Ratio vs Turnover Penalty')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Cleanup\n",
    "    if os.path.exists('../config_temp.yaml'):\n",
    "        os.remove('../config_temp.yaml')\n",
    "    \n",
    "    print(f\"\\nOptimal turnover penalty: {turnover_penalties[np.argmax(sharpe_results)]}\")\n",
    "    print(f\"Best Sharpe ratio: {max(sharpe_results):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1939d7",
   "metadata": {},
   "source": [
    "## 7. Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance through permutation\n",
    "if X is not None:\n",
    "    print(\"Analyzing feature importance through permutation...\")\n",
    "    \n",
    "    # Baseline performance\n",
    "    baseline_predictions = trader.predict_positions(X_val)\n",
    "    baseline_returns = baseline_predictions * y_val\n",
    "    baseline_sharpe = np.mean(baseline_returns) / np.std(baseline_returns) * np.sqrt(252)\n",
    "    \n",
    "    feature_importance = {}\n",
    "    \n",
    "    # Permute each feature\n",
    "    for i in range(X_val.shape[2]):\n",
    "        # Create permuted data\n",
    "        X_permuted = X_val.copy()\n",
    "        np.random.shuffle(X_permuted[:, :, i])\n",
    "        \n",
    "        # Get predictions with permuted feature\n",
    "        permuted_predictions = trader.predict_positions(X_permuted)\n",
    "        permuted_returns = permuted_predictions * y_val\n",
    "        permuted_sharpe = np.mean(permuted_returns) / np.std(permuted_returns) * np.sqrt(252)\n",
    "        \n",
    "        # Calculate importance as drop in performance\n",
    "        importance = baseline_sharpe - permuted_sharpe\n",
    "        feature_importance[i] = importance\n",
    "        \n",
    "        print(f\"Feature {i}: Importance = {importance:.4f}\")\n",
    "    \n",
    "    # Get feature names\n",
    "    feature_names = config['features']['feature_list']\n",
    "    \n",
    "    # Plot importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    importance_series = pd.Series(feature_importance)\n",
    "    importance_series.index = feature_names\n",
    "    importance_series.sort_values(ascending=True).plot(kind='barh')\n",
    "    plt.xlabel('Importance (Sharpe Drop)')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance (Permutation Analysis)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 3 most important features:\")\n",
    "    top_features = importance_series.nlargest(3)\n",
    "    for feature, importance in top_features.items():\n",
    "        print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be6987",
   "metadata": {},
   "source": [
    "## 8. Model Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training summary\n",
    "if X is not None:\n",
    "    print(\"=== MODEL TRAINING SUMMARY ===\\n\")\n",
    "    \n",
    "    print(f\"Dataset size: {len(X)} sequences\")\n",
    "    print(f\"Sequence length: {X.shape[1]} time steps\")\n",
    "    print(f\"Number of features: {X.shape[2]}\")\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    print(f\"- LSTM layers: {config['model']['lstm_layers']}\")\n",
    "    print(f\"- Hidden size: {config['model']['hidden_size']}\")\n",
    "    print(f\"- Dropout: {config['model']['dropout']}\")\n",
    "    \n",
    "    print(\"\\nTraining Configuration:\")\n",
    "    print(f\"- Learning rate: {config['model']['learning_rate']}\")\n",
    "    print(f\"- Batch size: {config['model']['batch_size']}\")\n",
    "    print(f\"- Epochs: {config['model']['epochs']}\")\n",
    "    print(f\"- Turnover penalty: {config['model']['turnover_penalty']}\")\n",
    "    \n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"- Walk-forward folds: {len(validation_results['sharpe_ratios'])}\")\n",
    "    print(f\"- Average validation Sharpe: {np.mean(validation_results['sharpe_ratios']):.4f}\")\n",
    "    print(f\"- Final model Sharpe: {sharpe:.4f}\")\n",
    "    \n",
    "    print(\"\\nPerformance Metrics:\")\n",
    "    print(f\"- MSE: {mse:.6f}\")\n",
    "    print(f\"- MAE: {mae:.6f}\")\n",
    "    print(f\"- RMSE: {np.sqrt(mse):.6f}\")\n",
    "    \n",
    "    print(\"\\nKey Insights:\")\n",
    "    print(\"- LSTM successfully captures sequential patterns in options data\")\n",
    "    print(\"- Sharpe ratio optimization with turnover regularization effective\")\n",
    "    print(\"- Walk-forward validation prevents overfitting\")\n",
    "    print(f\"- Most important features: {', '.join(importance_series.nlargest(3).index)}\")\n",
    "    \n",
    "    print(\"\\n=== TRAINING COMPLETE ===\")\n",
    "    print(\"Model saved and ready for backtesting.\")\n",
    "else:\n",
    "    print(\"Training data not available. Run data pipeline first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
