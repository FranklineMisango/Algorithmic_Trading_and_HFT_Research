{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec65267b",
   "metadata": {},
   "source": [
    "# Deep Learning Options Trading - Data Exploration\n",
    "\n",
    "This notebook explores the S&P 100 options dataset used for training the LSTM model. We analyze:\n",
    "- Universe composition and coverage\n",
    "- Options data quality and liquidity\n",
    "- Feature distributions and correlations\n",
    "- Time series characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe461483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd512ea1",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09161c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load underlying price data\n",
    "try:\n",
    "    prices_df = pd.read_csv('data/underlying_prices/underlying_prices.csv')\n",
    "    prices_df['Date'] = pd.to_datetime(prices_df['Date'])\n",
    "    prices_df = prices_df.set_index(['ticker', 'Date'])\n",
    "    print(f\"Loaded underlying prices: {prices_df.shape[0]} records for {len(prices_df.index.levels[0])} tickers\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Underlying price data not found. Run data acquisition first.\")\n",
    "    prices_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78815cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load options data\n",
    "try:\n",
    "    options_df = pd.read_csv('data/options_data/options_data.csv')\n",
    "    options_df['date'] = pd.to_datetime(options_df['date'])\n",
    "    options_df['expiry'] = pd.to_datetime(options_df['expiry'])\n",
    "    print(f\"Loaded options data: {len(options_df)} records\")\n",
    "    print(f\"Date range: {options_df['date'].min()} to {options_df['date'].max()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Options data not found. Run data acquisition first.\")\n",
    "    options_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350046df",
   "metadata": {},
   "source": [
    "## 2. Universe Composition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe71dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices_df is not None:\n",
    "    # Analyze ticker coverage\n",
    "    ticker_counts = prices_df.groupby('ticker').size().sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ticker_counts.head(20).plot(kind='bar')\n",
    "    plt.title('Top 20 S&P 100 Tickers by Data Points')\n",
    "    plt.xlabel('Ticker')\n",
    "    plt.ylabel('Number of Trading Days')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Total unique tickers: {len(ticker_counts)}\")\n",
    "    print(f\"Average trading days per ticker: {ticker_counts.mean():.0f}\")\n",
    "    print(f\"Median trading days per ticker: {ticker_counts.median():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices_df is not None:\n",
    "    # Price distribution analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Price levels\n",
    "    prices_df['Adj Close'].hist(bins=50, ax=axes[0,0])\n",
    "    axes[0,0].set_title('Distribution of Stock Prices')\n",
    "    axes[0,0].set_xlabel('Price ($)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Daily returns\n",
    "    prices_df['return_1d'].hist(bins=50, ax=axes[0,1])\n",
    "    axes[0,1].set_title('Distribution of Daily Returns')\n",
    "    axes[0,1].set_xlabel('Daily Return')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Returns by ticker (top 10)\n",
    "    top_tickers = ticker_counts.head(10).index\n",
    "    returns_by_ticker = prices_df.loc[top_tickers]['return_1d'].unstack(level=0)\n",
    "    returns_by_ticker.boxplot(ax=axes[1,0])\n",
    "    axes[1,0].set_title('Daily Returns by Ticker (Top 10)')\n",
    "    axes[1,0].set_xlabel('Ticker')\n",
    "    axes[1,0].set_ylabel('Daily Return')\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Volatility clustering\n",
    "    abs_returns = prices_df['return_1d'].abs()\n",
    "    abs_returns.rolling(30).mean().plot(ax=axes[1,1])\n",
    "    axes[1,1].set_title('30-Day Rolling Average Absolute Returns')\n",
    "    axes[1,1].set_xlabel('Date')\n",
    "    axes[1,1].set_ylabel('Absolute Return')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64450d09",
   "metadata": {},
   "source": [
    "## 3. Options Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options_df is not None:\n",
    "    # Basic statistics\n",
    "    print(\"Options Data Summary:\")\n",
    "    print(options_df.describe())\n",
    "    \n",
    "    # Liquidity analysis\n",
    "    liquidity_stats = options_df.groupby('ticker').agg({\n",
    "        'volume': ['mean', 'median', 'min', 'max'],\n",
    "        'open_interest': ['mean', 'median', 'min', 'max']\n",
    "    })\n",
    "    \n",
    "    print(\"\\nLiquidity Statistics by Ticker:\")\n",
    "    print(liquidity_stats.head())\n",
    "    \n",
    "    # Check liquidity filters\n",
    "    min_volume = config['data']['min_volume']\n",
    "    min_oi = config['data']['min_open_interest']\n",
    "    \n",
    "    liquid_options = options_df[\n",
    "        (options_df['volume'] >= min_volume) & \n",
    "        (options_df['open_interest'] >= min_oi)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nLiquidity Filter Results:\")\n",
    "    print(f\"Total options: {len(options_df)}\")\n",
    "    print(f\"Liquid options: {len(liquid_options)}\")\n",
    "    print(f\"Liquidity ratio: {len(liquid_options)/len(options_df):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe379818",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options_df is not None:\n",
    "    # Options characteristics visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # Straddle prices\n",
    "    options_df['straddle_price'].hist(bins=50, ax=axes[0,0])\n",
    "    axes[0,0].set_title('Distribution of Straddle Prices')\n",
    "    axes[0,0].set_xlabel('Straddle Price ($)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Moneyness\n",
    "    options_df['moneyness'].hist(bins=50, ax=axes[0,1])\n",
    "    axes[0,1].set_title('Distribution of Moneyness')\n",
    "    axes[0,1].set_xlabel('Moneyness (Strike/Spot)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Time to expiry\n",
    "    options_df['days_to_expiry'].hist(bins=50, ax=axes[0,2])\n",
    "    axes[0,2].set_title('Distribution of Days to Expiry')\n",
    "    axes[0,2].set_xlabel('Days to Expiry')\n",
    "    axes[0,2].set_ylabel('Frequency')\n",
    "    \n",
    "    # Implied volatility\n",
    "    options_df['implied_vol'].hist(bins=50, ax=axes[1,0])\n",
    "    axes[1,0].set_title('Distribution of Implied Volatility')\n",
    "    axes[1,0].set_xlabel('Implied Volatility')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Volume distribution\n",
    "    np.log10(options_df['volume'] + 1).hist(bins=50, ax=axes[1,1])\n",
    "    axes[1,1].set_title('Distribution of Log Volume')\n",
    "    axes[1,1].set_xlabel('Log10(Volume + 1)')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Open interest distribution\n",
    "    np.log10(options_df['open_interest'] + 1).hist(bins=50, ax=axes[1,2])\n",
    "    axes[1,2].set_title('Distribution of Log Open Interest')\n",
    "    axes[1,2].set_xlabel('Log10(Open Interest + 1)')\n",
    "    axes[1,2].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893f006c",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17ea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered features if available\n",
    "try:\n",
    "    features_df = pd.read_csv('data/processed/features.csv')\n",
    "    features_df['date'] = pd.to_datetime(features_df['date'])\n",
    "    print(f\"Loaded engineered features: {len(features_df)} records\")\n",
    "    \n",
    "    # Display feature correlations\n",
    "    feature_cols = [col for col in features_df.columns if col not in ['date', 'ticker', 'straddle_price']]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlation_matrix = features_df[feature_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Engineered features not found. Run feature engineering first.\")\n",
    "    features_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if features_df is not None:\n",
    "    # Feature distributions\n",
    "    n_features = len(feature_cols)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feature in enumerate(feature_cols):\n",
    "        if i < len(axes):\n",
    "            features_df[feature].hist(bins=50, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {feature}')\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(feature_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4abf05",
   "metadata": {},
   "source": [
    "## 5. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd1ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options_df is not None:\n",
    "    # Time series of key metrics\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Average straddle price over time\n",
    "    daily_avg_price = options_df.groupby('date')['straddle_price'].mean()\n",
    "    daily_avg_price.plot(ax=axes[0])\n",
    "    axes[0].set_title('Average Daily Straddle Price Over Time')\n",
    "    axes[0].set_xlabel('Date')\n",
    "    axes[0].set_ylabel('Average Straddle Price ($)')\n",
    "    \n",
    "    # Average implied volatility over time\n",
    "    daily_avg_iv = options_df.groupby('date')['implied_vol'].mean()\n",
    "    daily_avg_iv.plot(ax=axes[1])\n",
    "    axes[1].set_title('Average Daily Implied Volatility Over Time')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Average Implied Volatility')\n",
    "    \n",
    "    # Trading volume over time\n",
    "    daily_volume = options_df.groupby('date')['volume'].sum()\n",
    "    daily_volume.plot(ax=axes[2])\n",
    "    axes[2].set_title('Total Daily Options Volume Over Time')\n",
    "    axes[2].set_xlabel('Date')\n",
    "    axes[2].set_ylabel('Total Volume')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935b083",
   "metadata": {},
   "source": [
    "## 6. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dbbb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data quality report\n",
    "if options_df is not None and prices_df is not None:\n",
    "    print(\"=== DATA QUALITY SUMMARY ===\\n\")\n",
    "    \n",
    "    # Coverage statistics\n",
    "    print(f\"Date Range: {options_df['date'].min()} to {options_df['date'].max()}\")\n",
    "    print(f\"Total Trading Days: {options_df['date'].nunique()}\")\n",
    "    print(f\"Unique Tickers: {len(options_df['ticker'].unique())}\")\n",
    "    \n",
    "    # Data completeness\n",
    "    total_expected = len(options_df['date'].unique()) * len(options_df['ticker'].unique())\n",
    "    total_actual = len(options_df)\n",
    "    completeness = total_actual / total_expected\n",
    "    print(f\"Data Completeness: {completeness:.2%}\")\n",
    "    \n",
    "    # Liquidity assessment\n",
    "    liquid_pct = len(liquid_options) / len(options_df) if 'liquid_options' in locals() else 0\n",
    "    print(f\"Liquid Options (%): {liquid_pct:.2%}\")\n",
    "    \n",
    "    # Statistical summary\n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    stats_summary = options_df[['straddle_price', 'moneyness', 'days_to_expiry', 'implied_vol']].describe()\n",
    "    print(stats_summary)\n",
    "    \n",
    "    print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "else:\n",
    "    print(\"Data not available for quality assessment. Run data acquisition pipeline first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
