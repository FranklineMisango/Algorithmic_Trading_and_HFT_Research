{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d53372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import subprocess\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\" Environment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch underlying prices to match options date range\n",
    "# Since we have options from 2025-10-01 to 2026-01-30, fetch prices for the same period\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# Parameters matching your options data\n",
    "tickers = ['AAPL', 'MSFT', 'AMZN']  # From options files\n",
    "start_date = '2025-10-01'\n",
    "end_date = '2026-01-31'  # Day after last options date\n",
    "\n",
    "print(f\"Fetching underlying prices for {', '.join(tickers)}\")\n",
    "print(f\"   Date range: {start_date} to {end_date}\\n\")\n",
    "\n",
    "all_data = []\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        print(f\"   Downloading {ticker}...\", end=' ')\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, \n",
    "                          progress=False, auto_adjust=True)\n",
    "        \n",
    "        if not data.empty:\n",
    "            data = data.reset_index()\n",
    "            data['ticker'] = ticker\n",
    "            \n",
    "            # Flatten columns if MultiIndex\n",
    "            if isinstance(data.columns, pd.MultiIndex):\n",
    "                data.columns = [col[0] if isinstance(col, tuple) else col for col in data.columns]\n",
    "            \n",
    "            all_data.append(data)\n",
    "            print(f\"OK - {len(data)} days\")\n",
    "        else:\n",
    "            print(f\"No data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if all_data:\n",
    "    # Combine and process\n",
    "    prices_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Rename columns\n",
    "    column_map = {'Date': 'date', 'Open': 'open', 'High': 'high', \n",
    "                  'Low': 'low', 'Close': 'close', 'Volume': 'volume'}\n",
    "    prices_df = prices_df.rename(columns=column_map)\n",
    "    \n",
    "    # Calculate returns and volatility\n",
    "    prices_df = prices_df.sort_values(['ticker', 'date'])\n",
    "    prices_df['return_1d'] = prices_df.groupby('ticker')['close'].pct_change()\n",
    "    prices_df['return_5d'] = prices_df.groupby('ticker')['close'].pct_change(5)\n",
    "    prices_df['volatility_30d'] = prices_df.groupby('ticker')['return_1d'].transform(\n",
    "        lambda x: x.rolling(30, min_periods=10).std() * np.sqrt(252)\n",
    "    )\n",
    "    \n",
    "    # Save to file\n",
    "    output_file = '../data/underlying_prices/underlying_prices.csv'\n",
    "    prices_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nFETCHED AND SAVED UNDERLYING PRICES\")\n",
    "    print(f\"   File: {output_file}\")\n",
    "    print(f\"   Shape: {prices_df.shape}\")\n",
    "    print(f\"   Tickers: {sorted(prices_df['ticker'].unique())}\")\n",
    "    print(f\"   Date range: {prices_df['date'].min().date()} to {prices_df['date'].max().date()}\")\n",
    "    print(f\"   Total days: {prices_df['date'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nSAMPLE:\")\n",
    "    display(prices_df.head(3))\n",
    "else:\n",
    "    print(\"\\nFailed to fetch any price data\")\n",
    "    prices_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32423473",
   "metadata": {},
   "source": [
    "## 1. Load Underlying Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea1697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 options data files:\n",
      "   ✓ MSFT_Options_Data.csv: 800,516 rows\n",
      "   ✓ AAPL_Options_Data.csv: 704,124 rows\n",
      "   ✓ AMZN_Options_Data.csv: 812,784 rows\n",
      "\n",
      " OPTIONS DATA LOADED\n",
      "   Shape: (2317424, 12)\n",
      "   Tickers: ['AAPL', 'AMZN', 'MSFT']\n",
      "   Date range: 2025-10-01 to 2026-01-30\n",
      "   Columns: ['ts_event', 'rtype', 'publisher_id', 'instrument_id', 'open', 'high', 'low', 'close', 'volume', 'symbol', 'date', 'ticker']\n",
      "\n",
      " DATA QUALITY:\n",
      "   ✓ No missing values in price/volume columns\n",
      "\n",
      " SAMPLE DATA (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MSFT  260220C00520000</td>\n",
       "      <td>34.37</td>\n",
       "      <td>34.37</td>\n",
       "      <td>34.37</td>\n",
       "      <td>34.37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MSFT  260220C00520000</td>\n",
       "      <td>33.30</td>\n",
       "      <td>36.15</td>\n",
       "      <td>33.30</td>\n",
       "      <td>36.15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MSFT  251010P00492500</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MSFT  251010P00492500</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-01 00:00:00+00:00</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>MSFT  261218P00605000</td>\n",
       "      <td>97.45</td>\n",
       "      <td>97.45</td>\n",
       "      <td>97.45</td>\n",
       "      <td>97.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date ticker                 symbol   open   high  \\\n",
       "0 2025-10-01 00:00:00+00:00   MSFT  MSFT  260220C00520000  34.37  34.37   \n",
       "1 2025-10-01 00:00:00+00:00   MSFT  MSFT  260220C00520000  33.30  36.15   \n",
       "2 2025-10-01 00:00:00+00:00   MSFT  MSFT  251010P00492500   1.19   1.19   \n",
       "3 2025-10-01 00:00:00+00:00   MSFT  MSFT  251010P00492500   1.16   1.16   \n",
       "4 2025-10-01 00:00:00+00:00   MSFT  MSFT  261218P00605000  97.45  97.45   \n",
       "\n",
       "     low  close  volume  \n",
       "0  34.37  34.37       2  \n",
       "1  33.30  36.15       4  \n",
       "2   0.69   0.71       7  \n",
       "3   1.04   1.04       2  \n",
       "4  97.45  97.45       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SUMMARY STATS:\n",
      "   Records per ticker:\n",
      "      AMZN: 812,784\n",
      "      MSFT: 800,516\n",
      "      AAPL: 704,124\n",
      "   Volume: min=1, max=200,041, mean=67.7\n",
      "   Close: min=$0.01, max=$425.90, mean=$18.18\n"
     ]
    }
   ],
   "source": [
    "# Load options data\n",
    "try:\n",
    "    import glob\n",
    "    \n",
    "    # Find all options data files\n",
    "    options_files = glob.glob('../data/options_data/*_Options_Data.csv')\n",
    "    \n",
    "    if not options_files:\n",
    "        raise FileNotFoundError(\"No options data files found in ../data/options_data/\")\n",
    "    \n",
    "    print(f\"Found {len(options_files)} options data files:\")\n",
    "    \n",
    "    # Load and combine all files, checking for column consistency\n",
    "    dfs = []\n",
    "    for file in options_files:\n",
    "        df = pd.read_csv(file)\n",
    "        ticker_name = Path(file).stem.split('_')[0]\n",
    "        \n",
    "        # Check if ts_event column exists\n",
    "        if 'ts_event' not in df.columns:\n",
    "            print(f\"        {Path(file).name}: MISSING ts_event column - SKIPPING this file\")\n",
    "            print(f\"       (This file has {len(df):,} rows that will be excluded)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   OK - {Path(file).name}: {len(df):,} rows\")\n",
    "        dfs.append(df)\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No valid options data files found (all missing ts_event column)\")\n",
    "    \n",
    "    # Concatenate all valid dataframes\n",
    "    options_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Handle timestamp conversion\n",
    "    if 'ts_event' in options_df.columns:\n",
    "        options_df['date'] = pd.to_datetime(options_df['ts_event'])\n",
    "    elif 'date' in options_df.columns:\n",
    "        options_df['date'] = pd.to_datetime(options_df['date'])\n",
    "    else:\n",
    "        raise ValueError(\"No timestamp column found\")\n",
    "    \n",
    "    # Extract ticker from symbol if not present\n",
    "    if 'ticker' not in options_df.columns and 'symbol' in options_df.columns:\n",
    "        options_df['ticker'] = options_df['symbol'].str.strip().str.split().str[0]\n",
    "    \n",
    "    # Remove any rows with missing dates (should be none now)\n",
    "    initial_rows = len(options_df)\n",
    "    options_df = options_df[options_df['date'].notna()].copy()\n",
    "    dropped_rows = initial_rows - len(options_df)\n",
    "    \n",
    "    print(f\"\\n OPTIONS DATA LOADED\")\n",
    "    print(f\"   Shape: {options_df.shape}\")\n",
    "    print(f\"   Tickers: {sorted(options_df['ticker'].unique())}\")\n",
    "    print(f\"   Date range: {options_df['date'].min().date()} to {options_df['date'].max().date()}\")\n",
    "    print(f\"   Columns: {list(options_df.columns)}\")\n",
    "    if dropped_rows > 0:\n",
    "        print(f\"Dropped {dropped_rows:,} rows with missing timestamps\")\n",
    "    \n",
    "    # Check for NaN values in numerical columns\n",
    "    print(f\"\\n DATA QUALITY:\")\n",
    "    numerical_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    null_counts = options_df[numerical_cols].isnull().sum()\n",
    "    total_nulls = null_counts.sum()\n",
    "    \n",
    "    if total_nulls > 0:\n",
    "        print(f\"Found {total_nulls:,} NaN values in price/volume data:\")\n",
    "        for col, count in null_counts[null_counts > 0].items():\n",
    "            print(f\"      {col}: {count:,} ({count/len(options_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   No missing values in price/volume columns\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"\\n SAMPLE DATA (first 5 rows):\")\n",
    "    display(options_df.head(5)[['date', 'ticker', 'symbol', 'open', 'high', 'low', 'close', 'volume']])\n",
    "    \n",
    "    # Show statistics\n",
    "    print(f\"\\n SUMMARY STATS:\")\n",
    "    print(f\"   Records per ticker:\")\n",
    "    for ticker, count in options_df.groupby('ticker').size().sort_values(ascending=False).items():\n",
    "        print(f\"      {ticker}: {count:,}\")\n",
    "    print(f\"   Volume: min={options_df['volume'].min()}, max={options_df['volume'].max():,}, mean={options_df['volume'].mean():.1f}\")\n",
    "    print(f\"   Close: min=${options_df['close'].min():.2f}, max=${options_df['close'].max():.2f}, mean=${options_df['close'].mean():.2f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error loading options: {e}\")\n",
    "    print(\"   Check data files or re-run data acquisition\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    options_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df519bb",
   "metadata": {},
   "source": [
    "## 2. Underlying Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices_df is not None:\n",
    "    # Ticker coverage\n",
    "    ticker_counts = prices_df.groupby('ticker').size().sort_values(ascending=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Ticker coverage\n",
    "    ticker_counts.plot(kind='bar', ax=axes[0,0], color='steelblue')\n",
    "    axes[0,0].set_title('Data Points per Ticker', fontsize=14, fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Ticker')\n",
    "    axes[0,0].set_ylabel('Number of Trading Days')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Price distribution\n",
    "    axes[0,1].hist(prices_df['close'], bins=50, color='green', alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution of Stock Prices', fontsize=14, fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Price ($)')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # 3. Daily returns distribution\n",
    "    axes[1,0].hist(prices_df['return_1d'].dropna(), bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].set_title('Distribution of Daily Returns', fontsize=14, fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Daily Return')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # 4. Volatility over time\n",
    "    if 'volatility_30d' in prices_df.columns:\n",
    "        vol_data = prices_df[prices_df['volatility_30d'].notna()]\n",
    "        for ticker in vol_data['ticker'].unique()[:5]:  # Plot first 5 tickers\n",
    "            ticker_data = vol_data[vol_data['ticker'] == ticker].sort_values('date')\n",
    "            axes[1,1].plot(ticker_data['date'], ticker_data['volatility_30d'], label=ticker, alpha=0.7)\n",
    "        axes[1,1].set_title('30-Day Volatility Over Time (First 5 Tickers)', fontsize=14, fontweight='bold')\n",
    "        axes[1,1].set_xlabel('Date')\n",
    "        axes[1,1].set_ylabel('Volatility')\n",
    "        axes[1,1].legend(loc='best')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n PRICE STATISTICS:\")\n",
    "    print(f\"   Total records: {len(prices_df):,}\")\n",
    "    print(f\"   Unique tickers: {prices_df['ticker'].nunique()}\")\n",
    "    print(f\"   Avg trading days/ticker: {ticker_counts.mean():.0f}\")\n",
    "    print(f\"   Price range: ${prices_df['close'].min():.2f} - ${prices_df['close'].max():.2f}\")\n",
    "    if 'return_1d' in prices_df.columns:\n",
    "        print(f\"   Avg daily return: {prices_df['return_1d'].mean()*100:.3f}%\")\n",
    "        print(f\"   Daily return std: {prices_df['return_1d'].std()*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89756e85",
   "metadata": {},
   "source": [
    "## 3. Options Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9bd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if options_df is not None:\n",
    "    # Options characteristics\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # 1. Volume distribution (log scale)\n",
    "    axes[0,0].hist(np.log10(options_df['volume'] + 1), bins=50, color='purple', alpha=0.7, edgecolor='black')\n",
    "    axes[0,0].set_title('Options Volume Distribution (Log10)', fontsize=12, fontweight='bold')\n",
    "    axes[0,0].set_xlabel('Log10(Volume + 1)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 2. Volume by ticker\n",
    "    vol_by_ticker = options_df.groupby('ticker')['volume'].mean().sort_values(ascending=False)\n",
    "    vol_by_ticker.plot(kind='bar', ax=axes[0,1], color='teal')\n",
    "    axes[0,1].set_title('Average Volume by Ticker', fontsize=12, fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Ticker')\n",
    "    axes[0,1].set_ylabel('Avg Volume')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Records per ticker\n",
    "    records_by_ticker = options_df.groupby('ticker').size().sort_values(ascending=False)\n",
    "    records_by_ticker.plot(kind='bar', ax=axes[0,2], color='coral')\n",
    "    axes[0,2].set_title('Option Records by Ticker', fontsize=12, fontweight='bold')\n",
    "    axes[0,2].set_xlabel('Ticker')\n",
    "    axes[0,2].set_ylabel('Number of Records')\n",
    "    axes[0,2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Price distribution\n",
    "    axes[1,0].hist(options_df['close'], bins=50, color='blue', alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].set_title('Option Price Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Option Close Price')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # 5. Daily volume over time\n",
    "    daily_vol = options_df.groupby('date')['volume'].sum()\n",
    "    axes[1,1].plot(daily_vol.index, daily_vol.values, color='green', linewidth=2)\n",
    "    axes[1,1].set_title('Total Daily Options Volume', fontsize=12, fontweight='bold')\n",
    "    axes[1,1].set_xlabel('Date')\n",
    "    axes[1,1].set_ylabel('Total Volume')\n",
    "    axes[1,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 6. Options per day\n",
    "    opts_per_day = options_df.groupby('date').size()\n",
    "    axes[1,2].plot(opts_per_day.index, opts_per_day.values, color='red', linewidth=2)\n",
    "    axes[1,2].set_title('Options Records per Day', fontsize=12, fontweight='bold')\n",
    "    axes[1,2].set_xlabel('Date')\n",
    "    axes[1,2].set_ylabel('Number of Options')\n",
    "    axes[1,2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n OPTIONS STATISTICS:\")\n",
    "    print(f\"   Total option records: {len(options_df):,}\")\n",
    "    print(f\"   Unique tickers: {options_df['ticker'].nunique()}\")\n",
    "    print(f\"   Date range: {options_df['date'].nunique()} days\")\n",
    "    print(f\"   Avg options/day: {len(options_df) / options_df['date'].nunique():.0f}\")\n",
    "    print(f\"\\n   Volume Stats:\")\n",
    "    print(f\"      Mean: {options_df['volume'].mean():.1f}\")\n",
    "    print(f\"      Median: {options_df['volume'].median():.1f}\")\n",
    "    print(f\"      75th percentile: {options_df['volume'].quantile(0.75):.1f}\")\n",
    "    print(f\"      Max: {options_df['volume'].max():.0f}\")\n",
    "    print(f\"\\n   Price Stats:\")\n",
    "    print(f\"      Mean: ${options_df['close'].mean():.2f}\")\n",
    "    print(f\"      Median: ${options_df['close'].median():.2f}\")\n",
    "    print(f\"      Range: ${options_df['close'].min():.2f} - ${options_df['close'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1ad8d",
   "metadata": {},
   "source": [
    "## 4. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices_df is not None and options_df is not None:\n",
    "    print(\"=\"*70)\n",
    "    print(\"DATA QUALITY REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Underlying prices quality\n",
    "    print(\"\\n UNDERLYING PRICES:\")\n",
    "    print(f\"   Shape: {prices_df.shape}\")\n",
    "    print(f\"   Missing values: {prices_df.isnull().sum().sum()} ({prices_df.isnull().sum().sum()/prices_df.size*100:.2f}%)\")\n",
    "    print(f\"   Tickers: {prices_df['ticker'].nunique()}\")\n",
    "    print(f\"   Date coverage: {prices_df['date'].nunique()} days\")\n",
    "    \n",
    "    missing_by_col = prices_df.isnull().sum()\n",
    "    if missing_by_col.sum() > 0:\n",
    "        print(f\"\\n   Missing by column:\")\n",
    "        for col, count in missing_by_col[missing_by_col > 0].items():\n",
    "            print(f\"      {col}: {count}\")\n",
    "    \n",
    "    # Options data quality\n",
    "    print(f\"\\n OPTIONS DATA:\")\n",
    "    print(f\"   Shape: {options_df.shape}\")\n",
    "    print(f\"   Missing values: {options_df.isnull().sum().sum()} ({options_df.isnull().sum().sum()/options_df.size*100:.2f}%)\")\n",
    "    print(f\"   Tickers: {options_df['ticker'].nunique()}\")\n",
    "    print(f\"   Date coverage: {options_df['date'].nunique()} days\")\n",
    "    \n",
    "    # Liquidity assessment\n",
    "    liquid_threshold = 10  # Min volume for \"liquid\" options\n",
    "    liquid_count = (options_df['volume'] >= liquid_threshold).sum()\n",
    "    print(f\"\\n LIQUIDITY:\")\n",
    "    print(f\"   Options with volume ≥ {liquid_threshold}: {liquid_count:,} ({liquid_count/len(options_df)*100:.1f}%)\")\n",
    "    print(f\"   Options with volume < {liquid_threshold}: {len(options_df)-liquid_count:,}\")\n",
    "    \n",
    "    # Data completeness\n",
    "    print(f\"\\n COMPLETENESS:\")\n",
    "    expected_combos = prices_df['ticker'].nunique() * prices_df['date'].nunique()\n",
    "    actual_prices = len(prices_df)\n",
    "    print(f\"   Underlying: {actual_prices}/{expected_combos} ({actual_prices/expected_combos*100:.1f}%)\")\n",
    "    \n",
    "    # Symbol check if available\n",
    "    if 'symbol' in options_df.columns:\n",
    "        print(f\"\\n OPTIONS CONTRACTS:\")\n",
    "        print(f\"   Unique symbols: {options_df['symbol'].nunique():,}\")\n",
    "        print(f\"   Sample symbols: {list(options_df['symbol'].head(3))}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" Data quality check complete!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b8243",
   "metadata": {},
   "source": [
    "## 5. Export Summary\n",
    "\n",
    "Save a summary of your data for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd1164",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prices_df is not None and options_df is not None:\n",
    "    # Create summary dataframe\n",
    "    summary = {\n",
    "        'Metric': [],\n",
    "        'Value': []\n",
    "    }\n",
    "    \n",
    "    # Add metrics\n",
    "    summary['Metric'].extend([\n",
    "        'Underlying Records',\n",
    "        'Options Records',\n",
    "        'Tickers',\n",
    "        'Date Range Start',\n",
    "        'Date Range End',\n",
    "        'Trading Days',\n",
    "        'Avg Options Volume',\n",
    "        'Liquid Options %',\n",
    "        'Missing Data %'\n",
    "    ])\n",
    "    \n",
    "    liquid_pct = (options_df['volume'] >= 10).sum() / len(options_df) * 100\n",
    "    missing_pct = (prices_df.isnull().sum().sum() + options_df.isnull().sum().sum()) / (prices_df.size + options_df.size) * 100\n",
    "    \n",
    "    summary['Value'].extend([\n",
    "        f\"{len(prices_df):,}\",\n",
    "        f\"{len(options_df):,}\",\n",
    "        f\"{prices_df['ticker'].nunique()}\",\n",
    "        str(prices_df['date'].min().date()),\n",
    "        str(prices_df['date'].max().date()),\n",
    "        f\"{prices_df['date'].nunique()}\",\n",
    "        f\"{options_df['volume'].mean():.1f}\",\n",
    "        f\"{liquid_pct:.1f}%\",\n",
    "        f\"{missing_pct:.2f}%\"\n",
    "    ])\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    \n",
    "    # Save summary\n",
    "    summary_file = '../data/data_summary.csv'\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    \n",
    "    print(\" Data Summary:\")\n",
    "    display(summary_df)\n",
    "    print(f\"\\n Summary saved to: {summary_file}\")\n",
    "else:\n",
    "    print(\" Cannot generate summary - data not loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
