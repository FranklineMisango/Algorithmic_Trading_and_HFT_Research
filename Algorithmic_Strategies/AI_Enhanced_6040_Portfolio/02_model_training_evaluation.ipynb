{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91819e80",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "This notebook covers the machine learning model training process for the AI-enhanced 60/40 portfolio strategy.\n",
    "\n",
    "## Objectives:\n",
    "1. Engineer features from economic indicators\n",
    "2. Train decision tree models for each asset\n",
    "3. Evaluate model performance\n",
    "4. Analyze feature importance\n",
    "5. Validate with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from sklearn.tree import plot_tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from data_acquisition import DataAcquisition\n",
    "from feature_engineering import FeatureEngineer\n",
    "from ml_model import PortfolioMLModel\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853b46d",
   "metadata": {},
   "source": [
    "## 1. Load Data and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34ef57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Fetch data\n",
    "data_acq = DataAcquisition(config)\n",
    "prices, returns, indicators = data_acq.get_full_dataset()\n",
    "\n",
    "print(f\"Data loaded: {len(prices)} periods from {prices.index[0]} to {prices.index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6564db",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d496da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "feature_eng = FeatureEngineer(config)\n",
    "\n",
    "# Create all features\n",
    "print(\"Engineering features...\")\n",
    "features_raw = feature_eng.engineer_all_features(indicators)\n",
    "print(f\"Raw features created: {features_raw.shape}\")\n",
    "\n",
    "# Prepare features for training\n",
    "features = feature_eng.prepare_features_for_training(features_raw)\n",
    "print(f\"Prepared features: {features.shape}\")\n",
    "print(f\"Feature columns: {len(features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample features\n",
    "print(\"Sample of engineered features:\")\n",
    "display(features.head())\n",
    "\n",
    "print(\"\\nFeature columns:\")\n",
    "for i, col in enumerate(features.columns, 1):\n",
    "    print(f\"{i:3d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69149f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature correlations (sample)\n",
    "sample_features = features[[col for col in features.columns if 'VIX' in col or 'Spread' in col or 'Rate' in col][:10]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "corr = sample_features.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, ax=ax, cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Sample Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d222cbce",
   "metadata": {},
   "source": [
    "## 3. Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML model\n",
    "ml_model = PortfolioMLModel(config)\n",
    "\n",
    "# Create target variables (next period returns)\n",
    "targets = ml_model.create_target_variables(returns, lookback=1)\n",
    "\n",
    "print(f\"Targets created: {targets.shape}\")\n",
    "print(f\"\\nTarget assets: {list(targets.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db93927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = ml_model.prepare_train_test_data(\n",
    "    features, \n",
    "    targets,\n",
    "    test_size=config['model']['validation']['test_size']\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"  From {X_train.index[0]} to {X_train.index[-1]}\")\n",
    "print(f\"\\nTest set: {X_test.shape}\")\n",
    "print(f\"  From {X_test.index[0]} to {X_test.index[-1]}\")\n",
    "\n",
    "print(f\"\\nTrain/Test split: {len(X_train)}/{len(X_test)} ({len(X_train)/(len(X_train)+len(X_test)):.1%}/{len(X_test)/(len(X_train)+len(X_test)):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e1b78",
   "metadata": {},
   "source": [
    "## 4. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f54771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for all assets\n",
    "models = ml_model.train_all_models(X_train, y_train)\n",
    "\n",
    "print(f\"\\nTrained {len(models)} models\")\n",
    "print(f\"Model type: {type(list(models.values())[0]).__name__}\")\n",
    "print(f\"Model parameters: {ml_model.model_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training history\n",
    "print(\"Training performance:\")\n",
    "training_df = pd.DataFrame(ml_model.training_history).T\n",
    "display(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e360ceab",
   "metadata": {},
   "source": [
    "## 5. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efe6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "evaluation_results = ml_model.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "print(\"\\nDetailed evaluation results:\")\n",
    "display(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5946cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize evaluation metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_to_plot = ['rmse', 'mae', 'r2', 'directional_accuracy']\n",
    "titles = ['RMSE', 'MAE', 'R² Score', 'Directional Accuracy']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics_to_plot, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    values = evaluation_results[metric]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(values)))\n",
    "    \n",
    "    bars = ax.bar(range(len(values)), values, color=colors, edgecolor='black')\n",
    "    ax.set_xticks(range(len(values)))\n",
    "    ax.set_xticklabels(values.index, rotation=45, ha='right')\n",
    "    ax.set_ylabel(title, fontsize=11)\n",
    "    ax.set_title(f'{title} by Asset', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, values)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bc7cc",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9831c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance for each asset\n",
    "print(\"Top 15 features by importance:\\n\")\n",
    "\n",
    "for asset, importance in ml_model.feature_importance.items():\n",
    "    print(f\"\\n{asset}:\")\n",
    "    print(importance.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f84c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance for all assets\n",
    "n_assets = len(ml_model.feature_importance)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (asset, importance) in enumerate(ml_model.feature_importance.items()):\n",
    "    if idx < len(axes):\n",
    "        top_features = importance.head(15)\n",
    "        \n",
    "        axes[idx].barh(range(len(top_features)), top_features.values, color='steelblue', edgecolor='black')\n",
    "        axes[idx].set_yticks(range(len(top_features)))\n",
    "        axes[idx].set_yticklabels(top_features.index, fontsize=9)\n",
    "        axes[idx].set_xlabel('Importance', fontsize=10)\n",
    "        axes[idx].set_title(f'Top 15 Features - {asset}', fontsize=11, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "        axes[idx].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate feature importance across all assets\n",
    "all_importance = pd.DataFrame(ml_model.feature_importance)\n",
    "avg_importance = all_importance.mean(axis=1).sort_values(ascending=False)\n",
    "\n",
    "print(\"Average feature importance across all assets:\")\n",
    "print(avg_importance.head(20))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_avg = avg_importance.head(20)\n",
    "ax.barh(range(len(top_avg)), top_avg.values, color='coral', edgecolor='black')\n",
    "ax.set_yticks(range(len(top_avg)))\n",
    "ax.set_yticklabels(top_avg.index, fontsize=10)\n",
    "ax.set_xlabel('Average Importance', fontsize=12)\n",
    "ax.set_title('Top 20 Features - Average Across All Assets', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036b620",
   "metadata": {},
   "source": [
    "## 7. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "predictions = ml_model.predict_returns(X_test)\n",
    "\n",
    "print(\"Predictions shape:\", predictions.shape)\n",
    "print(\"\\nSample predictions:\")\n",
    "display(predictions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a557c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions vs actual returns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, asset in enumerate(y_test.columns):\n",
    "    if idx < len(axes):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(y_test[asset], predictions[asset], alpha=0.6, s=30)\n",
    "        \n",
    "        # Add diagonal line (perfect prediction)\n",
    "        min_val = min(y_test[asset].min(), predictions[asset].min())\n",
    "        max_val = max(y_test[asset].max(), predictions[asset].max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "        \n",
    "        # Calculate R²\n",
    "        from sklearn.metrics import r2_score\n",
    "        r2 = r2_score(y_test[asset], predictions[asset])\n",
    "        \n",
    "        ax.set_xlabel('Actual Returns', fontsize=11)\n",
    "        ax.set_ylabel('Predicted Returns', fontsize=11)\n",
    "        ax.set_title(f'{asset} - Predictions vs Actual (R²={r2:.3f})', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series of predictions vs actuals\n",
    "fig, axes = plt.subplots(len(y_test.columns), 1, figsize=(14, 12))\n",
    "\n",
    "for idx, asset in enumerate(y_test.columns):\n",
    "    axes[idx].plot(y_test.index, y_test[asset], label='Actual', linewidth=2, alpha=0.7)\n",
    "    axes[idx].plot(predictions.index, predictions[asset], label='Predicted', \n",
    "                  linewidth=2, alpha=0.7, linestyle='--')\n",
    "    axes[idx].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    axes[idx].set_ylabel('Returns', fontsize=10)\n",
    "    axes[idx].set_title(f'{asset} - Predictions Over Time', fontsize=11, fontweight='bold')\n",
    "    axes[idx].legend(fontsize=9)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Date', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c7484",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time series cross-validation\n",
    "print(\"Performing cross-validation...\")\n",
    "cv_scores = ml_model.cross_validate(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=config['model']['validation']['cv_folds']\n",
    ")\n",
    "\n",
    "print(\"\\nCross-validation results:\")\n",
    "cv_df = pd.DataFrame(cv_scores).T\n",
    "display(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf6f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "assets = list(cv_scores.keys())\n",
    "means = [cv_scores[asset]['mean_mse'] for asset in assets]\n",
    "stds = [cv_scores[asset]['std_mse'] for asset in assets]\n",
    "\n",
    "x_pos = np.arange(len(assets))\n",
    "ax.bar(x_pos, means, yerr=stds, capsize=5, color='skyblue', edgecolor='black', alpha=0.8)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(assets, rotation=45, ha='right')\n",
    "ax.set_ylabel('Mean Squared Error', fontsize=12)\n",
    "ax.set_title('Cross-Validation Scores (with std dev)', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c994aa37",
   "metadata": {},
   "source": [
    "## 9. Model Visualization (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision tree structure for one asset (limited depth for readability)\n",
    "sample_asset = list(models.keys())[0]\n",
    "sample_model = models[sample_asset]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_tree(sample_model, \n",
    "          feature_names=X_train.columns,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=8,\n",
    "          max_depth=3,  # Limit depth for visualization\n",
    "          ax=ax)\n",
    "ax.set_title(f'Decision Tree Structure - {sample_asset} (Depth Limited to 3)', \n",
    "            fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Note: Full tree has depth {sample_model.get_depth()}\")\n",
    "print(f\"Number of leaves: {sample_model.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceda4b6",
   "metadata": {},
   "source": [
    "## 10. Key Findings\n",
    "\n",
    "### Model Performance:\n",
    "- Decision tree models show varying performance across assets\n",
    "- Directional accuracy is particularly important for portfolio allocation\n",
    "- Feature importance reveals which economic indicators drive predictions\n",
    "\n",
    "### Important Features:\n",
    "- VIX and its derivatives consistently rank high\n",
    "- Yield spread changes provide valuable signals\n",
    "- Interaction features capture complex market dynamics\n",
    "\n",
    "### Next Steps:\n",
    "1. Use these models to generate portfolio allocations\n",
    "2. Backtest the complete strategy\n",
    "3. Compare against traditional benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6476bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "ml_model.save_models(config['output']['models_dir'])\n",
    "print(f\"Models saved to {config['output']['models_dir']}/\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
