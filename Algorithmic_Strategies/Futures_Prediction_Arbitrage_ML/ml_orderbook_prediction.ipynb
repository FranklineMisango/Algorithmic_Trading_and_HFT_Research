{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73822b7a",
   "metadata": {},
   "source": [
    "# ML-Based Short-Term Futures Price Prediction Using Order Book Data\n",
    "\n",
    "This notebook implements a machine learning pipeline to predict short-term futures prices using real-time order book data fetched via WebSocket connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331d7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LD_LIBRARY_PATH for GPU support (run this cell first if GPU not detected)\n",
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = os.environ.get('CONDA_PREFIX', '') + '/lib:' + os.environ.get('LD_LIBRARY_PATH', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad023094",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import libraries for data fetching, processing, and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98ab734",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-19 00:36:39.916776: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import websocket\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import threading\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fba689",
   "metadata": {},
   "source": [
    "### GPU Availability Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3718c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ada8e",
   "metadata": {},
   "source": [
    "## 2.5 Start Background Data Fetcher\n",
    "\n",
    "Run the separate data fetcher script to collect real-time order book data in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fetcher_script = 'data_fetcher.py'\n",
    "if os.path.exists(fetcher_script):\n",
    "    print(\"Starting background data fetcher...\")\n",
    "    process = subprocess.Popen(['python', fetcher_script], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(f\"Data fetcher started with PID: {process.pid}\")\n",
    "    print(\"It will collect data to 'live_order_book_data.csv'\")\n",
    "else:\n",
    "    print(f\"Data fetcher script '{fetcher_script}' not found. Please ensure it's in the same directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b9ed8",
   "metadata": {},
   "source": [
    "# Kill If you wanna terminate live data fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pkill -f data_fetcher.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb7f0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 243776 records from live_order_book_data.csv\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[4], line 13\u001b[0m\n    df['bid_quantities'] = df['bid_quantities'].apply(ast.literal_eval)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/pandas/core/series.py:4943\u001b[0m in \u001b[1;35mapply\u001b[0m\n    ).apply()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m in \u001b[1;35mapply\u001b[0m\n    return self.apply_standard()\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m in \u001b[1;35mapply_standard\u001b[0m\n    mapped = obj._map_values(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m in \u001b[1;35m_map_values\u001b[0m\n    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m in \u001b[1;35mmap_array\u001b[0m\n    return lib.map_infer(values, mapper, convert=convert)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32mpandas/_libs/lib.pyx:2999\u001b[0m in \u001b[1;35mpandas._libs.lib.map_infer\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/anaconda3/envs/research_env/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/anaconda3/envs/research_env/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    [23.186, 0.024, 0.004, 0.092, 0.011, 0.002, 0.005, 0.005, 0.089, 0.003, 0.002, 0.003, 0.079, 0.089, 0.003, 0.002, 0.003, 0.002,$0.096, 0.006]\u001b[0m\n\u001b[0m                                                                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load data from background fetcher\n",
    "DATA_FILE = 'live_order_book_data.csv'\n",
    "\n",
    "if os.path.exists(DATA_FILE):\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    print(f\"Loaded {len(df)} records from {DATA_FILE}\")\n",
    "    # Ensure timestamp is datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    # Parse string columns back to lists\n",
    "    import ast\n",
    "    df['bid_prices'] = df['bid_prices'].apply(ast.literal_eval)\n",
    "    df['bid_quantities'] = df['bid_quantities'].apply(ast.literal_eval)\n",
    "    df['ask_prices'] = df['ask_prices'].apply(ast.literal_eval)\n",
    "    df['ask_quantities'] = df['ask_quantities'].apply(ast.literal_eval)\n",
    "    \n",
    "    # Data Validation\n",
    "    print(\"Performing data validation...\")\n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['timestamp']).sum()\n",
    "    print(f\"Duplicate timestamps: {duplicates}\")\n",
    "    if duplicates > 0:\n",
    "        df = df.drop_duplicates(subset=['timestamp'])\n",
    "    \n",
    "    # Check for missing or invalid lists\n",
    "    def validate_lists(row):\n",
    "        try:\n",
    "            if not isinstance(row['bid_prices'], list) or not isinstance(row['ask_prices'], list):\n",
    "                return False\n",
    "            if len(row['bid_prices']) == 0 or len(row['ask_prices']) == 0:\n",
    "                return False\n",
    "            # Check monotonicity (bids descending, asks ascending)\n",
    "            if row['bid_prices'] != sorted(row['bid_prices'], reverse=True):\n",
    "                return False\n",
    "            if row['ask_prices'] != sorted(row['ask_prices']):\n",
    "                return False\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    valid_mask = df.apply(validate_lists, axis=1)\n",
    "    invalid_count = (~valid_mask).sum()\n",
    "    print(f\"Invalid order book entries: {invalid_count}\")\n",
    "    df = df[valid_mask]\n",
    "    \n",
    "    # Outlier detection for mid_price\n",
    "    df['temp_mid_price'] = df.apply(lambda row: (row['bid_prices'][0] + row['ask_prices'][0]) / 2, axis=1)\n",
    "    q1 = df['temp_mid_price'].quantile(0.25)\n",
    "    q3 = df['temp_mid_price'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = ((df['temp_mid_price'] < lower_bound) | (df['temp_mid_price'] > upper_bound)).sum()\n",
    "    print(f\"Price outliers detected: {outliers}\")\n",
    "    df = df[(df['temp_mid_price'] >= lower_bound) & (df['temp_mid_price'] <= upper_bound)]\n",
    "    df = df.drop(columns=['temp_mid_price'])\n",
    "    \n",
    "    print(f\"Data after validation: {len(df)} records\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Data file {DATA_FILE} not found. Please run the background data fetcher first.\")\n",
    "    df = pd.DataFrame()  # Empty dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9425f7",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering from Order Book Data\n",
    "\n",
    "Compute features like bid-ask imbalance, mid-price, spread, and volatility metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24aa45cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after optimized feature engineering: ['timestamp', 'bids', 'asks', 'lastUpdateId', 'bid_prices', 'bid_quantities', 'ask_prices', 'ask_quantities', 'mid_price', 'spread', 'imbalance', 'weighted_mid_price', 'bid_cum_volume', 'ask_cum_volume', 'bid_slope', 'ask_slope', 'depth', 'liquidity_ratio', 'mid_price_volatility', 'price_change', 'order_book_image']\n",
      "Shape: (241432, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bids</th>\n",
       "      <th>asks</th>\n",
       "      <th>lastUpdateId</th>\n",
       "      <th>bid_prices</th>\n",
       "      <th>bid_quantities</th>\n",
       "      <th>ask_prices</th>\n",
       "      <th>ask_quantities</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>spread</th>\n",
       "      <th>...</th>\n",
       "      <th>weighted_mid_price</th>\n",
       "      <th>bid_cum_volume</th>\n",
       "      <th>ask_cum_volume</th>\n",
       "      <th>bid_slope</th>\n",
       "      <th>ask_slope</th>\n",
       "      <th>depth</th>\n",
       "      <th>liquidity_ratio</th>\n",
       "      <th>mid_price_volatility</th>\n",
       "      <th>price_change</th>\n",
       "      <th>order_book_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-27 05:20:22.563871</td>\n",
       "      <td>[['89781.50', '2.809'], ['89781.40', '0.014'],...</td>\n",
       "      <td>[['89781.60', '8.184'], ['89781.70', '0.405'],...</td>\n",
       "      <td>9316990205736</td>\n",
       "      <td>[89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...</td>\n",
       "      <td>[2.809, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...</td>\n",
       "      <td>[89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...</td>\n",
       "      <td>[8.184, 0.405, 0.015, 0.002, 0.003, 0.002, 0.0...</td>\n",
       "      <td>89781.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.451307</td>\n",
       "      <td>4.746</td>\n",
       "      <td>8.708</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>0.180606</td>\n",
       "      <td>13.454</td>\n",
       "      <td>0.545016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.809, 8.184], [0.014, 0.405], [0.003, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-27 05:20:22.665831</td>\n",
       "      <td>[['89781.50', '2.823'], ['89781.40', '0.014'],...</td>\n",
       "      <td>[['89781.60', '8.177'], ['89781.70', '0.405'],...</td>\n",
       "      <td>9316990211012</td>\n",
       "      <td>[89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...</td>\n",
       "      <td>[2.823, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...</td>\n",
       "      <td>[89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...</td>\n",
       "      <td>[8.177, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...</td>\n",
       "      <td>89781.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.451690</td>\n",
       "      <td>4.760</td>\n",
       "      <td>8.704</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>0.158182</td>\n",
       "      <td>13.464</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.823, 8.177], [0.014, 0.405], [0.003, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-27 05:20:22.768242</td>\n",
       "      <td>[['89781.50', '2.837'], ['89781.40', '0.014'],...</td>\n",
       "      <td>[['89781.60', '8.175'], ['89781.70', '0.405'],...</td>\n",
       "      <td>9316990215488</td>\n",
       "      <td>[89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...</td>\n",
       "      <td>[2.837, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...</td>\n",
       "      <td>[89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...</td>\n",
       "      <td>[8.175, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...</td>\n",
       "      <td>89781.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.452376</td>\n",
       "      <td>4.773</td>\n",
       "      <td>8.702</td>\n",
       "      <td>-0.198182</td>\n",
       "      <td>0.158182</td>\n",
       "      <td>13.475</td>\n",
       "      <td>0.548495</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.837, 8.175], [0.014, 0.405], [0.003, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-27 05:20:22.973001</td>\n",
       "      <td>[['89781.50', '2.237'], ['89781.40', '0.014'],...</td>\n",
       "      <td>[['89781.60', '8.177'], ['89781.70', '0.405'],...</td>\n",
       "      <td>9316990222999</td>\n",
       "      <td>[89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...</td>\n",
       "      <td>[2.237, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...</td>\n",
       "      <td>[89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...</td>\n",
       "      <td>[8.177, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...</td>\n",
       "      <td>89781.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.436523</td>\n",
       "      <td>4.174</td>\n",
       "      <td>8.706</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>0.158182</td>\n",
       "      <td>12.880</td>\n",
       "      <td>0.479439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.237, 8.177], [0.014, 0.405], [0.003, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-27 05:20:23.075444</td>\n",
       "      <td>[['89781.50', '2.008'], ['89781.40', '0.014'],...</td>\n",
       "      <td>[['89781.60', '8.182'], ['89781.70', '0.405'],...</td>\n",
       "      <td>9316990229087</td>\n",
       "      <td>[89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...</td>\n",
       "      <td>[2.008, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...</td>\n",
       "      <td>[89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...</td>\n",
       "      <td>[8.182, 0.405, 0.015, 0.002, 0.003, 0.002, 0.0...</td>\n",
       "      <td>89781.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.429258</td>\n",
       "      <td>3.945</td>\n",
       "      <td>8.708</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>0.180606</td>\n",
       "      <td>12.653</td>\n",
       "      <td>0.453032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>[[2.008, 8.182], [0.014, 0.405], [0.003, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-27 05:20:23.280298</td>\n",
       "      <td>[['89781.00', '2.239'], ['89780.90', '0.002'],...</td>\n",
       "      <td>[['89781.10', '22.079'], ['89781.20', '0.006']...</td>\n",
       "      <td>9316990260974</td>\n",
       "      <td>[89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...</td>\n",
       "      <td>[2.239, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...</td>\n",
       "      <td>[89781.1, 89781.2, 89781.5, 89781.6, 89781.7, ...</td>\n",
       "      <td>[22.079, 0.006, 2.032, 1.418, 0.037, 0.002, 0....</td>\n",
       "      <td>89781.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.062613</td>\n",
       "      <td>2.363</td>\n",
       "      <td>25.585</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.187879</td>\n",
       "      <td>27.948</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[2.239, 22.079], [0.002, 0.006], [0.05, 2.032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-27 05:20:23.280657</td>\n",
       "      <td>[['89781.00', '3.841'], ['89780.90', '0.002'],...</td>\n",
       "      <td>[['89781.10', '18.706'], ['89781.20', '0.006']...</td>\n",
       "      <td>9316990270741</td>\n",
       "      <td>[89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...</td>\n",
       "      <td>[3.841, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...</td>\n",
       "      <td>[89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...</td>\n",
       "      <td>[18.706, 0.006, 0.07, 0.179, 0.8, 1.122, 0.022...</td>\n",
       "      <td>89781.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.062526</td>\n",
       "      <td>3.965</td>\n",
       "      <td>20.912</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>24.877</td>\n",
       "      <td>0.189604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[3.841, 18.706], [0.002, 0.006], [0.05, 0.07]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11-27 05:20:23.485151</td>\n",
       "      <td>[['89781.00', '5.998'], ['89780.90', '0.002'],...</td>\n",
       "      <td>[['89781.10', '17.984'], ['89781.20', '0.006']...</td>\n",
       "      <td>9316990279735</td>\n",
       "      <td>[89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...</td>\n",
       "      <td>[5.998, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...</td>\n",
       "      <td>[89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...</td>\n",
       "      <td>[17.984, 0.006, 0.07, 0.179, 0.8, 1.032, 0.022...</td>\n",
       "      <td>89781.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.068053</td>\n",
       "      <td>6.122</td>\n",
       "      <td>20.192</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>26.314</td>\n",
       "      <td>0.303189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[5.998, 17.984], [0.002, 0.006], [0.05, 0.07]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-11-27 05:20:23.590558</td>\n",
       "      <td>[['89781.00', '5.084'], ['89780.90', '0.002'],...</td>\n",
       "      <td>[['89781.10', '17.984'], ['89781.20', '0.006']...</td>\n",
       "      <td>9316990286420</td>\n",
       "      <td>[89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...</td>\n",
       "      <td>[5.084, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...</td>\n",
       "      <td>[89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...</td>\n",
       "      <td>[17.984, 0.006, 0.072, 0.314, 0.8, 1.032, 0.02...</td>\n",
       "      <td>89781.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.067678</td>\n",
       "      <td>5.208</td>\n",
       "      <td>20.329</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>25.537</td>\n",
       "      <td>0.256186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[5.084, 17.984], [0.002, 0.006], [0.05, 0.072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-11-27 05:20:23.689427</td>\n",
       "      <td>[['89781.00', '1.697'], ['89780.90', '0.002'],...</td>\n",
       "      <td>[['89781.10', '18.333'], ['89781.20', '0.006']...</td>\n",
       "      <td>9316990296059</td>\n",
       "      <td>[89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...</td>\n",
       "      <td>[1.697, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...</td>\n",
       "      <td>[89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...</td>\n",
       "      <td>[18.333, 0.006, 0.074, 0.314, 0.8, 1.032, 0.02...</td>\n",
       "      <td>89781.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>89781.052143</td>\n",
       "      <td>1.821</td>\n",
       "      <td>20.680</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.141818</td>\n",
       "      <td>22.501</td>\n",
       "      <td>0.088056</td>\n",
       "      <td>0.263523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[1.697, 18.333], [0.002, 0.006], [0.05, 0.074...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  \\\n",
       "0 2025-11-27 05:20:22.563871   \n",
       "1 2025-11-27 05:20:22.665831   \n",
       "2 2025-11-27 05:20:22.768242   \n",
       "3 2025-11-27 05:20:22.973001   \n",
       "4 2025-11-27 05:20:23.075444   \n",
       "5 2025-11-27 05:20:23.280298   \n",
       "6 2025-11-27 05:20:23.280657   \n",
       "7 2025-11-27 05:20:23.485151   \n",
       "8 2025-11-27 05:20:23.590558   \n",
       "9 2025-11-27 05:20:23.689427   \n",
       "\n",
       "                                                bids  \\\n",
       "0  [['89781.50', '2.809'], ['89781.40', '0.014'],...   \n",
       "1  [['89781.50', '2.823'], ['89781.40', '0.014'],...   \n",
       "2  [['89781.50', '2.837'], ['89781.40', '0.014'],...   \n",
       "3  [['89781.50', '2.237'], ['89781.40', '0.014'],...   \n",
       "4  [['89781.50', '2.008'], ['89781.40', '0.014'],...   \n",
       "5  [['89781.00', '2.239'], ['89780.90', '0.002'],...   \n",
       "6  [['89781.00', '3.841'], ['89780.90', '0.002'],...   \n",
       "7  [['89781.00', '5.998'], ['89780.90', '0.002'],...   \n",
       "8  [['89781.00', '5.084'], ['89780.90', '0.002'],...   \n",
       "9  [['89781.00', '1.697'], ['89780.90', '0.002'],...   \n",
       "\n",
       "                                                asks   lastUpdateId  \\\n",
       "0  [['89781.60', '8.184'], ['89781.70', '0.405'],...  9316990205736   \n",
       "1  [['89781.60', '8.177'], ['89781.70', '0.405'],...  9316990211012   \n",
       "2  [['89781.60', '8.175'], ['89781.70', '0.405'],...  9316990215488   \n",
       "3  [['89781.60', '8.177'], ['89781.70', '0.405'],...  9316990222999   \n",
       "4  [['89781.60', '8.182'], ['89781.70', '0.405'],...  9316990229087   \n",
       "5  [['89781.10', '22.079'], ['89781.20', '0.006']...  9316990260974   \n",
       "6  [['89781.10', '18.706'], ['89781.20', '0.006']...  9316990270741   \n",
       "7  [['89781.10', '17.984'], ['89781.20', '0.006']...  9316990279735   \n",
       "8  [['89781.10', '17.984'], ['89781.20', '0.006']...  9316990286420   \n",
       "9  [['89781.10', '18.333'], ['89781.20', '0.006']...  9316990296059   \n",
       "\n",
       "                                          bid_prices  \\\n",
       "0  [89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...   \n",
       "1  [89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...   \n",
       "2  [89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...   \n",
       "3  [89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...   \n",
       "4  [89781.5, 89781.4, 89781.1, 89781.0, 89780.8, ...   \n",
       "5  [89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...   \n",
       "6  [89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...   \n",
       "7  [89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...   \n",
       "8  [89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...   \n",
       "9  [89781.0, 89780.9, 89780.8, 89780.6, 89780.1, ...   \n",
       "\n",
       "                                      bid_quantities  \\\n",
       "0  [2.809, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...   \n",
       "1  [2.823, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...   \n",
       "2  [2.837, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...   \n",
       "3  [2.237, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...   \n",
       "4  [2.008, 0.014, 0.003, 1.805, 0.05, 0.005, 0.00...   \n",
       "5  [2.239, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...   \n",
       "6  [3.841, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...   \n",
       "7  [5.998, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...   \n",
       "8  [5.084, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...   \n",
       "9  [1.697, 0.002, 0.05, 0.005, 0.003, 0.052, 0.00...   \n",
       "\n",
       "                                          ask_prices  \\\n",
       "0  [89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...   \n",
       "1  [89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...   \n",
       "2  [89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...   \n",
       "3  [89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...   \n",
       "4  [89781.6, 89781.7, 89781.8, 89782.0, 89782.1, ...   \n",
       "5  [89781.1, 89781.2, 89781.5, 89781.6, 89781.7, ...   \n",
       "6  [89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...   \n",
       "7  [89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...   \n",
       "8  [89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...   \n",
       "9  [89781.1, 89781.2, 89781.3, 89781.4, 89781.5, ...   \n",
       "\n",
       "                                      ask_quantities  mid_price  spread  ...  \\\n",
       "0  [8.184, 0.405, 0.015, 0.002, 0.003, 0.002, 0.0...   89781.55     0.1  ...   \n",
       "1  [8.177, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...   89781.55     0.1  ...   \n",
       "2  [8.175, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...   89781.55     0.1  ...   \n",
       "3  [8.177, 0.405, 0.015, 0.002, 0.003, 0.005, 0.0...   89781.55     0.1  ...   \n",
       "4  [8.182, 0.405, 0.015, 0.002, 0.003, 0.002, 0.0...   89781.55     0.1  ...   \n",
       "5  [22.079, 0.006, 2.032, 1.418, 0.037, 0.002, 0....   89781.05     0.1  ...   \n",
       "6  [18.706, 0.006, 0.07, 0.179, 0.8, 1.122, 0.022...   89781.05     0.1  ...   \n",
       "7  [17.984, 0.006, 0.07, 0.179, 0.8, 1.032, 0.022...   89781.05     0.1  ...   \n",
       "8  [17.984, 0.006, 0.072, 0.314, 0.8, 1.032, 0.02...   89781.05     0.1  ...   \n",
       "9  [18.333, 0.006, 0.074, 0.314, 0.8, 1.032, 0.02...   89781.05     0.1  ...   \n",
       "\n",
       "   weighted_mid_price  bid_cum_volume  ask_cum_volume  bid_slope  ask_slope  \\\n",
       "0        89781.451307           4.746           8.708  -0.226667   0.180606   \n",
       "1        89781.451690           4.760           8.704  -0.226667   0.158182   \n",
       "2        89781.452376           4.773           8.702  -0.198182   0.158182   \n",
       "3        89781.436523           4.174           8.706  -0.226667   0.158182   \n",
       "4        89781.429258           3.945           8.708  -0.226667   0.180606   \n",
       "5        89781.062613           2.363          25.585  -0.200000   0.187879   \n",
       "6        89781.062526           3.965          20.912  -0.200000   0.141818   \n",
       "7        89781.068053           6.122          20.192  -0.200000   0.141818   \n",
       "8        89781.067678           5.208          20.329  -0.200000   0.141818   \n",
       "9        89781.052143           1.821          20.680  -0.200000   0.141818   \n",
       "\n",
       "    depth  liquidity_ratio  mid_price_volatility  price_change  \\\n",
       "0  13.454         0.545016                   NaN           0.0   \n",
       "1  13.464         0.546875                   NaN           0.0   \n",
       "2  13.475         0.548495                   NaN           0.0   \n",
       "3  12.880         0.479439                   NaN           0.0   \n",
       "4  12.653         0.453032                   NaN          -0.5   \n",
       "5  27.948         0.092359                   NaN           0.0   \n",
       "6  24.877         0.189604                   NaN           0.0   \n",
       "7  26.314         0.303189                   NaN           0.0   \n",
       "8  25.537         0.256186                   NaN           0.0   \n",
       "9  22.501         0.088056              0.263523           0.0   \n",
       "\n",
       "                                    order_book_image  \n",
       "0  [[2.809, 8.184], [0.014, 0.405], [0.003, 0.015...  \n",
       "1  [[2.823, 8.177], [0.014, 0.405], [0.003, 0.015...  \n",
       "2  [[2.837, 8.175], [0.014, 0.405], [0.003, 0.015...  \n",
       "3  [[2.237, 8.177], [0.014, 0.405], [0.003, 0.015...  \n",
       "4  [[2.008, 8.182], [0.014, 0.405], [0.003, 0.015...  \n",
       "5  [[2.239, 22.079], [0.002, 0.006], [0.05, 2.032...  \n",
       "6  [[3.841, 18.706], [0.002, 0.006], [0.05, 0.07]...  \n",
       "7  [[5.998, 17.984], [0.002, 0.006], [0.05, 0.07]...  \n",
       "8  [[5.084, 17.984], [0.002, 0.006], [0.05, 0.072...  \n",
       "9  [[1.697, 18.333], [0.002, 0.006], [0.05, 0.074...  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimized Feature Engineering for Large Datasets (e.g., 1M rows)\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "K = 10  # Top levels to consider\n",
    "MAX_LEVELS = 20  # For order book image\n",
    "\n",
    "# Vectorized features where possible\n",
    "df['mid_price'] = df.apply(lambda row: (row['bid_prices'][0] + row['ask_prices'][0]) / 2, axis=1)  # Keep simple for now, or vectorize if possible\n",
    "df['spread'] = df.apply(lambda row: row['ask_prices'][0] - row['bid_prices'][0], axis=1)\n",
    "\n",
    "# For list-based features, use efficient slicing and summation\n",
    "def safe_slice_sum(lst, k):\n",
    "    return sum(lst[:k]) if len(lst) >= k else sum(lst)\n",
    "\n",
    "def safe_weighted_avg(prices, quantities, k):\n",
    "    if len(prices) < k or len(quantities) < k:\n",
    "        k = min(len(prices), len(quantities))\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    total_vol = sum(quantities[:k])\n",
    "    if total_vol == 0:\n",
    "        return prices[0] if prices else 0\n",
    "    return sum(p * q for p, q in zip(prices[:k], quantities[:k])) / total_vol\n",
    "\n",
    "# Imbalance\n",
    "df['bid_sum_k'] = df['bid_quantities'].apply(lambda x: safe_slice_sum(x, K))\n",
    "df['ask_sum_k'] = df['ask_quantities'].apply(lambda x: safe_slice_sum(x, K))\n",
    "df['imbalance'] = (df['bid_sum_k'] - df['ask_sum_k']) / (df['bid_sum_k'] + df['ask_sum_k']).replace(0, np.nan)\n",
    "df['imbalance'] = df['imbalance'].fillna(0)\n",
    "\n",
    "# Weighted mid-price\n",
    "df['bid_weighted'] = df.apply(lambda row: safe_weighted_avg(row['bid_prices'], row['bid_quantities'], K), axis=1)\n",
    "df['ask_weighted'] = df.apply(lambda row: safe_weighted_avg(row['ask_prices'], row['ask_quantities'], K), axis=1)\n",
    "df['weighted_mid_price'] = (df['bid_weighted'] + df['ask_weighted']) / 2\n",
    "\n",
    "# Cumulative volumes\n",
    "df['bid_cum_volume'] = df['bid_quantities'].apply(lambda x: safe_slice_sum(x, K))\n",
    "df['ask_cum_volume'] = df['ask_quantities'].apply(lambda x: safe_slice_sum(x, K))\n",
    "\n",
    "# Slopes (using vectorized linregress approximation or precompute)\n",
    "def slope_linregress(prices, k):\n",
    "    if len(prices) < k:\n",
    "        return 0\n",
    "    x = np.arange(k)\n",
    "    y = np.array(prices[:k])\n",
    "    if len(np.unique(x)) < 2:\n",
    "        return 0\n",
    "    slope = np.polyfit(x, y, 1)[0]\n",
    "    return slope\n",
    "\n",
    "df['bid_slope'] = df['bid_prices'].apply(lambda x: slope_linregress(x, K))\n",
    "df['ask_slope'] = df['ask_prices'].apply(lambda x: slope_linregress(x, K))\n",
    "\n",
    "# Depth and liquidity ratio\n",
    "df['depth'] = df['bid_sum_k'] + df['ask_sum_k']\n",
    "df['liquidity_ratio'] = df['bid_sum_k'] / df['ask_sum_k'].replace(0, np.nan)\n",
    "df['liquidity_ratio'] = df['liquidity_ratio'].fillna(0)\n",
    "\n",
    "# Rolling volatility (already vectorized)\n",
    "df['mid_price_volatility'] = df['mid_price'].rolling(window=10).std()\n",
    "\n",
    "# Price change\n",
    "df['price_change'] = df['mid_price'].shift(-1) - df['mid_price']\n",
    "\n",
    "# Order book image (optimized padding)\n",
    "def create_order_book_image_opt(bids, asks, max_levels=MAX_LEVELS):\n",
    "    bids_arr = np.array(bids[:max_levels])\n",
    "    asks_arr = np.array(asks[:max_levels])\n",
    "    if len(bids_arr) < max_levels:\n",
    "        bids_arr = np.pad(bids_arr, (0, max_levels - len(bids_arr)), constant_values=0)\n",
    "    if len(asks_arr) < max_levels:\n",
    "        asks_arr = np.pad(asks_arr, (0, max_levels - len(asks_arr)), constant_values=0)\n",
    "    return np.stack([bids_arr, asks_arr], axis=-1)\n",
    "\n",
    "df['order_book_image'] = df.apply(lambda row: create_order_book_image_opt(row['bid_quantities'], row['ask_quantities']), axis=1)\n",
    "\n",
    "# Clean up intermediate columns if not needed\n",
    "df.drop(columns=['bid_sum_k', 'ask_sum_k', 'bid_weighted', 'ask_weighted'], inplace=True)\n",
    "\n",
    "print(f\"Columns after optimized feature engineering: {list(df.columns)}\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0279331b",
   "metadata": {},
   "source": [
    "## 5. Prepare Dataset for Modeling\n",
    "\n",
    "Clean the data, create binary labels for price movements, and split into training/validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36121906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution (price change):\n",
      "count    241422.000000\n",
      "mean          0.004775\n",
      "std           1.737445\n",
      "min         -88.250000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max         116.300000\n",
      "Name: price_change, dtype: float64\n",
      "\n",
      "Classification target distribution:\n",
      "price_change\n",
      "0    232410\n",
      "1      9012\n",
      "Name: count, dtype: int64\n",
      "Training set size: 193137, Test set size: 48285\n",
      "Selected features: ['imbalance', 'spread', 'mid_price_volatility', 'weighted_mid_price', 'bid_cum_volume', 'ask_cum_volume', 'depth', 'liquidity_ratio']\n",
      "Applied SMOTE for class imbalance.\n",
      "Selected features: ['imbalance', 'spread', 'mid_price_volatility', 'weighted_mid_price', 'bid_cum_volume', 'ask_cum_volume', 'depth', 'liquidity_ratio']\n",
      "Applied SMOTE for class imbalance.\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()  # Drop rows with NaN\n",
    "features = ['imbalance', 'spread', 'mid_price_volatility', 'weighted_mid_price', 'bid_cum_volume', 'ask_cum_volume', 'bid_slope', 'ask_slope', 'depth', 'liquidity_ratio']\n",
    "X = df[features]\n",
    "y_regression = df['price_change']\n",
    "y_classification = (y_regression > 0).astype(int)  # 1 if price increases, 0 otherwise\n",
    "print(\"Target distribution (price change):\")\n",
    "print(y_regression.describe())\n",
    "print(\"\\nClassification target distribution:\")\n",
    "print(y_classification.value_counts())\n",
    "\n",
    "# Time-aware split to prevent future data leakage\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "split_idx = int(len(X) * 0.8)  # Fallback to simple split, but note: use TSCV for CV\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train_reg, y_test_reg = y_regression[:split_idx], y_regression[split_idx:]\n",
    "y_train_clf, y_test_clf = y_classification[:split_idx], y_classification[split_idx:]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "\n",
    "# Improved feature selection with mutual info and stability check\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "selector = SelectKBest(score_func=mutual_info_regression, k=8)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train_reg)\n",
    "selected_features = [features[i] for i in selector.get_support(indices=True)]\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "X = X[selected_features]\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "\n",
    "X_train_reg = X_train.copy()\n",
    "\n",
    "# Handle class imbalance with SMOTE if severe\n",
    "from imblearn.over_sampling import SMOTE\n",
    "if y_train_clf.value_counts().min() / y_train_clf.value_counts().max() < 0.5:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train_clf = smote.fit_resample(X_train, y_train_clf)\n",
    "    print(\"Applied SMOTE for class imbalance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af92771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class imbalance\n",
    "plt.figure(figsize=(8, 6))\n",
    "y_classification.value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title('Class Distribution (0: No Increase, 1: Increase)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb81d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}, CV Score: 0.7029\n",
      "Tuned XGBoost Classifier Accuracy: 0.7783, AUC: 0.8730\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87     46703\n",
      "           1       0.11      0.81      0.19      1582\n",
      "\n",
      "    accuracy                           0.78     48285\n",
      "   macro avg       0.55      0.80      0.53     48285\n",
      "weighted avg       0.96      0.78      0.85     48285\n",
      "\n",
      "Best params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}, CV Score: -3.0333\n",
      "Best params: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200}, CV Score: -3.0333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Modular model training function with nested CV\n",
    "def train_model_with_cv(model, X_train, y_train, param_grid=None, scoring='accuracy', cv=3):\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        print(f\"Best params: {grid_search.best_params_}, CV Score: {grid_search.best_score_:.4f}\")\n",
    "        return grid_search.best_estimator_\n",
    "    else:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)\n",
    "        print(f\"CV Scores: {scores}, Mean: {scores.mean():.4f}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "# XGBoost Classifier with nested CV\n",
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "model_clf = xgb.XGBClassifier(objective='binary:logistic', scale_pos_weight=len(y_train_clf[y_train_clf==0])/len(y_train_clf[y_train_clf==1]), random_state=42)\n",
    "best_model_clf = train_model_with_cv(model_clf, X_train, y_train_clf, param_grid_xgb)\n",
    "\n",
    "y_pred_clf = best_model_clf.predict(X_test)\n",
    "y_pred_proba = best_model_clf.predict_proba(X_test)[:, 1]\n",
    "acc = accuracy_score(y_test_clf, y_pred_clf)\n",
    "auc = roc_auc_score(y_test_clf, y_pred_proba)\n",
    "print(f\"Tuned XGBoost Classifier Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "print(classification_report(y_test_clf, y_pred_clf))\n",
    "\n",
    "# XGBoost Regressor\n",
    "if 'X_train_reg' not in locals():\n",
    "    X_train_reg = X_train.copy()\n",
    "\n",
    "model_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "best_model_reg = train_model_with_cv(model_reg, X_train_reg, y_train_reg, param_grid_xgb, scoring='neg_mean_squared_error')\n",
    "y_pred_reg = best_model_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfffb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'y_train_clf' not in locals():\n",
    "    print(\"Data preparation not run. Running it now...\")\n",
    "    \n",
    "    df = df.dropna()  # Drop rows with NaN\n",
    "    features = ['imbalance', 'spread', 'mid_price_volatility', 'weighted_mid_price', 'bid_cum_volume', 'ask_cum_volume', 'bid_slope', 'ask_slope', 'depth', 'liquidity_ratio']\n",
    "    X = df[features]\n",
    "    y_regression = df['price_change']\n",
    "    y_classification = (y_regression > 0).astype(int)  # 1 if price increases, 0 otherwise\n",
    "    print(\"Target distribution (price change):\")\n",
    "    print(y_regression.describe())\n",
    "    print(\"\\nClassification target distribution:\")\n",
    "    print(y_classification.value_counts())\n",
    "    \n",
    "    # Time-aware split to prevent future data leakage\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    split_idx = int(len(X) * 0.8)  # Fallback to simple split, but note: use TSCV for CV\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train_reg, y_test_reg = y_regression[:split_idx], y_regression[split_idx:]\n",
    "    y_train_clf, y_test_clf = y_classification[:split_idx], y_classification[split_idx:]\n",
    "    print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "    \n",
    "    # Improved feature selection with mutual info and stability check\n",
    "    from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "    selector = SelectKBest(score_func=mutual_info_regression, k=8)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train_reg)\n",
    "    selected_features = [features[i] for i in selector.get_support(indices=True)]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    X = X[selected_features]\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    X_train_reg = X_train.copy()\n",
    "    \n",
    "    # Handle class imbalance with SMOTE if severe\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    if y_train_clf.value_counts().min() / y_train_clf.value_counts().max() < 0.5:\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train, y_train_clf = smote.fit_resample(X_train, y_train_clf)\n",
    "        print(\"Applied SMOTE for class imbalance.\")\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    y_classification.value_counts().plot(kind='bar', color=['blue', 'orange'])\n",
    "    plt.title('Class Distribution (0: No Increase, 1: Increase)')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78f0a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m----> 9\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb\u001b[38;5;241m.\u001b[39mXGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m, scale_pos_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43my_train_clf\u001b[49m[y_train_clf\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_train_clf[y_train_clf\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m])),\n\u001b[1;32m     10\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m     11\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     14\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_clf)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Grid search for Regressor\n",
    "grid_search_reg = GridSearchCV(\n",
    "    estimator=xgb.XGBRegressor(objective='reg:squarederror'),\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_reg.fit(X_train_reg, y_train_reg)\n",
    "print(f\"Best parameters for Regressor: {grid_search_reg.best_params_}\")\n",
    "print(f\"Best cross-validation score (neg MSE): {grid_search_reg.best_score_:.4f}\")\n",
    "best_model_reg = grid_search_reg.best_estimator_\n",
    "y_pred_tuned_reg = best_model_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88896f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [0.80519365 0.77802189 0.54193726], Mean: 0.7084\n",
      "Random Forest Accuracy: 0.8350, AUC: 0.8487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91     46703\n",
      "           1       0.12      0.67      0.21      1582\n",
      "\n",
      "    accuracy                           0.83     48285\n",
      "   macro avg       0.56      0.76      0.56     48285\n",
      "weighted avg       0.96      0.83      0.88     48285\n",
      "\n",
      "Random Forest Accuracy: 0.8350, AUC: 0.8487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91     46703\n",
      "           1       0.12      0.67      0.21      1582\n",
      "\n",
      "    accuracy                           0.83     48285\n",
      "   macro avg       0.56      0.76      0.56     48285\n",
      "weighted avg       0.96      0.83      0.88     48285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_model_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model_clf = train_model_with_cv(rf_model_clf, X_train, y_train_clf)\n",
    "rf_pred_clf = rf_model_clf.predict(X_test)\n",
    "rf_pred_proba = rf_model_clf.predict_proba(X_test)[:, 1]\n",
    "rf_acc = accuracy_score(y_test_clf, rf_pred_clf)\n",
    "rf_auc = roc_auc_score(y_test_clf, rf_pred_proba)\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.4f}, AUC: {rf_auc:.4f}\")\n",
    "print(classification_report(y_test_clf, rf_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bddad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 123805, number of negative: 123804\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 247609, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of positive: 123804, number of negative: 123805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 247609, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 123804, number of negative: 123805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 247609, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Number of positive: 123805, number of negative: 123805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 247610, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 123805, number of negative: 123805\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 247610, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "CV Scores: [0.85011914 0.73904931 0.54256728], Mean: 0.7106\n",
      "[LightGBM] [Info] Number of positive: 185707, number of negative: 185707\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 371414, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "CV Scores: [0.85011914 0.73904931 0.54256728], Mean: 0.7106\n",
      "[LightGBM] [Info] Number of positive: 185707, number of negative: 185707\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2040\n",
      "[LightGBM] [Info] Number of data points in the train set: 371414, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "LightGBM Accuracy: 0.8798, AUC: 0.8712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93     46703\n",
      "           1       0.16      0.64      0.26      1582\n",
      "\n",
      "    accuracy                           0.88     48285\n",
      "   macro avg       0.57      0.76      0.60     48285\n",
      "weighted avg       0.96      0.88      0.91     48285\n",
      "\n",
      "CatBoost not available. Skipping.\n",
      "LightGBM Accuracy: 0.8798, AUC: 0.8712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.93     46703\n",
      "           1       0.16      0.64      0.26      1582\n",
      "\n",
      "    accuracy                           0.88     48285\n",
      "   macro avg       0.57      0.76      0.60     48285\n",
      "weighted avg       0.96      0.88      0.91     48285\n",
      "\n",
      "CatBoost not available. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Classifier\n",
    "try:\n",
    "    lgb_model_clf = lgb.LGBMClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    lgb_model_clf = train_model_with_cv(lgb_model_clf, X_train, y_train_clf)\n",
    "    lgb_pred_clf = lgb_model_clf.predict(X_test)\n",
    "    lgb_pred_proba = lgb_model_clf.predict_proba(X_test)[:, 1]\n",
    "    lgb_acc = accuracy_score(y_test_clf, lgb_pred_clf)\n",
    "    lgb_auc = roc_auc_score(y_test_clf, lgb_pred_proba)\n",
    "    print(f\"LightGBM Accuracy: {lgb_acc:.4f}, AUC: {lgb_auc:.4f}\")\n",
    "    print(classification_report(y_test_clf, lgb_pred_clf))\n",
    "except NameError:\n",
    "    print(\"LightGBM not available. Skipping.\")\n",
    "    lgb_model_clf = None\n",
    "\n",
    "# CatBoost Classifier\n",
    "try:\n",
    "    cb_model_clf = cb.CatBoostClassifier(iterations=100, random_state=42, auto_class_weights='Balanced', verbose=0)\n",
    "    cb_model_clf = train_model_with_cv(cb_model_clf, X_train, y_train_clf)\n",
    "    cb_pred_clf = cb_model_clf.predict(X_test)\n",
    "    cb_pred_proba = cb_model_clf.predict_proba(X_test)[:, 1]\n",
    "    cb_acc = accuracy_score(y_test_clf, cb_pred_clf)\n",
    "    cb_auc = roc_auc_score(y_test_clf, cb_pred_proba)\n",
    "    print(f\"CatBoost Accuracy: {cb_acc:.4f}, AUC: {cb_auc:.4f}\")\n",
    "    print(classification_report(y_test_clf, cb_pred_clf))\n",
    "except NameError:\n",
    "    print(\"CatBoost not available. Skipping.\")\n",
    "    cb_model_clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa58e302",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VotingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_model_clf:\n\u001b[1;32m      6\u001b[0m     estimators\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcb\u001b[39m\u001b[38;5;124m'\u001b[39m, cb_model_clf))\n\u001b[0;32m----> 8\u001b[0m voting_model_clf \u001b[38;5;241m=\u001b[39m \u001b[43mVotingClassifier\u001b[49m(estimators\u001b[38;5;241m=\u001b[39mestimators, voting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m voting_model_clf \u001b[38;5;241m=\u001b[39m train_model_with_cv(voting_model_clf, X_train, y_train_clf)\n\u001b[1;32m     10\u001b[0m voting_pred_clf \u001b[38;5;241m=\u001b[39m voting_model_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VotingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensemble: Voting Classifier with available models\n",
    "estimators = [('xgb', best_model_clf), ('rf', rf_model_clf)]\n",
    "if lgb_model_clf:\n",
    "    estimators.append(('lgb', lgb_model_clf))\n",
    "if cb_model_clf:\n",
    "    estimators.append(('cb', cb_model_clf))\n",
    "\n",
    "voting_model_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting_model_clf = train_model_with_cv(voting_model_clf, X_train, y_train_clf)\n",
    "voting_pred_clf = voting_model_clf.predict(X_test)\n",
    "voting_pred_proba = voting_model_clf.predict_proba(X_test)[:, 1]\n",
    "voting_acc = accuracy_score(y_test_clf, voting_pred_clf)\n",
    "voting_auc = roc_auc_score(y_test_clf, voting_pred_proba)\n",
    "print(f\"Voting Ensemble Accuracy: {voting_acc:.4f}, AUC: {voting_auc:.4f}\")\n",
    "print(classification_report(y_test_clf, voting_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM (sequences, regression)\n",
    "sequence_length = 20  # Increased for more context\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X.iloc[i:i+sequence_length].values)\n",
    "    y_seq.append(y_regression.iloc[i+sequence_length])\n",
    "\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "X_train_seq, X_test_seq, y_train_seq, y_test_seq = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model for regression with hyperparameter tuning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_lstm_model(units=50, dropout_rate=0.2, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(sequence_length, X.shape[1])))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))  # Regression\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Simple grid search for LSTM\n",
    "best_mse = float('inf')\n",
    "best_params = {}\n",
    "for units in [32, 50, 64]:\n",
    "    for dropout_rate in [0.1, 0.2]:\n",
    "        for learning_rate in [0.001, 0.01]:\n",
    "            model = build_lstm_model(units=units, dropout_rate=dropout_rate, learning_rate=learning_rate)\n",
    "            model.fit(X_train_seq, y_train_seq, epochs=10, batch_size=32, verbose=0, validation_split=0.1, callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])\n",
    "            mse = model.evaluate(X_test_seq, y_test_seq, verbose=0)[0]\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_params = {'units': units, 'dropout_rate': dropout_rate, 'learning_rate': learning_rate}\n",
    "\n",
    "print(f\"Best LSTM params: {best_params}, MSE: {best_mse}\")\n",
    "\n",
    "model_lstm = build_lstm_model(**best_params)\n",
    "model_lstm.fit(X_train_seq, y_train_seq, epochs=20, batch_size=32, validation_data=(X_test_seq, y_test_seq), callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84b059",
   "metadata": {},
   "source": [
    "## 8. Generate Price Predictions\n",
    "\n",
    "Use the trained models to predict on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with XGBoost Regressor\n",
    "def directional_accuracy(y_true, y_pred):\n",
    "    return np.mean((np.sign(y_true) == np.sign(y_pred)).astype(int))\n",
    "\n",
    "predictions_xgb = best_model_reg.predict(X_test)\n",
    "\n",
    "# Prepare consistent data for LSTM and CNN using same test split\n",
    "sequence_length = 20\n",
    "X_seq = []\n",
    "y_seq_reg = []\n",
    "for i in range(len(X) - sequence_length):\n",
    "    X_seq.append(X.iloc[i:i+sequence_length].values)\n",
    "    y_seq_reg.append(y_regression.iloc[i+sequence_length])\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq_reg = np.array(y_seq_reg)\n",
    "\n",
    "# Align with test split\n",
    "test_start = split_idx - sequence_length\n",
    "X_test_seq = X_seq[test_start:len(X_test) + test_start]\n",
    "y_test_seq = y_seq_reg[test_start:len(y_test_reg) + test_start]\n",
    "\n",
    "predictions_lstm = model_lstm.predict(X_test_seq).flatten()\n",
    "\n",
    "# CNN data aligned\n",
    "X_images = np.stack(df['order_book_image'].values)\n",
    "y_images = y_regression.values\n",
    "X_test_img = X_images[split_idx:split_idx + len(X_test)]\n",
    "y_test_img = y_images[split_idx:split_idx + len(y_test_reg)]\n",
    "\n",
    "predictions_cnn = model_cnn.predict(X_test_img).flatten()\n",
    "\n",
    "print(\"XGBoost Predictions (first 10):\", predictions_xgb[:10])\n",
    "print(\"LSTM Predictions (first 10):\", predictions_lstm[:10])\n",
    "print(\"CNN Predictions (first 10):\", predictions_cnn[:10])\n",
    "\n",
    "# Evaluation with aligned data\n",
    "print(\"\\nXGBoost MSE:\", mean_squared_error(y_test_reg, predictions_xgb))\n",
    "print(\"LSTM MSE:\", mean_squared_error(y_test_seq, predictions_lstm))\n",
    "print(\"CNN MSE:\", mean_squared_error(y_test_img, predictions_cnn))\n",
    "\n",
    "print(\"\\nDirectional Accuracy:\")\n",
    "print(\"XGBoost:\", directional_accuracy(y_test_reg, predictions_xgb))\n",
    "print(\"LSTM:\", directional_accuracy(y_test_seq, predictions_lstm))\n",
    "print(\"CNN:\", directional_accuracy(y_test_img, predictions_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f296ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions with XGBoost Classifier (use best_model_clf if tuned, else model_clf)\n",
    "predictions_clf = best_model_clf.predict(X_test) if 'best_model_clf' in locals() else model_clf.predict(X_test)\n",
    "predictions_proba = best_model_clf.predict_proba(X_test)[:, 1] if 'best_model_clf' in locals() else model_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predictions with LightGBM\n",
    "try:\n",
    "    predictions_lgb_clf = lgb_model_clf.predict(X_test)\n",
    "    predictions_lgb_proba = lgb_model_clf.predict_proba(X_test)[:, 1]\n",
    "except NameError:\n",
    "    predictions_lgb_clf = None\n",
    "    predictions_lgb_proba = None\n",
    "\n",
    "# Predictions with CatBoost\n",
    "try:\n",
    "    predictions_cb_clf = cb_model_clf.predict(X_test)\n",
    "    predictions_cb_proba = cb_model_clf.predict_proba(X_test)[:, 1]\n",
    "except NameError:\n",
    "    predictions_cb_clf = None\n",
    "    predictions_cb_proba = None\n",
    "\n",
    "# Predictions with Random Forest\n",
    "predictions_rf_clf = rf_model_clf.predict(X_test)\n",
    "predictions_rf_proba = rf_model_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Predictions with Voting Ensemble\n",
    "predictions_voting_clf = voting_model_clf.predict(X_test)\n",
    "predictions_voting_proba = voting_model_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"XGBoost Classifier Predictions (first 10):\", predictions_clf[:10])\n",
    "print(\"XGBoost Probabilities (first 10):\", predictions_proba[:10])\n",
    "if predictions_lgb_clf is not None:\n",
    "    print(\"LightGBM Classifier Predictions (first 10):\", predictions_lgb_clf[:10])\n",
    "    print(\"LightGBM Probabilities (first 10):\", predictions_lgb_proba[:10])\n",
    "if predictions_cb_clf is not None:\n",
    "    print(\"CatBoost Classifier Predictions (first 10):\", predictions_cb_clf[:10])\n",
    "    print(\"CatBoost Probabilities (first 10):\", predictions_cb_proba[:10])\n",
    "print(\"Random Forest Classifier Predictions (first 10):\", predictions_rf_clf[:10])\n",
    "print(\"Random Forest Probabilities (first 10):\", predictions_rf_proba[:10])\n",
    "print(\"Voting Ensemble Classifier Predictions (first 10):\", predictions_voting_clf[:10])\n",
    "print(\"Voting Ensemble Probabilities (first 10):\", predictions_voting_proba[:10])\n",
    "\n",
    "# Classification Evaluation\n",
    "print(\"\\nXGBoost Accuracy:\", accuracy_score(y_test_clf, predictions_clf))\n",
    "\n",
    "if predictions_lgb_clf is not None:\n",
    "    print(\"\\nLightGBM Accuracy:\", accuracy_score(y_test_clf, predictions_lgb_clf))\n",
    "\n",
    "if predictions_cb_clf is not None:\n",
    "    print(\"\\nCatBoost Accuracy:\", accuracy_score(y_test_clf, predictions_cb_clf))\n",
    "\n",
    "print(\"\\nRandom Forest Accuracy:\", accuracy_score(y_test_clf, predictions_rf_clf))\n",
    "\n",
    "print(\"\\nVoting Ensemble Accuracy:\", accuracy_score(y_test_clf, predictions_voting_clf))\n",
    "\n",
    "# Check prediction distribution\n",
    "print(\"\\nProbability distribution for XGBoost:\")\n",
    "print(pd.Series(predictions_proba).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcaf8990",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Baseline: Predict mean price change\u001b[39;00m\n\u001b[1;32m      4\u001b[0m baseline_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull_like(y_test_reg, y_train_reg\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m----> 5\u001b[0m baseline_mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m(y_test_reg, baseline_pred)\n\u001b[1;32m      6\u001b[0m baseline_mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test_reg, baseline_pred)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline (mean prediction) MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_mse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_mae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Baseline: Predict mean price change\n",
    "baseline_pred = np.full_like(y_test_reg, y_train_reg.mean())\n",
    "baseline_mse = mean_squared_error(y_test_reg, baseline_pred)\n",
    "baseline_mae = mean_absolute_error(y_test_reg, baseline_pred)\n",
    "\n",
    "print(f\"Baseline (mean prediction) MSE: {baseline_mse:.6f}, MAE: {baseline_mae:.6f}\")\n",
    "\n",
    "# Compare to models\n",
    "print(f\"\\nXGBoost vs Baseline: {'Better' if mean_squared_error(y_test_reg, predictions_xgb) < baseline_mse else 'Worse'}\")\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "if 'best_model_reg' in locals():\n",
    "    xgb.plot_importance(best_model_reg)\n",
    "    plt.show()\n",
    "\n",
    "# Check target statistics\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Train mean: {y_train_reg.mean():.6f}, std: {y_train_reg.std():.6f}\")\n",
    "print(f\"Test mean: {y_test_reg.mean():.6f}, std: {y_test_reg.std():.6f}\")\n",
    "print(f\"Min: {y_regression.min():.6f}, Max: {y_regression.max():.6f}\")\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test_reg - predictions_xgb\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals, bins=50, alpha=0.7)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a6580",
   "metadata": {},
   "source": [
    "## 10. Time Series Analysis\n",
    "\n",
    "Perform time series analysis on the mid-price data to understand trends, stationarity, and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2975447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set timestamp as index for time series\n",
    "df_ts = df.set_index('timestamp')\n",
    "\n",
    "# Plot mid_price time series\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_ts['mid_price'])\n",
    "plt.title('Mid Price Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mid Price')\n",
    "plt.show()\n",
    "\n",
    "# Check for stationarity with Augmented Dickey-Fuller test\n",
    "result = adfuller(df_ts['mid_price'].dropna())\n",
    "print('ADF Statistic:', result[0])\n",
    "print('p-value:', result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'   {key}: {value}')\n",
    "print('Stationary' if result[1] < 0.05 else 'Non-stationary')\n",
    "\n",
    "# ACF and PACF plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "plot_acf(df_ts['mid_price'].dropna(), lags=50, ax=ax1)\n",
    "ax1.set_title('Autocorrelation Function (ACF)')\n",
    "plot_pacf(df_ts['mid_price'].dropna(), lags=50, ax=ax2)\n",
    "ax2.set_title('Partial Autocorrelation Function (PACF)')\n",
    "plt.show()\n",
    "\n",
    "# Rolling statistics\n",
    "rolling_mean = df_ts['mid_price'].rolling(window=100).mean()\n",
    "rolling_std = df_ts['mid_price'].rolling(window=100).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_ts['mid_price'], label='Mid Price')\n",
    "plt.plot(rolling_mean, label='Rolling Mean (100 periods)')\n",
    "plt.plot(rolling_std, label='Rolling Std (100 periods)')\n",
    "plt.legend()\n",
    "plt.title('Rolling Statistics')\n",
    "plt.show()\n",
    "\n",
    "# Seasonal decomposition (if applicable, assuming no strong seasonality)\n",
    "try:\n",
    "    decomposition = seasonal_decompose(df_ts['mid_price'], model='additive', period=1000)  # Adjust period based on data frequency\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(14, 10)\n",
    "    plt.show()\n",
    "except:\n",
    "    print(\"Seasonal decomposition not applicable or failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Backtesting with risk metrics\n",
    "def backtest(predictions, y_true, initial_capital=10000, transaction_cost=0.001, position_size=0.1):\n",
    "    capital = initial_capital\n",
    "    position = 0\n",
    "    trades = 0\n",
    "    pnl = []\n",
    "    for pred, true in zip(predictions, y_true):\n",
    "        if pred > 0.001:\n",
    "            if position <= 0:\n",
    "                position = position_size\n",
    "                trades += 1\n",
    "                capital -= transaction_cost * position * capital\n",
    "        elif pred < -0.001:\n",
    "            if position >= 0:\n",
    "                position = -position_size\n",
    "                trades += 1\n",
    "                capital -= transaction_cost * abs(position) * capital\n",
    "        else:\n",
    "            position = 0\n",
    "        \n",
    "        # P&L\n",
    "        if position != 0:\n",
    "            pnl_change = position * true * capital\n",
    "            capital += pnl_change\n",
    "            pnl.append(pnl_change)\n",
    "    \n",
    "    # Metrics\n",
    "    total_return = (capital - initial_capital) / initial_capital\n",
    "    sharpe = np.mean(pnl) / np.std(pnl) if pnl else 0\n",
    "    max_drawdown = min(0, min(np.cumsum(pnl) - np.maximum.accumulate(np.cumsum(pnl))) if pnl else 0)\n",
    "    return capital, trades, total_return, sharpe, max_drawdown\n",
    "\n",
    "# Backtest XGBoost\n",
    "final_capital_xgb, trades_xgb, ret_xgb, sharpe_xgb, dd_xgb = backtest(predictions_xgb, y_test_reg)\n",
    "print(f\"XGBoost Backtest - Final Capital: {final_capital_xgb:.2f}, Trades: {trades_xgb}, Return: {ret_xgb:.4f}, Sharpe: {sharpe_xgb:.4f}, Max DD: {dd_xgb:.4f}\")\n",
    "\n",
    "if len(predictions_lstm) == len(y_test_seq):\n",
    "    final_capital_lstm, trades_lstm, ret_lstm, sharpe_lstm, dd_lstm = backtest(predictions_lstm, y_test_seq)\n",
    "    print(f\"LSTM Backtest - Final Capital: {final_capital_lstm:.2f}, Trades: {trades_lstm}, Return: {ret_lstm:.4f}, Sharpe: {sharpe_lstm:.4f}, Max DD: {dd_lstm:.4f}\")\n",
    "\n",
    "if len(predictions_cnn) == len(y_test_img):\n",
    "    final_capital_cnn, trades_cnn, ret_cnn, sharpe_cnn, dd_cnn = backtest(predictions_cnn, y_test_img)\n",
    "    print(f\"CNN Backtest - Final Capital: {final_capital_cnn:.2f}, Trades: {trades_cnn}, Return: {ret_cnn:.4f}, Sharpe: {sharpe_cnn:.4f}, Max DD: {dd_cnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f615e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Model Performance\n",
    "models = ['XGBoost', 'RF', 'Voting']\n",
    "accs = [acc, rf_acc, voting_acc]\n",
    "aucs = [auc, rf_auc, voting_auc]\n",
    "\n",
    "summary_df = pd.DataFrame({'Model': models, 'Accuracy': accs, 'AUC': aucs})\n",
    "print(summary_df)\n",
    "\n",
    "# Best model selection\n",
    "best_idx = np.argmax(aucs)\n",
    "print(f\"Best model: {models[best_idx]} with AUC {aucs[best_idx]:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "import joblib\n",
    "joblib.dump(best_model_clf, 'best_model.pkl')\n",
    "print(\"Best model saved as 'best_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
