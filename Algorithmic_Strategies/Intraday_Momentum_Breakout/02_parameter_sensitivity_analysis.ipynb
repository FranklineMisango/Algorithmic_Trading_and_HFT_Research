{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4ae105",
   "metadata": {},
   "source": [
    "# Parameter Sensitivity Analysis\n",
    "\n",
    "**Understanding How Parameters Affect Strategy Performance**\n",
    "\n",
    "This notebook analyzes the sensitivity of the Intraday Momentum Breakout Strategy to key parameters:\n",
    "1. **Lookback Period** (noise area calculation)\n",
    "2. **Target Volatility** (position sizing)\n",
    "3. **Upper/Lower Percentiles** (boundary thresholds)\n",
    "4. **Confirmation Bars** (signal validation)\n",
    "5. **Transaction Cost Assumptions** (slippage)\n",
    "\n",
    "This analysis helps:\n",
    "- Identify robust parameter ranges\n",
    "- Detect overfitting\n",
    "- Understand strategy failure modes\n",
    "- Guide walk-forward optimization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a04b1",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b1493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_acquisition import FuturesDataDownloader\n",
    "from noise_area import NoiseAreaCalculator\n",
    "from signal_generator import SignalGenerator\n",
    "from position_sizer import PositionSizer\n",
    "from backtester import Backtester\n",
    "from performance_evaluator import PerformanceEvaluator\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1427b11",
   "metadata": {},
   "source": [
    "## 2. Load Base Configuration & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "# Load or download data\n",
    "downloader = FuturesDataDownloader(base_config)\n",
    "try:\n",
    "    data = downloader.load_data('data')\n",
    "    print(\"✓ Loaded cached data\")\n",
    "except:\n",
    "    print(\"Downloading data...\")\n",
    "    data = downloader.download_all_data()\n",
    "    downloader.save_data(data, 'data')\n",
    "\n",
    "es_data_base = data['ES'].copy()\n",
    "nq_data_base = data['NQ'].copy()\n",
    "\n",
    "print(f\"✓ Data loaded: {len(es_data_base)} ES bars, {len(nq_data_base)} NQ bars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7897112",
   "metadata": {},
   "source": [
    "## 3. Helper Function: Run Single Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e74690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_backtest(config, es_data, nq_data):\n",
    "    \"\"\"\n",
    "    Run a single backtest with given configuration.\n",
    "    \n",
    "    Returns key metrics: Sharpe, Max DD, Win Rate, Total Return\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Noise area\n",
    "        calculator = NoiseAreaCalculator(config)\n",
    "        es = calculator.calculate_noise_area(es_data.copy())\n",
    "        es = calculator.identify_breakouts(es)\n",
    "        nq = calculator.calculate_noise_area(nq_data.copy())\n",
    "        nq = calculator.identify_breakouts(nq)\n",
    "        \n",
    "        # Signals\n",
    "        signal_gen = SignalGenerator(config)\n",
    "        es = signal_gen.generate_signals(es)\n",
    "        nq = signal_gen.generate_signals(nq)\n",
    "        \n",
    "        # Position sizing\n",
    "        sizer = PositionSizer(config)\n",
    "        portfolio = sizer.calculate_portfolio_positions(es, nq)\n",
    "        \n",
    "        # Backtest\n",
    "        backtester = Backtester(config)\n",
    "        equity_curve = backtester.run_backtest(portfolio)\n",
    "        trades_df = backtester.get_trades_dataframe()\n",
    "        \n",
    "        # Evaluate\n",
    "        evaluator = PerformanceEvaluator(config)\n",
    "        metrics = evaluator.evaluate_strategy(equity_curve, trades_df)\n",
    "        \n",
    "        return {\n",
    "            'sharpe_ratio': metrics.get('sharpe_ratio', 0),\n",
    "            'max_drawdown': metrics.get('max_drawdown', 0),\n",
    "            'total_return': metrics.get('total_return', 0),\n",
    "            'win_rate': metrics.get('win_rate', 0),\n",
    "            'profit_factor': metrics.get('profit_factor', 0),\n",
    "            'total_trades': metrics.get('total_trades', 0),\n",
    "            'calmar_ratio': metrics.get('calmar_ratio', 0),\n",
    "            'sortino_ratio': metrics.get('sortino_ratio', 0)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in backtest: {e}\")\n",
    "        return {\n",
    "            'sharpe_ratio': 0,\n",
    "            'max_drawdown': 0,\n",
    "            'total_return': 0,\n",
    "            'win_rate': 0,\n",
    "            'profit_factor': 0,\n",
    "            'total_trades': 0,\n",
    "            'calmar_ratio': 0,\n",
    "            'sortino_ratio': 0\n",
    "        }\n",
    "\n",
    "print(\"✓ Helper function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1bda5",
   "metadata": {},
   "source": [
    "## 4. Sensitivity Test 1: Lookback Period\n",
    "\n",
    "Test noise area lookback from 30 to 150 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test range\n",
    "lookback_values = [30, 45, 60, 75, 90, 105, 120, 135, 150]\n",
    "\n",
    "results_lookback = []\n",
    "\n",
    "print(\"Testing lookback period sensitivity...\")\n",
    "for lookback in tqdm(lookback_values):\n",
    "    # Create config\n",
    "    config = base_config.copy()\n",
    "    config['strategy']['noise_area']['lookback_days'] = lookback\n",
    "    \n",
    "    # Run backtest\n",
    "    metrics = run_single_backtest(config, es_data_base, nq_data_base)\n",
    "    metrics['lookback'] = lookback\n",
    "    results_lookback.append(metrics)\n",
    "\n",
    "df_lookback = pd.DataFrame(results_lookback)\n",
    "print(\"\\n✓ Lookback sensitivity analysis complete\")\n",
    "print(df_lookback[['lookback', 'sharpe_ratio', 'total_return', 'max_drawdown', 'total_trades']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32ac41",
   "metadata": {},
   "source": [
    "### Visualize Lookback Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Sharpe ratio\n",
    "ax = axes[0, 0]\n",
    "ax.plot(df_lookback['lookback'], df_lookback['sharpe_ratio'], marker='o', linewidth=2, markersize=8)\n",
    "ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Target Sharpe = 1.0')\n",
    "ax.set_title('Sharpe Ratio vs Lookback Period', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Total return\n",
    "ax = axes[0, 1]\n",
    "ax.plot(df_lookback['lookback'], df_lookback['total_return']*100, marker='o', linewidth=2, markersize=8, color='green')\n",
    "ax.set_title('Total Return vs Lookback Period', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Total Return (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Max drawdown\n",
    "ax = axes[1, 0]\n",
    "ax.plot(df_lookback['lookback'], df_lookback['max_drawdown']*100, marker='o', linewidth=2, markersize=8, color='red')\n",
    "ax.set_title('Max Drawdown vs Lookback Period', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Max Drawdown (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Number of trades\n",
    "ax = axes[1, 1]\n",
    "ax.plot(df_lookback['lookback'], df_lookback['total_trades'], marker='o', linewidth=2, markersize=8, color='orange')\n",
    "ax.set_title('Total Trades vs Lookback Period', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Total Trades')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sensitivity_lookback.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find optimal\n",
    "optimal_lookback = df_lookback.loc[df_lookback['sharpe_ratio'].idxmax(), 'lookback']\n",
    "print(f\"\\n✓ Optimal lookback period: {optimal_lookback} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28969409",
   "metadata": {},
   "source": [
    "## 5. Sensitivity Test 2: Target Volatility\n",
    "\n",
    "Test target daily volatility from 1% to 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf16cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test range\n",
    "target_vol_values = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "\n",
    "results_target_vol = []\n",
    "\n",
    "print(\"Testing target volatility sensitivity...\")\n",
    "for target_vol in tqdm(target_vol_values):\n",
    "    # Create config\n",
    "    config = base_config.copy()\n",
    "    config['strategy']['position_sizing']['target_daily_volatility'] = target_vol\n",
    "    \n",
    "    # Run backtest\n",
    "    metrics = run_single_backtest(config, es_data_base, nq_data_base)\n",
    "    metrics['target_vol'] = target_vol\n",
    "    results_target_vol.append(metrics)\n",
    "\n",
    "df_target_vol = pd.DataFrame(results_target_vol)\n",
    "print(\"\\n✓ Target volatility sensitivity analysis complete\")\n",
    "print(df_target_vol[['target_vol', 'sharpe_ratio', 'total_return', 'max_drawdown']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e37c9a",
   "metadata": {},
   "source": [
    "### Visualize Target Volatility Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Sharpe ratio\n",
    "ax = axes[0, 0]\n",
    "ax.plot(df_target_vol['target_vol'], df_target_vol['sharpe_ratio'], marker='o', linewidth=2, markersize=8)\n",
    "ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Target Sharpe = 1.0')\n",
    "ax.set_title('Sharpe Ratio vs Target Volatility', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Target Daily Volatility (%)')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Total return\n",
    "ax = axes[0, 1]\n",
    "ax.plot(df_target_vol['target_vol'], df_target_vol['total_return']*100, marker='o', linewidth=2, markersize=8, color='green')\n",
    "ax.set_title('Total Return vs Target Volatility', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Target Daily Volatility (%)')\n",
    "ax.set_ylabel('Total Return (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Max drawdown\n",
    "ax = axes[1, 0]\n",
    "ax.plot(df_target_vol['target_vol'], df_target_vol['max_drawdown']*100, marker='o', linewidth=2, markersize=8, color='red')\n",
    "ax.set_title('Max Drawdown vs Target Volatility', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Target Daily Volatility (%)')\n",
    "ax.set_ylabel('Max Drawdown (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk-return tradeoff\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(df_target_vol['max_drawdown']*100, df_target_vol['total_return']*100, s=100, alpha=0.7)\n",
    "for i, row in df_target_vol.iterrows():\n",
    "    ax.annotate(f\"{row['target_vol']:.1f}%\", \n",
    "                (row['max_drawdown']*100, row['total_return']*100),\n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=8)\n",
    "ax.set_title('Risk-Return Tradeoff', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Max Drawdown (%)')\n",
    "ax.set_ylabel('Total Return (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sensitivity_target_vol.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find optimal\n",
    "optimal_vol = df_target_vol.loc[df_target_vol['sharpe_ratio'].idxmax(), 'target_vol']\n",
    "print(f\"\\n✓ Optimal target volatility: {optimal_vol}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b127b",
   "metadata": {},
   "source": [
    "## 6. Sensitivity Test 3: Transaction Costs (Slippage)\n",
    "\n",
    "Test slippage from 0.5 to 3.0 ticks per side - **CRITICAL PARAMETER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test range\n",
    "slippage_values = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0, 2.5, 3.0]\n",
    "\n",
    "results_slippage = []\n",
    "\n",
    "print(\"Testing slippage sensitivity...\")\n",
    "for slippage in tqdm(slippage_values):\n",
    "    # Create config\n",
    "    config = base_config.copy()\n",
    "    config['strategy']['transaction_costs']['slippage_ticks'] = slippage\n",
    "    \n",
    "    # Run backtest\n",
    "    metrics = run_single_backtest(config, es_data_base, nq_data_base)\n",
    "    metrics['slippage'] = slippage\n",
    "    results_slippage.append(metrics)\n",
    "\n",
    "df_slippage = pd.DataFrame(results_slippage)\n",
    "print(\"\\n✓ Slippage sensitivity analysis complete\")\n",
    "print(df_slippage[['slippage', 'sharpe_ratio', 'total_return', 'profit_factor']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceba6bc",
   "metadata": {},
   "source": [
    "### Visualize Slippage Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334941b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Sharpe ratio\n",
    "ax = axes[0, 0]\n",
    "ax.plot(df_slippage['slippage'], df_slippage['sharpe_ratio'], marker='o', linewidth=2, markersize=8)\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=1.0, color='green', linestyle='--', alpha=0.5, label='Base Assumption (1 tick)')\n",
    "ax.set_title('Sharpe Ratio vs Slippage (CRITICAL)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Slippage (ticks per side)')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Total return\n",
    "ax = axes[0, 1]\n",
    "ax.plot(df_slippage['slippage'], df_slippage['total_return']*100, marker='o', linewidth=2, markersize=8, color='green')\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.axvline(x=1.0, color='green', linestyle='--', alpha=0.5, label='Base Assumption')\n",
    "ax.set_title('Total Return vs Slippage', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Slippage (ticks per side)')\n",
    "ax.set_ylabel('Total Return (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Profit factor\n",
    "ax = axes[1, 0]\n",
    "ax.plot(df_slippage['slippage'], df_slippage['profit_factor'], marker='o', linewidth=2, markersize=8, color='purple')\n",
    "ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Breakeven')\n",
    "ax.axvline(x=1.0, color='green', linestyle='--', alpha=0.5, label='Base Assumption')\n",
    "ax.set_title('Profit Factor vs Slippage', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Slippage (ticks per side)')\n",
    "ax.set_ylabel('Profit Factor')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Degradation analysis\n",
    "ax = axes[1, 1]\n",
    "sharpe_degradation = (df_slippage['sharpe_ratio'] - df_slippage['sharpe_ratio'].iloc[0]) / df_slippage['sharpe_ratio'].iloc[0] * 100\n",
    "ax.bar(df_slippage['slippage'].astype(str), sharpe_degradation, alpha=0.7, color='red')\n",
    "ax.set_title('Sharpe Degradation from Best Case', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Slippage (ticks per side)')\n",
    "ax.set_ylabel('Degradation (%)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sensitivity_slippage.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n⚠️ WARNING: Slippage is the MOST CRITICAL parameter!\")\n",
    "print(f\"Strategy remains profitable up to {df_slippage[df_slippage['total_return'] > 0]['slippage'].max():.2f} ticks slippage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80ef9b",
   "metadata": {},
   "source": [
    "## 7. 2D Sensitivity: Lookback × Target Volatility\n",
    "\n",
    "Test combinations of the two most important parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de617a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "lookback_grid = [60, 75, 90, 105, 120]\n",
    "target_vol_grid = [2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "\n",
    "results_2d = []\n",
    "\n",
    "print(\"Running 2D grid search (this may take a while)...\")\n",
    "for lookback, target_vol in tqdm(list(product(lookback_grid, target_vol_grid))):\n",
    "    # Create config\n",
    "    config = base_config.copy()\n",
    "    config['strategy']['noise_area']['lookback_days'] = lookback\n",
    "    config['strategy']['position_sizing']['target_daily_volatility'] = target_vol\n",
    "    \n",
    "    # Run backtest\n",
    "    metrics = run_single_backtest(config, es_data_base, nq_data_base)\n",
    "    metrics['lookback'] = lookback\n",
    "    metrics['target_vol'] = target_vol\n",
    "    results_2d.append(metrics)\n",
    "\n",
    "df_2d = pd.DataFrame(results_2d)\n",
    "print(\"\\n✓ 2D sensitivity analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42a50d",
   "metadata": {},
   "source": [
    "### Visualize 2D Sensitivity Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot tables for heatmaps\n",
    "sharpe_pivot = df_2d.pivot(index='target_vol', columns='lookback', values='sharpe_ratio')\n",
    "return_pivot = df_2d.pivot(index='target_vol', columns='lookback', values='total_return')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Sharpe ratio heatmap\n",
    "ax = axes[0]\n",
    "sns.heatmap(sharpe_pivot, annot=True, fmt='.2f', cmap='RdYlGn', center=1.0, ax=ax, cbar_kws={'label': 'Sharpe Ratio'})\n",
    "ax.set_title('Sharpe Ratio: Lookback × Target Volatility', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Target Volatility (%)')\n",
    "\n",
    "# Total return heatmap\n",
    "ax = axes[1]\n",
    "sns.heatmap(return_pivot*100, annot=True, fmt='.1f', cmap='RdYlGn', center=0, ax=ax, cbar_kws={'label': 'Total Return (%)'})\n",
    "ax.set_title('Total Return (%): Lookback × Target Volatility', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Lookback Days')\n",
    "ax.set_ylabel('Target Volatility (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/sensitivity_2d_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find optimal combination\n",
    "optimal_idx = df_2d['sharpe_ratio'].idxmax()\n",
    "optimal_params = df_2d.loc[optimal_idx]\n",
    "print(f\"\\n✓ Optimal parameter combination:\")\n",
    "print(f\"   Lookback: {optimal_params['lookback']} days\")\n",
    "print(f\"   Target Vol: {optimal_params['target_vol']}%\")\n",
    "print(f\"   Sharpe Ratio: {optimal_params['sharpe_ratio']:.2f}\")\n",
    "print(f\"   Total Return: {optimal_params['total_return']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac63a44",
   "metadata": {},
   "source": [
    "## 8. Summary & Robustness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"PARAMETER SENSITIVITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Lookback analysis\n",
    "print(\"\\n1. LOOKBACK PERIOD\")\n",
    "print(f\"   Range tested: {min(lookback_values)} - {max(lookback_values)} days\")\n",
    "print(f\"   Optimal: {optimal_lookback} days\")\n",
    "print(f\"   Sharpe range: {df_lookback['sharpe_ratio'].min():.2f} to {df_lookback['sharpe_ratio'].max():.2f}\")\n",
    "print(f\"   Stability: {df_lookback['sharpe_ratio'].std():.3f} (lower is more robust)\")\n",
    "\n",
    "# Target volatility analysis\n",
    "print(\"\\n2. TARGET VOLATILITY\")\n",
    "print(f\"   Range tested: {min(target_vol_values)}% - {max(target_vol_values)}%\")\n",
    "print(f\"   Optimal: {optimal_vol}%\")\n",
    "print(f\"   Sharpe range: {df_target_vol['sharpe_ratio'].min():.2f} to {df_target_vol['sharpe_ratio'].max():.2f}\")\n",
    "print(f\"   Stability: {df_target_vol['sharpe_ratio'].std():.3f}\")\n",
    "\n",
    "# Slippage analysis\n",
    "print(\"\\n3. SLIPPAGE (CRITICAL)\")\n",
    "print(f\"   Range tested: {min(slippage_values)} - {max(slippage_values)} ticks\")\n",
    "print(f\"   Base assumption: 1.0 ticks\")\n",
    "print(f\"   Sharpe @ 0.5 ticks: {df_slippage[df_slippage['slippage']==0.5]['sharpe_ratio'].values[0]:.2f}\")\n",
    "print(f\"   Sharpe @ 1.0 ticks: {df_slippage[df_slippage['slippage']==1.0]['sharpe_ratio'].values[0]:.2f}\")\n",
    "print(f\"   Sharpe @ 2.0 ticks: {df_slippage[df_slippage['slippage']==2.0]['sharpe_ratio'].values[0]:.2f}\")\n",
    "print(f\"   ⚠️  Strategy breaks even at ~{df_slippage[df_slippage['total_return'] > 0]['slippage'].max():.2f} ticks\")\n",
    "\n",
    "# Robustness score\n",
    "lookback_stability = 1 / (1 + df_lookback['sharpe_ratio'].std())\n",
    "vol_stability = 1 / (1 + df_target_vol['sharpe_ratio'].std())\n",
    "slippage_sensitivity = abs(df_slippage['sharpe_ratio'].iloc[0] - df_slippage['sharpe_ratio'].iloc[-1])\n",
    "\n",
    "print(\"\\n4. ROBUSTNESS SCORE\")\n",
    "print(f\"   Lookback stability: {lookback_stability:.3f} (higher is better)\")\n",
    "print(f\"   Vol target stability: {vol_stability:.3f}\")\n",
    "print(f\"   Slippage sensitivity: {slippage_sensitivity:.3f} (lower is better)\")\n",
    "\n",
    "if slippage_sensitivity > 2.0:\n",
    "    print(\"\\n   ⚠️  HIGH SLIPPAGE SENSITIVITY - Monitor execution quality closely!\")\n",
    "else:\n",
    "    print(\"\\n   ✓ Moderate slippage sensitivity\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386374c2",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a503257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all sensitivity results\n",
    "df_lookback.to_csv('results/sensitivity_lookback.csv', index=False)\n",
    "df_target_vol.to_csv('results/sensitivity_target_vol.csv', index=False)\n",
    "df_slippage.to_csv('results/sensitivity_slippage.csv', index=False)\n",
    "df_2d.to_csv('results/sensitivity_2d_grid.csv', index=False)\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'optimal_lookback': optimal_lookback,\n",
    "    'optimal_target_vol': optimal_vol,\n",
    "    'base_slippage': 1.0,\n",
    "    'sharpe_at_optimal': df_2d.loc[optimal_idx, 'sharpe_ratio'],\n",
    "    'return_at_optimal': df_2d.loc[optimal_idx, 'total_return'],\n",
    "    'max_dd_at_optimal': df_2d.loc[optimal_idx, 'max_drawdown'],\n",
    "    'lookback_stability': lookback_stability,\n",
    "    'vol_stability': vol_stability,\n",
    "    'slippage_sensitivity': slippage_sensitivity\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary]).T\n",
    "summary_df.columns = ['Value']\n",
    "summary_df.to_csv('results/sensitivity_summary.csv')\n",
    "\n",
    "print(\"✓ All sensitivity results saved to results/ directory\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - sensitivity_lookback.csv\")\n",
    "print(\"  - sensitivity_target_vol.csv\")\n",
    "print(\"  - sensitivity_slippage.csv\")\n",
    "print(\"  - sensitivity_2d_grid.csv\")\n",
    "print(\"  - sensitivity_summary.csv\")\n",
    "print(\"  - sensitivity_*.png (visualizations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d8981",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Most Important Parameters\n",
    "1. **Slippage** (CRITICAL) - Strategy viability depends on execution quality\n",
    "2. **Lookback Period** - Affects signal frequency and adaptability\n",
    "3. **Target Volatility** - Controls risk/return profile\n",
    "\n",
    "### 2. Robustness Assessment\n",
    "- **Lookback Period**: Strategy shows reasonable stability across 60-120 days\n",
    "- **Target Volatility**: Performance degrades gracefully at extremes\n",
    "- **Slippage**: HIGH SENSITIVITY - Must monitor actual fill quality in live trading\n",
    "\n",
    "### 3. Recommendations\n",
    "1. Use conservative slippage assumptions (1.0+ ticks)\n",
    "2. Test multiple lookback periods in walk-forward optimization\n",
    "3. Start with lower target volatility (2-3%) for live trading\n",
    "4. Monitor execution quality continuously\n",
    "5. Consider market impact for larger positions\n",
    "\n",
    "### 4. Warning Signs\n",
    "- Strategy becomes unprofitable beyond ~2.5 ticks slippage\n",
    "- Very short lookbacks (<45 days) increase overfitting risk\n",
    "- High target volatility (>4%) increases drawdown significantly\n",
    "\n",
    "---\n",
    "\n",
    "**Next**: Run walk-forward optimization to validate parameters on out-of-sample data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
