{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Container Analysis for Trading Signals\n",
    "\n",
    "This notebook implements the satellite image analysis system described in the research to:\n",
    "1. Collect satellite imagery from major ports\n",
    "2. Use deep learning to count shipping containers\n",
    "3. Generate trading signals from container volume changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ee\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pynvml\n",
    "\n",
    "# Import GEE collector\n",
    "from gee_collector import GoogleEarthCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.11 available ğŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.4.7 ğŸš€ Python-3.10.19 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11908MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dota8.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo26n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5, 3, True]        \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    119808  ultralytics.nn.modules.block.C3k2            [384, 128, 1, True]           \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     34304  ultralytics.nn.modules.block.C3k2            [256, 64, 1, True]            \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     95232  ultralytics.nn.modules.block.C3k2            [192, 128, 1, True]           \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    463104  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True, 0.5, True]\n",
      " 23        [16, 19, 22]  1    390360  ultralytics.nn.modules.head.OBB26            [15, 1, 1, True, [64, 128, 256]]\n",
      "YOLO26n-obb summary: 291 layers, 2,652,984 parameters, 2,652,984 gradients, 6.3 GFLOPs\n",
      "\n",
      "Transferred 792/792 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3747.6Â±1160.0 MB/s, size: 227.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/misango/codechest/FeenQR/ml_service/datasets/dota8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 883.0Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1350.5Â±761.8 MB/s, size: 97.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/misango/codechest/FeenQR/ml_service/datasets/dota8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 104.9Kit/s 0.0s\n",
      "Plotting labels to /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.000526, momentum=0.9) with parameter groups 126 weight(decay=0.0), 144 weight(decay=0.0005), 144 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misango/anaconda3/envs/research_env/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/04 22:25:01 INFO mlflow.tracking.fluent: Experiment with name '/Shared/Ultralytics' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(64553a3376724deab76f25f2b9fc0f64) to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs/mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      1/100     0.721G     0.9284     0.7868    0.01875   0.004521         72        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.3s/it 9.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4s/it 2.4s\n",
      "                   all          4          8      0.977      0.973      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      2/100     0.797G      1.073     0.5874    0.01381    0.01367        143        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.6it/s 0.1s\n",
      "                   all          4          8      0.978      0.972      0.995      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      3/100     0.904G     0.9856     0.5589    0.01162    0.00815        160        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
      "                   all          4          8      0.978      0.971      0.995      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      4/100      0.92G      1.259      1.612    0.01354    0.01842        277        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.3it/s 0.1s\n",
      "                   all          4          8      0.978      0.969      0.995      0.844\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      5/100      0.92G     0.7985      0.503    0.02622    0.01141         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4          8      0.977      0.973      0.995      0.843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      6/100      0.92G     0.9789       0.61   0.009609   0.009151        149        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.1it/s 0.1s\n",
      "                   all          4          8      0.976      0.975      0.995      0.843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      7/100     0.922G     0.9004     0.8518    0.02236   0.008482         87        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4          8      0.973      0.981      0.995      0.843\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      8/100     0.938G     0.8821     0.3717    0.01268   0.009427         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.9it/s 0.1s\n",
      "                   all          4          8      0.971       0.99      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K      9/100     0.951G     0.8943      1.911     0.0276    0.01217         93        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          4          8      0.969      0.998      0.995      0.839\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     10/100     0.969G     0.7769     0.6921     0.0221     0.0135         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.2it/s 0.1s\n",
      "                   all          4          8      0.949          1      0.995       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     11/100     0.982G     0.8778     0.5291    0.02083    0.01088        137        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.8it/s 0.1s\n",
      "                   all          4          8      0.937          1      0.995       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     12/100      1.13G      1.474       3.06    0.01046    0.01627        385        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          4          8      0.941          1      0.995       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     13/100      1.15G      1.067      1.094    0.01134    0.01703        226        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
      "                   all          4          8      0.936          1      0.995       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     14/100      1.17G      0.979     0.9461    0.01562     0.0162        199        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.9it/s 0.1s\n",
      "                   all          4          8      0.924          1      0.995       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     15/100      1.17G      1.059      1.087    0.01231   0.008635        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.9it/s 0.1s\n",
      "                   all          4          8      0.916          1      0.995      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     16/100      1.17G      1.217      1.185    0.01074     0.0217        276        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.1it/s 0.1s\n",
      "                   all          4          8      0.914          1      0.995      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     17/100      1.17G      1.383     0.8431    0.01142   0.008394        103        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.913          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     18/100      1.17G     0.8086     0.4434    0.01443   0.004028         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.5it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
      "                   all          4          8      0.913          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     19/100      1.17G     0.7767     0.3091    0.01816    0.01098         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.9it/s 0.1s\n",
      "                   all          4          8      0.891          1      0.995      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     20/100      1.17G     0.7948      2.378    0.03933    0.01215         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.8it/s 0.1s\n",
      "                   all          4          8      0.891          1      0.995      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     21/100      1.17G      1.099      0.731    0.01369    0.01809        177        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.0it/s 0.1s\n",
      "                   all          4          8      0.874          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     22/100      1.17G     0.9785     0.5383    0.01236    0.01085         90        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.1it/s 0.1s\n",
      "                   all          4          8      0.874          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     23/100      1.17G      0.799     0.4546    0.02337    0.01458         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.4it/s 0.1s\n",
      "                   all          4          8       0.87          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     24/100      1.17G      1.207      0.884    0.01092    0.01619         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.4it/s 0.1s\n",
      "                   all          4          8       0.87          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     25/100      1.17G     0.8342      2.506    0.03945   0.007222         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.2it/s 0.1s\n",
      "                   all          4          8      0.856          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     26/100      1.17G      1.237      1.301    0.01012    0.01204        257        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
      "                   all          4          8      0.856          1      0.995      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     27/100      1.17G      1.363      1.214   0.009361     0.0162        312        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.3it/s 0.1s\n",
      "                   all          4          8      0.799          1      0.995      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     28/100      1.17G      1.136     0.9483    0.01295   0.009027        223        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
      "                   all          4          8      0.799          1      0.995      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     29/100      1.17G     0.9301     0.5198      0.018    0.01277        107        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     30/100      1.17G     0.5796     0.6918     0.0315   0.005328         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.2it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.4it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     31/100      1.17G     0.9795     0.5727     0.0179    0.01154        131        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.2it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     32/100      1.17G      1.209      0.669    0.03083    0.02504         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.4it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     33/100      1.17G      1.006     0.6505    0.01407   0.009949        151        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     34/100      1.17G     0.9094     0.6086     0.0187    0.02189        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.4it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.4it/s 0.1s\n",
      "                   all          4          8      0.756          1      0.995       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     35/100      1.17G      1.205     0.9375    0.01065     0.0112        212        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
      "                   all          4          8      0.658      0.549      0.663      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     36/100      1.17G       0.92     0.4799     0.0151   0.008415        119        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.8it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.549      0.663      0.581\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     37/100      1.17G      1.083     0.5641    0.02147    0.01508         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.7it/s 0.1s\n",
      "                   all          4          8      0.659      0.547      0.663      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     38/100      1.31G      1.622      1.892    0.00925    0.01168        391        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.2it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
      "                   all          4          8      0.659      0.547      0.663      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     39/100      1.31G       1.19     0.7175    0.00929   0.006426        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.548      0.647      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     40/100      1.31G     0.6245      1.037    0.04221   0.005601         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          4          8      0.658      0.548      0.647      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     41/100      1.31G      1.162     0.9317    0.01001   0.009763        258        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.1it/s 0.1s\n",
      "                   all          4          8      0.658      0.549      0.647      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     42/100      1.31G      1.225      2.144   0.009584    0.01819        398        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.0it/s 0.1s\n",
      "                   all          4          8      0.658      0.549      0.647      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     43/100      1.31G     0.6285     0.6903    0.02403    0.01873         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.8it/s 0.1s\n",
      "                   all          4          8      0.658      0.548      0.612      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     44/100      1.31G      1.382      2.964    0.01195    0.01802        367        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4          8      0.658      0.548      0.612      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     45/100      1.31G      1.069     0.7309     0.0111   0.009522        148        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.7it/s 0.1s\n",
      "                   all          4          8      0.658      0.547      0.612      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     46/100      1.31G     0.5653      1.675    0.03375    0.00831         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.9it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
      "                   all          4          8      0.658      0.547      0.612      0.531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     47/100      1.31G     0.7092      2.684    0.04111   0.007794         46        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.546      0.623       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     48/100      1.31G     0.9997     0.6253    0.01969     0.0154        131        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.3it/s 0.1s\n",
      "                   all          4          8      0.658      0.546      0.623       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     49/100      1.31G      0.898     0.4231    0.01486   0.006796        136        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
      "                   all          4          8      0.658      0.545      0.623      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     50/100      1.31G      1.062     0.5958    0.01087   0.009443        203        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
      "                   all          4          8      0.658      0.545      0.623      0.543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     51/100      1.31G     0.9629     0.5593    0.01356    0.01053        167        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.8it/s 0.1s\n",
      "                   all          4          8      0.658      0.544      0.623       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     52/100      1.31G      1.075     0.8435    0.01225    0.01174        235        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.2it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.2it/s 0.1s\n",
      "                   all          4          8      0.658      0.544      0.623       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     53/100      1.31G      0.738      2.055    0.03531    0.01229         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.5it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.8it/s 0.1s\n",
      "                   all          4          8      0.658      0.544      0.623       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     54/100      1.31G     0.7484     0.3839     0.0347   0.004926         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
      "                   all          4          8      0.658      0.543      0.623      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     55/100      1.31G      1.335      2.433    0.01009    0.02215        370        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.543      0.623      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     56/100      1.31G     0.4197     0.9272    0.05719   0.001758         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.2it/s 0.1s\n",
      "                   all          4          8      0.658      0.543      0.623      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     57/100      1.31G     0.9173      0.621     0.0133    0.01117        140        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.3it/s 0.1s\n",
      "                   all          4          8      0.658      0.542      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     58/100      1.31G      1.066      1.146     0.0216   0.007362         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.542      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     59/100      1.31G      1.042     0.9175    0.01506    0.01083        178        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.542      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     60/100      1.31G     0.8191     0.4419     0.0173   0.009505        140        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.9it/s 0.1s\n",
      "                   all          4          8      0.658      0.541      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     61/100      1.31G      1.172     0.9843    0.01255     0.0131        258        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.5it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "                   all          4          8      0.658      0.541      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     62/100      1.31G     0.9281     0.6066    0.01022   0.007165         75        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.658      0.541      0.623      0.514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     63/100      1.31G     0.9222     0.5823    0.01543    0.01239        175        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     64/100      1.31G     0.9721     0.5112    0.01288   0.005361        113        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.7it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     65/100      1.31G     0.8185     0.4106    0.01612    0.00763         85        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.7it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     66/100      1.31G        1.1      1.327    0.01148    0.02262        329        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.7it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     67/100      1.31G      1.098      1.856    0.01132     0.0135        272        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.5it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.2it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     68/100      1.31G      1.183      1.184   0.008843    0.01448        317        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     69/100      1.31G      1.023     0.9756    0.01601   0.008239        115        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.4it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     70/100      1.31G      1.163     0.8914    0.01337    0.01421         72        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.3it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.9it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     71/100      1.31G      1.018     0.7859    0.01333    0.01161        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.1it/s 0.1s\n",
      "                   all          4          8      0.663        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     72/100      1.31G      0.623     0.8226    0.03056    0.03358         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.6it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     73/100      1.31G      1.054      1.195    0.01107    0.01285        305        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     74/100      1.31G     0.8914     0.8601    0.03035    0.01633         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.3it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     75/100      1.31G     0.8446     0.4847    0.01292   0.006751        138        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.1it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     76/100      1.31G       1.05     0.6743    0.01185   0.007879        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     77/100      1.31G      1.013     0.6387    0.01131   0.007575         73        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4          8      0.664        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     78/100      1.31G      1.192      2.133    0.01366     0.0158        308        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.2it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     79/100      1.31G     0.9192      0.516    0.01311    0.01145        172        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.1it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     80/100      1.31G      1.148     0.7645    0.01167    0.01116        221        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.3it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     81/100      1.31G     0.9032     0.9182    0.03182    0.01058         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     82/100      1.31G      1.021     0.7766     0.0127   0.007789         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.9it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     83/100      1.31G     0.9371     0.5063    0.01338   0.004954         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.2it/s 0.1s\n",
      "                   all          4          8      0.665        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     84/100      1.31G       1.21      1.094    0.01037    0.01474        324        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     85/100      1.31G      1.208      1.369    0.01212   0.009574        309        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.0it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     86/100      1.31G      1.104      1.202   0.008862   0.008822        351        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.7it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     87/100      1.31G      1.058     0.7203    0.01429    0.01343        111        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.3it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     88/100      1.31G      1.111     0.7377    0.01067   0.008705        257        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.3it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     89/100      1.31G      0.954     0.8915    0.04298    0.01839         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     90/100      1.31G      0.928     0.6102    0.02077   0.006231         65        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.7it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.498\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     91/100      1.31G     0.8282     0.3147    0.01745    0.00753        107        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.0it/s 0.1s\n",
      "                   all          4          8      0.667      0.498      0.582      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     92/100      1.31G      0.811     0.3639     0.0146   0.008125         98        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.2it/s 0.1s\n",
      "                   all          4          8      0.667        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     93/100      1.31G     0.8467     0.3763    0.01266   0.008008        114        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
      "                   all          4          8      0.667        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     94/100      1.31G     0.8686     0.4038    0.01149   0.007325        125        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.3it/s 0.1s\n",
      "                   all          4          8      0.667        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     95/100      1.31G     0.8636     0.4677    0.01492    0.00732        123        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.4it/s 0.1s\n",
      "                   all          4          8      0.667        0.5      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     96/100      1.31G     0.8566     0.4644    0.01615   0.007734        124        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.1it/s 0.1s\n",
      "                   all          4          8      0.667      0.495      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     97/100      1.31G     0.8534      0.338    0.01526   0.009602         94        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.1it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
      "                   all          4          8      0.667      0.495      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     98/100      1.31G     0.8036     0.3529    0.01342   0.004102        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.3it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.2it/s 0.1s\n",
      "                   all          4          8      0.667      0.495      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K     99/100      1.31G     0.9043     0.3468    0.02619    0.01377         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.5it/s 0.1s\n",
      "                   all          4          8      0.667      0.495      0.582      0.504\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss angle_loss  Instances       Size\n",
      "\u001b[K    100/100      1.31G     0.8525      0.462    0.01505   0.008772        125        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
      "                   all          4          8      0.658      0.541      0.623      0.514\n",
      "\n",
      "100 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train/weights/last.pt, 5.8MB\n",
      "Optimizer stripped from /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train/weights/best.pt, 5.8MB\n",
      "\n",
      "Validating /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train/weights/best.pt...\n",
      "Ultralytics 8.4.7 ğŸš€ Python-3.10.19 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11908MiB)\n",
      "YOLO26n-obb summary (fused): 132 layers, 2,449,332 parameters, 0 gradients, 5.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 22.6it/s 0.0s\n",
      "                   all          4          8      0.977      0.972      0.995      0.877\n",
      "      baseball diamond          3          4          1      0.917      0.995      0.899\n",
      "      basketball court          1          3      0.931          1      0.995      0.936\n",
      "     soccer ball field          1          1          1          1      0.995      0.796\n",
      "Speed: 0.2ms preprocess, 4.8ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/obb/train\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    }
   ],
   "source": [
    "# Train YOLO on xView dataset (for satellite imagery detection)\n",
    "# xView has 60 classes including Container Ship, Shipping Container, Maritime Vessel, etc.\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11n.pt\")  # load a pretrained model\n",
    "results = model.train(data=\"xView.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# Note: xView dataset must be manually downloaded from https://challenge.xviewdataset.org\n",
    "# Extract to datasets/xView/ directory before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Google Earth Engine initialized with project: algorithmictrading-414808\n",
      "Loaded 5 major ports for analysis\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initialize Google Earth Engine Collector\n",
    "collector = GoogleEarthCollector(config_path='config.json', authenticate=False)\n",
    "\n",
    "ports = config['ports']\n",
    "print(f\"Loaded {len(ports)} major ports for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port Locations\n",
    "\n",
    "Let's visualize the major ports we're analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Ports for Container Analysis:\n",
      "======================================================================\n",
      "1. Shanghai        | China           | Lat: 31.2304, Lon: 121.4737\n",
      "2. Singapore       | Singapore       | Lat:  1.2644, Lon: 103.8220\n",
      "3. Rotterdam       | Netherlands     | Lat: 51.9225, Lon:   4.4792\n",
      "4. Los Angeles     | USA             | Lat: 33.7405, Lon: -118.2720\n",
      "5. Hamburg         | Germany         | Lat: 53.5395, Lon:   9.9847\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "lat": [
          31.2304,
          1.2644,
          51.9225,
          33.7405,
          53.5395
         ],
         "lon": [
          121.4737,
          103.822,
          4.4792,
          -118.272,
          9.9847
         ],
         "marker": {
          "color": "red",
          "line": {
           "color": "white",
           "width": 2
          },
          "size": 15
         },
         "mode": "markers+text",
         "text": [
          "Shanghai<br>China",
          "Singapore<br>Singapore",
          "Rotterdam<br>Netherlands",
          "Los Angeles<br>USA",
          "Hamburg<br>Germany"
         ],
         "textfont": {
          "color": "black",
          "family": "Arial Black",
          "size": 12
         },
         "textposition": "top center",
         "type": "scattergeo"
        }
       ],
       "layout": {
        "geo": {
         "coastlinecolor": "rgb(204, 204, 204)",
         "countrycolor": "rgb(204, 204, 204)",
         "landcolor": "rgb(243, 243, 243)",
         "projection": {
          "type": "natural earth"
         },
         "showcountries": true,
         "showland": true
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Major Ports for Container Analysis"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display port information\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"Major Ports for Container Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "for i, port in enumerate(ports, 1):\n",
    "    print(f\"{i}. {port['name']:15} | {port['country']:15} | Lat: {port['lat']:7.4f}, Lon: {port['lon']:8.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create world map with port locations\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "    lon=[p['lon'] for p in ports],\n",
    "    lat=[p['lat'] for p in ports],\n",
    "    text=[f\"{p['name']}<br>{p['country']}\" for p in ports],\n",
    "    mode='markers+text',\n",
    "    marker=dict(\n",
    "        size=15,\n",
    "        color='red',\n",
    "        line=dict(width=2, color='white')\n",
    "    ),\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=12, color='black', family='Arial Black')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Major Ports for Container Analysis',\n",
    "    geo=dict(\n",
    "        projection_type='natural earth',\n",
    "        showland=True,\n",
    "        landcolor='rgb(243, 243, 243)',\n",
    "        coastlinecolor='rgb(204, 204, 204)',\n",
    "        showcountries=True,\n",
    "        countrycolor='rgb(204, 204, 204)',\n",
    "    ),\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerDetector:\n",
    "    def __init__(self, model_type='xview'):\n",
    "        \"\"\"\n",
    "        Initialize container detector with satellite-specific models\n",
    "        \n",
    "        Args:\n",
    "            model_type: 'xview' (best for satellite), 'dota' (aerial), or 'yolo-coco' (ground-level)\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if model_type == 'xview':\n",
    "            # xView dataset - specifically for overhead satellite imagery\n",
    "            try:\n",
    "                # Try your trained xView model\n",
    "                self.model = YOLO('runs/detect/train/weights/best.pt')\n",
    "                print(\"âœ“ Loaded your trained xView model\")\n",
    "                print(\"  xView classes include: Container Ship, Shipping Container, Maritime Vessel\")\n",
    "            except:\n",
    "                try:\n",
    "                    # Try pre-existing xView model\n",
    "                    self.model = YOLO('yolov8n-xview.pt')\n",
    "                    print(\"âœ“ Loaded YOLOv8 trained on xView dataset\")\n",
    "                except:\n",
    "                    print(\"âš ï¸  xView model not found\")\n",
    "                    print(\"   Train one with: model.train(data='xView.yaml', epochs=100)\")\n",
    "                    print(\"   Falling back to OBB model...\")\n",
    "                    self.model = YOLO('runs/obb/train/weights/best.pt')\n",
    "                    self.model_type = 'dota'\n",
    "        elif model_type == 'dota':\n",
    "            # DOTA dataset for aerial imagery\n",
    "            try:\n",
    "                self.model = YOLO('runs/obb/train/weights/best.pt')\n",
    "                print(\"âœ“ Loaded your trained DOTA OBB model\")\n",
    "            except:\n",
    "                self.model = YOLO('yolov8n.pt')\n",
    "                self.model_type = 'yolo-optimized'\n",
    "        else:\n",
    "            # Standard COCO-trained model\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            print(\"âœ“ Loaded standard YOLOv8 (COCO dataset)\")\n",
    "        \n",
    "        # Print available classes\n",
    "        print(f\"  Model classes ({len(self.model.names)}): {list(self.model.names.values())[:10]}...\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess satellite image for container detection\"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # For satellite imagery, enhance contrast\n",
    "        if self.model_type in ['xview', 'dota', 'yolo-optimized']:\n",
    "            # Convert to LAB color space for better contrast\n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            l = clahe.apply(l)\n",
    "            \n",
    "            # Merge and convert back\n",
    "            enhanced = cv2.merge([l, a, b])\n",
    "            img = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def detect_containers(self, image, show_all_classes=False):\n",
    "        \"\"\"Detect and count containers in satellite image\"\"\"\n",
    "        \n",
    "        # Define container-related classes for xView dataset\n",
    "        xview_container_classes = [\n",
    "            'Container Ship',       # Class 31\n",
    "            'Shipping Container',   # Class 57\n",
    "            'Shipping container lot', # Class 56\n",
    "            'Container Crane',      # Class 35\n",
    "            'Cargo Ship',          # Class 2\n",
    "            'Cargo Plane',         # Class 2\n",
    "            'Cargo Truck',         # Class 10\n",
    "            'Cargo Car',           # Class 19\n",
    "            'Maritime Vessel',     # Class 23\n",
    "            'Barge',               # Class 27\n",
    "            'Crane Truck',         # Class 16\n",
    "            'Reach Stacker',       # Class 36\n",
    "            'Straddle Carrier'     # Class 37\n",
    "        ]\n",
    "        \n",
    "        if self.model_type == 'xview':\n",
    "            conf_threshold = 0.15  # Reasonable threshold for xView\n",
    "            container_classes = xview_container_classes\n",
    "        elif self.model_type == 'dota':\n",
    "            conf_threshold = 0.10\n",
    "            container_classes = list(self.model.names.values())\n",
    "        else:\n",
    "            conf_threshold = 0.05\n",
    "            container_classes = [2, 5, 7, 8]  # car, bus, truck, boat for COCO\n",
    "        \n",
    "        # Use higher image size for better detection\n",
    "        results = self.model(image, conf=conf_threshold, verbose=False, imgsz=1280)\n",
    "        \n",
    "        containers = []\n",
    "        all_detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes if hasattr(result, 'boxes') else result.obb\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    cls = int(box.cls)\n",
    "                    conf = float(box.conf)\n",
    "                    class_name = self.model.names[cls]\n",
    "                    \n",
    "                    # Track all detections for analysis\n",
    "                    all_detections.append({\n",
    "                        'class_id': cls,\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf\n",
    "                    })\n",
    "                    \n",
    "                    # Filter for container-like objects\n",
    "                    is_container = False\n",
    "                    if self.model_type == 'xview':\n",
    "                        is_container = class_name in container_classes\n",
    "                    elif self.model_type == 'dota':\n",
    "                        is_container = True  # Accept all DOTA classes\n",
    "                    else:\n",
    "                        is_container = cls in container_classes\n",
    "                    \n",
    "                    if is_container and conf > conf_threshold:\n",
    "                        containers.append({\n",
    "                            'bbox': box.xyxy.cpu().numpy() if hasattr(box, 'xyxy') else box.xywhr.cpu().numpy(),\n",
    "                            'confidence': conf,\n",
    "                            'class': cls,\n",
    "                            'class_name': class_name\n",
    "                        })\n",
    "        \n",
    "        if show_all_classes:\n",
    "            return len(containers), containers, all_detections\n",
    "        return len(containers), containers\n",
    "    \n",
    "    def analyze_port_activity(self, image_dir, port_name):\n",
    "        \"\"\"Analyze container activity for a specific port\"\"\"\n",
    "        image_files = list(Path(image_dir).glob('*.jp*g')) + list(Path(image_dir).glob('*.png'))\n",
    "        results = []\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            img = self.preprocess_image(img_path)\n",
    "            count, detections = self.detect_containers(img)\n",
    "            \n",
    "            results.append({\n",
    "                'port': port_name,\n",
    "                'image': img_path.name,\n",
    "                'container_count': count,\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingSignalGenerator:\n",
    "    def __init__(self):\n",
    "        self.container_data = pd.DataFrame()\n",
    "        \n",
    "    def load_container_data(self, data):\n",
    "        \"\"\"Load container count data\"\"\"\n",
    "        self.container_data = data\n",
    "        \n",
    "    def calculate_signals(self):\n",
    "        \"\"\"Generate trading signals from container volume changes\"\"\"\n",
    "        if self.container_data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Group by port and calculate rolling statistics\n",
    "        signals = []\n",
    "        \n",
    "        for port in self.container_data['port'].unique():\n",
    "            port_data = self.container_data[self.container_data['port'] == port].copy()\n",
    "            port_data = port_data.sort_values('timestamp')\n",
    "            \n",
    "            # Calculate moving averages and changes\n",
    "            port_data['ma_7'] = port_data['container_count'].rolling(7).mean()\n",
    "            port_data['ma_30'] = port_data['container_count'].rolling(30).mean()\n",
    "            port_data['pct_change'] = port_data['container_count'].pct_change()\n",
    "            \n",
    "            # Generate signals\n",
    "            port_data['signal'] = 0\n",
    "            port_data.loc[port_data['ma_7'] > port_data['ma_30'], 'signal'] = 1  # Bullish\n",
    "            port_data.loc[port_data['ma_7'] < port_data['ma_30'], 'signal'] = -1  # Bearish\n",
    "            \n",
    "            # Warning signal for extremely high volumes\n",
    "            high_threshold = port_data['container_count'].quantile(0.95)\n",
    "            port_data['warning'] = port_data['container_count'] > high_threshold\n",
    "            \n",
    "            signals.append(port_data)\n",
    "        \n",
    "        return pd.concat(signals, ignore_index=True)\n",
    "    \n",
    "    def generate_global_signal(self, port_signals):\n",
    "        \"\"\"Generate global trading signal from all ports\"\"\"\n",
    "        global_signal = port_signals.groupby('timestamp').agg({\n",
    "            'container_count': 'sum',\n",
    "            'signal': 'mean',\n",
    "            'warning': 'any'\n",
    "        }).reset_index()\n",
    "        \n",
    "        global_signal['global_signal'] = np.where(\n",
    "            global_signal['signal'] > 0.2, 1,\n",
    "            np.where(global_signal['signal'] < -0.2, -1, 0)\n",
    "        )\n",
    "        \n",
    "        return global_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded your trained DOTA OBB model\n",
      "  Model classes: ['plane', 'ship', 'storage tank', 'baseball diamond', 'tennis court', 'basketball court', 'ground track field', 'harbor', 'bridge', 'large vehicle', 'small vehicle', 'helicopter', 'roundabout', 'soccer ball field', 'swimming pool']\n",
      "âœ“ Container detector initialized\n",
      "âœ“ Trading signal generator initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize detector and signal generator\n",
    "detector = ContainerDetector(model_type='dota')\n",
    "signal_gen = TradingSignalGenerator()\n",
    "\n",
    "print(\"âœ“ Container detector initialized\")\n",
    "print(\"âœ“ Trading signal generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DOTA-Trained Model\n",
    "\n",
    "Three options to get satellite-specific detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading imagery of Shanghai port...\n",
      "Using Google Earth Engine with Sentinel-2 satellite\n",
      "\n",
      "============================================================\n",
      "Processing: Shanghai (China)\n",
      "Coordinates: 31.2304, 121.4737\n",
      "Date range: 2026-01-05 to 2026-02-04\n",
      "Max cloud cover: 10%\n",
      "============================================================\n",
      "Found 7 images with <10% cloud cover\n",
      "  Downloading 1/7: 2026-02-03 (cloud: 3.4%)\n",
      "  âœ“ Saved: Shanghai_2026-02-03_sentinel2.png\n",
      "  Downloading 2/7: 2026-02-03 (cloud: 4.4%)\n",
      "  âœ“ Saved: Shanghai_2026-02-03_sentinel2.png\n",
      "  Downloading 3/7: 2026-01-24 (cloud: 4.0%)\n",
      "  âœ“ Saved: Shanghai_2026-01-24_sentinel2.png\n",
      "  Downloading 4/7: 2026-01-14 (cloud: 2.0%)\n",
      "  âœ“ Saved: Shanghai_2026-01-14_sentinel2.png\n",
      "  Downloading 5/7: 2026-01-12 (cloud: 7.7%)\n",
      "  âœ“ Saved: Shanghai_2026-01-12_sentinel2.png\n",
      "  Downloading 6/7: 2026-01-09 (cloud: 8.6%)\n",
      "  âœ“ Saved: Shanghai_2026-01-09_sentinel2.png\n",
      "  Downloading 7/7: 2026-01-07 (cloud: 1.7%)\n",
      "  âœ“ Saved: Shanghai_2026-01-07_sentinel2.png\n",
      "âœ“ Downloaded 7 images for Shanghai\n",
      "\n",
      "âœ“ Saved metadata to data/results/image_metadata.csv\n",
      "âœ“ Total images downloaded: 7\n",
      "\n",
      "âœ“ Downloaded 7 images\n"
     ]
    }
   ],
   "source": [
    "# Download satellite images using GoogleEarthCollector\n",
    "shanghai = ports[0]  # Shanghai port\n",
    "print(f\"\\nDownloading imagery of {shanghai['name']} port...\")\n",
    "print(f\"Using Google Earth Engine with Sentinel-2 satellite\")\n",
    "\n",
    "# Download images using GEE collector\n",
    "downloaded_df = collector.collect_port_images(\n",
    "    port_name=shanghai['name'],\n",
    "    days_back=30,\n",
    "    max_images=10,\n",
    "    max_cloud=10,\n",
    "    source='sentinel2'\n",
    ")\n",
    "\n",
    "if not downloaded_df.empty:\n",
    "    print(f\"\\nâœ“ Downloaded {len(downloaded_df)} images\")\n",
    "    \n",
    "    # Convert DataFrame to list format for compatibility with visualization code\n",
    "    downloaded = [\n",
    "        {\n",
    "            'port': row['port'],\n",
    "            'filepath': Path(row['filepath']),\n",
    "            'date': row['date']\n",
    "        }\n",
    "        for _, row in downloaded_df.iterrows()\n",
    "    ]\n",
    "else:\n",
    "    print(\"No images downloaded\")\n",
    "    downloaded = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image Download and Visualization\n",
    "\n",
    "Now let's download actual satellite images and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Downloaded 7 satellite images for Shanghai\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Image Summary:\n",
      "  â€¢ Total images: 7\n",
      "  â€¢ Date range: 2026-02-03 to 2026-01-07\n",
      "\n",
      " Image Details:\n",
      "   1. 2026-02-03 - Shanghai_2026-02-03_sentinel2.png\n",
      "   2. 2026-02-03 - Shanghai_2026-02-03_sentinel2.png\n",
      "   3. 2026-01-24 - Shanghai_2026-01-24_sentinel2.png\n",
      "   4. 2026-01-14 - Shanghai_2026-01-14_sentinel2.png\n",
      "   5. 2026-01-12 - Shanghai_2026-01-12_sentinel2.png\n",
      "   6. 2026-01-09 - Shanghai_2026-01-09_sentinel2.png\n",
      "   7. 2026-01-07 - Shanghai_2026-01-07_sentinel2.png\n"
     ]
    }
   ],
   "source": [
    "# Visualize ALL downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Downloaded {len(downloaded)} satellite images for {shanghai['name']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Calculate grid dimensions for all images\n",
    "    n_images = len(downloaded)\n",
    "    n_cols = min(5, n_images)  # Max 5 columns\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Create grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "    \n",
    "    # Flatten axes array for easy iteration\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    # Display all images\n",
    "    for idx, img_info in enumerate(downloaded):\n",
    "        img = Image.open(img_info['filepath'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_info['port']}\\n{img_info['date']}\", \n",
    "                           fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_images, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sentinel-2 Satellite Imagery - {shanghai[\"name\"]} Port ({n_images} images)', \n",
    "                 fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(f\"\\n Image Summary:\")\n",
    "    print(f\"  â€¢ Total images: {n_images}\")\n",
    "    print(f\"  â€¢ Date range: {downloaded[0]['date']} to {downloaded[-1]['date']}\")\n",
    "    print(f\"\\n Image Details:\")\n",
    "    for i, img_info in enumerate(downloaded, 1):\n",
    "        print(f\"  {i:2d}. {img_info['date']} - {img_info['filepath'].name}\")\n",
    "else:\n",
    "    print(\" No images downloaded yet. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images to process\n",
      "\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-01-09_sentinel2.png: 640x576 1 bridge, 1 swimming pool, 13.7ms\n",
      "Speed: 2.6ms preprocess, 13.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-01-09_sentinel2.png - 2 detections\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-01-14_sentinel2.png: 640x576 2 bridges, 1 roundabout, 1 swimming pool, 11.6ms\n",
      "Speed: 2.4ms preprocess, 11.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-01-14_sentinel2.png - 4 detections\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-01-12_sentinel2.png: 640x576 1 harbor, 1 bridge, 1 roundabout, 12.7ms\n",
      "Speed: 2.2ms preprocess, 12.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-01-12_sentinel2.png - 3 detections\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-02-03_sentinel2.png: 640x576 3 harbors, 1 bridge, 1 swimming pool, 12.9ms\n",
      "Speed: 2.5ms preprocess, 12.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-02-03_sentinel2.png - 5 detections\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-01-24_sentinel2.png: 640x576 2 bridges, 11.9ms\n",
      "Speed: 2.7ms preprocess, 11.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-01-24_sentinel2.png - 2 detections\n",
      "\n",
      "image 1/1 /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/data/images/Shanghai_2026-01-07_sentinel2.png: 640x576 2 harbors, 2 bridges, 10.8ms\n",
      "Speed: 2.4ms preprocess, 10.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 576)\n",
      "âœ“ Processed Shanghai_2026-01-07_sentinel2.png - 4 detections\n",
      "\n",
      "Detection results for all images:\n",
      "            name  class  confidence  \\\n",
      "0         bridge      8     0.83237   \n",
      "1  swimming pool     14     0.43271   \n",
      "2         bridge      8     0.82626   \n",
      "3     roundabout     12     0.53013   \n",
      "4         bridge      8     0.31506   \n",
      "\n",
      "                                                 box  \\\n",
      "0  {'x1': 950.31458, 'y1': 1963.35889, 'x2': 919....   \n",
      "1  {'x1': 973.20386, 'y1': 77.11244, 'x2': 966.71...   \n",
      "2  {'x1': 948.55017, 'y1': 1957.99402, 'x2': 920....   \n",
      "3  {'x1': 1347.22009, 'y1': 1509.18298, 'x2': 135...   \n",
      "4  {'x1': 1423.81213, 'y1': 1562.93774, 'x2': 142...   \n",
      "\n",
      "                               image  \n",
      "0  Shanghai_2026-01-09_sentinel2.png  \n",
      "1  Shanghai_2026-01-09_sentinel2.png  \n",
      "2  Shanghai_2026-01-14_sentinel2.png  \n",
      "3  Shanghai_2026-01-14_sentinel2.png  \n",
      "4  Shanghai_2026-01-14_sentinel2.png  \n",
      "\n",
      "âœ“ All detection results saved to data/results/obb_detections.csv\n",
      "âœ“ Total detections: 20\n"
     ]
    }
   ],
   "source": [
    "# Inference on all downloaded satellite images using trained OBB model\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load the best trained OBB model\n",
    "model = YOLO(\"runs/obb/train/weights/best.pt\")\n",
    "\n",
    "# Directory containing satellite images\n",
    "image_dir = Path(\"data/images\")\n",
    "# GEE collector saves images as .png files\n",
    "image_files = list(image_dir.glob(\"*.png\")) + list(image_dir.glob(\"*.jpg\"))\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in {image_dir}\")\n",
    "    print(\"Please run the image download cell first (Cell 10)\")\n",
    "else:\n",
    "    print(f\"Found {len(image_files)} images to process\\n\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            results = model(str(img_path))\n",
    "            # Get results as DataFrame\n",
    "            result_data = results[0].to_df()\n",
    "            \n",
    "            # Handle both polars and pandas DataFrames\n",
    "            if hasattr(result_data, \"to_pandas\"):\n",
    "                df = result_data.to_pandas()\n",
    "            else:\n",
    "                df = pd.DataFrame(result_data)\n",
    "            \n",
    "            df[\"image\"] = img_path.name\n",
    "            results_list.append(df)\n",
    "            print(f\"âœ“ Processed {img_path.name} - {len(df)} detections\")\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    # Combine all results into a single DataFrame\n",
    "    if results_list:\n",
    "        all_detections = pd.concat(results_list, ignore_index=True)\n",
    "        print(\"\\nDetection results for all images:\")\n",
    "        print(all_detections.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        Path(\"data/results\").mkdir(parents=True, exist_ok=True)\n",
    "        all_detections.to_csv(\"data/results/obb_detections.csv\", index=False)\n",
    "        print(f\"\\nâœ“ All detection results saved to data/results/obb_detections.csv\")\n",
    "        print(f\"âœ“ Total detections: {len(all_detections)}\")\n",
    "    else:\n",
    "        print(\"\\n No detections made from any images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Detection on Downloaded Images\n",
    "\n",
    "Apply YOLO model to detect containers in the satellite images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running YOLO container detection...\n",
      "NOTE: YOLO is trained on ground photos, not satellite imagery!\n",
      "======================================================================\n",
      "âœ“ 2026-02-03:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-02-03:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-01-24:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-01-14:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-01-12:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-01-09:   0 vehicles |   0 total objects\n",
      "âœ“ 2026-01-07:   0 vehicles |   0 total objects\n",
      "======================================================================\n",
      "\n",
      "All Object Classes Detected (across all 7 images):\n",
      "  No objects detected at all!\n",
      "  This is because:\n",
      "    - Satellite images are taken from 700km altitude\n",
      "    - YOLO expects ground-level photos (0-100m)\n",
      "    - Objects are too small (< 5 pixels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detection Summary:\n",
      "  â€¢ Total vehicles detected: 0 (across 7 images)\n",
      "  â€¢ Total objects detected: 0\n",
      "  â€¢ Average per image: 0.0 vehicles, 0.0 objects\n",
      "\n",
      "Recommendation:\n",
      "  For satellite imagery, you need:\n",
      "  1. Models trained on aerial/satellite data (not COCO)\n",
      "  2. Higher resolution images (4096x4096 or larger)\n",
      "  3. Specialized container detection models\n",
      "  4. Or use synthetic data for demonstration (next cell)\n"
     ]
    }
   ],
   "source": [
    "# Run container detection on downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(\"Running YOLO container detection...\")\n",
    "    print(\"NOTE: YOLO is trained on ground photos, not satellite imagery!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    detection_results = []\n",
    "    all_classes_found = {}\n",
    "    \n",
    "    for img_info in downloaded:\n",
    "        # Load and preprocess image\n",
    "        img = detector.preprocess_image(img_info['filepath'])\n",
    "        \n",
    "        # Detect containers and get all detections\n",
    "        count, detections, all_dets = detector.detect_containers(img, show_all_classes=True)\n",
    "        \n",
    "        # Track what classes were found\n",
    "        for det in all_dets:\n",
    "            class_name = det['class_name']\n",
    "            if class_name not in all_classes_found:\n",
    "                all_classes_found[class_name] = 0\n",
    "            all_classes_found[class_name] += 1\n",
    "        \n",
    "        detection_results.append({\n",
    "            'port': img_info['port'],\n",
    "            'date': img_info['date'],\n",
    "            'filepath': img_info['filepath'],\n",
    "            'container_count': count,\n",
    "            'detections': detections,\n",
    "            'all_detections': all_dets\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ“ {img_info['date']}: {count:3d} vehicles | {len(all_dets):3d} total objects\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Show what YOLO actually detected\n",
    "    print(f\"\\nAll Object Classes Detected (across all {len(downloaded)} images):\")\n",
    "    if all_classes_found:\n",
    "        for class_name, count in sorted(all_classes_found.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  â€¢ {class_name:20s}: {count:4d} instances\")\n",
    "    else:\n",
    "        print(\"  No objects detected at all!\")\n",
    "        print(\"  This is because:\")\n",
    "        print(\"    - Satellite images are taken from 700km altitude\")\n",
    "        print(\"    - YOLO expects ground-level photos (0-100m)\")\n",
    "        print(\"    - Objects are too small (< 5 pixels)\")\n",
    "    \n",
    "    # Visualize detections on image with most detections\n",
    "    if detection_results:\n",
    "        # Find image with most detections\n",
    "        best_result = max(detection_results, key=lambda x: len(x['all_detections']))\n",
    "        \n",
    "        img = cv2.imread(str(best_result['filepath']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw ALL detections (not just vehicles)\n",
    "        for det in best_result['all_detections'][:50]:  # Limit to 50 for clarity\n",
    "            # Find bounding boxes from the model results\n",
    "            pass\n",
    "        \n",
    "        # Draw vehicle detections with boxes\n",
    "        for det in best_result['detections']:\n",
    "            bbox = det['bbox'][0]\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "            cv2.putText(img, label, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Best Detection Result - {best_result['port']} ({best_result['date']})\\n{best_result['container_count']} vehicles | {len(best_result['all_detections'])} total objects\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        total_vehicles = sum(r['container_count'] for r in detection_results)\n",
    "        total_objects = sum(len(r['all_detections']) for r in detection_results)\n",
    "        print(f\"\\nDetection Summary:\")\n",
    "        print(f\"  â€¢ Total vehicles detected: {total_vehicles} (across {len(detection_results)} images)\")\n",
    "        print(f\"  â€¢ Total objects detected: {total_objects}\")\n",
    "        print(f\"  â€¢ Average per image: {total_vehicles/len(detection_results):.1f} vehicles, {total_objects/len(detection_results):.1f} objects\")\n",
    "        \n",
    "        if total_vehicles == 0:\n",
    "            print(f\"\\nRecommendation:\")\n",
    "            print(f\"  For satellite imagery, you need:\")\n",
    "            print(f\"  1. Models trained on aerial/satellite data (not COCO)\")\n",
    "            print(f\"  2. Higher resolution images (4096x4096 or larger)\")\n",
    "            print(f\"  3. Specialized container detection models\")\n",
    "            print(f\"  4. Or use synthetic data for demonstration (next cell)\")\n",
    "else:\n",
    "    print(\"âš ï¸  No images available for detection. Download images first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Signal Generation\n",
    "\n",
    "Generate trading signals from container volume analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trading signals\n",
    "signal_gen.load_container_data(df_containers)\n",
    "port_signals = signal_gen.calculate_signals()\n",
    "global_signals = signal_gen.generate_global_signal(port_signals)\n",
    "\n",
    "print(\"Trading signals generated:\")\n",
    "print(global_signals.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"\\nGenerating trading signal visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Container counts by port\n",
    "print(\"  â€¢ Plotting container counts by port...\")\n",
    "for port in ports:\n",
    "    port_data = df_containers[df_containers['port'] == port['name']]\n",
    "    axes[0,0].plot(port_data['timestamp'], port_data['container_count'], \n",
    "                   label=f\"{port['name']} ({port['country']})\", marker='o', markersize=3)\n",
    "axes[0,0].set_title('Container Counts by Port', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Date', fontsize=11)\n",
    "axes[0,0].set_ylabel('Container Count', fontsize=11)\n",
    "axes[0,0].legend(loc='best', fontsize=9)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Global container volume\n",
    "print(\"  â€¢ Plotting global container volume...\")\n",
    "axes[0,1].plot(global_signals['timestamp'], global_signals['container_count'], \n",
    "               color='blue', linewidth=2, marker='o', markersize=4)\n",
    "axes[0,1].set_title('Global Container Volume (All Ports)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Date', fontsize=11)\n",
    "axes[0,1].set_ylabel('Total Container Count', fontsize=11)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].fill_between(global_signals['timestamp'], global_signals['container_count'], \n",
    "                        alpha=0.3, color='blue')\n",
    "\n",
    "# Trading signals\n",
    "print(\"  â€¢ Plotting trading signals...\")\n",
    "signal_colors = {1: 'green', -1: 'red', 0: 'gray'}\n",
    "for signal_val, color in signal_colors.items():\n",
    "    mask = global_signals['global_signal'] == signal_val\n",
    "    axes[1,0].scatter(global_signals[mask]['timestamp'], \n",
    "                     global_signals[mask]['global_signal'],\n",
    "                     c=color, s=100, alpha=0.7, \n",
    "                     label=f\"{'Buy' if signal_val == 1 else 'Sell' if signal_val == -1 else 'Hold'}\")\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1,0].set_title('Global Trading Signal', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Date', fontsize=11)\n",
    "axes[1,0].set_ylabel('Signal (-1: Sell, 0: Hold, 1: Buy)', fontsize=11)\n",
    "axes[1,0].set_ylim(-1.5, 1.5)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].legend(loc='best')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Warning signals\n",
    "print(\"  â€¢ Plotting warning signals...\")\n",
    "warning_dates = global_signals[global_signals['warning']]['timestamp']\n",
    "normal_dates = global_signals[~global_signals['warning']]['timestamp']\n",
    "axes[1,1].scatter(warning_dates, [1]*len(warning_dates), \n",
    "                 color='red', s=150, alpha=0.8, marker='X', label='High Volume Warning')\n",
    "axes[1,1].scatter(normal_dates, [0]*len(normal_dates), \n",
    "                 color='green', s=50, alpha=0.5, marker='o', label='Normal Volume')\n",
    "axes[1,1].set_title('High Volume Warning Signals', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Date', fontsize=11)\n",
    "axes[1,1].set_ylabel('Status', fontsize=11)\n",
    "axes[1,1].set_ylim(-0.5, 1.5)\n",
    "axes[1,1].set_yticks([0, 1])\n",
    "axes[1,1].set_yticklabels(['Normal', 'Warning'])\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend(loc='best')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Satellite Container Analysis - Trading Dashboard', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = Path('data/results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save container data and signals\n",
    "df_containers.to_csv(output_dir / 'container_counts.csv', index=False)\n",
    "port_signals.to_csv(output_dir / 'port_signals.csv', index=False)\n",
    "global_signals.to_csv(output_dir / 'global_signals.csv', index=False)\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Total observations: {len(df_containers)}\")\n",
    "print(f\"- Ports analyzed: {df_containers['port'].nunique()}\")\n",
    "print(f\"- Date range: {df_containers['timestamp'].min()} to {df_containers['timestamp'].max()}\")\n",
    "print(f\"- Average daily global volume: {global_signals['container_count'].mean():.0f} containers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
