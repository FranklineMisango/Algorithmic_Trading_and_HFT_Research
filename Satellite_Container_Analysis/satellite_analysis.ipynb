{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel-2 Satellite Analysis for Major Global Ports With an end goal of capturing Trading Signals based on Post Tarriffs Output on China and The EU\n",
    "\n",
    "This notebook implements the satellite image analysis system described in the research to:\n",
    "1. Collect satellite imagery from major ports\n",
    "2. Use deep learning to count shipping containers\n",
    "3. Generate trading signals from container volume changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misango/anaconda3/envs/research_env/lib/python3.10/site-packages/google/api_core/_python_version_support.py:275: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/misango/anaconda3/envs/research_env/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ee\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pynvml\n",
    "from gee_collector import GoogleEarthCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.12 üöÄ Python-3.10.19 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11908MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/datasets/xview/xView.yaml, degrees=15.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.4, hsv_v=0.4, imgsz=1024, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train16, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/detect/train16, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=62\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    843402  ultralytics.nn.modules.head.Detect           [62, 16, None, [128, 256, 512]]\n",
      "YOLO11s summary: 182 layers, 9,451,786 parameters, 9,451,770 gradients, 21.7 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1364.7¬±490.5 MB/s, size: 29211.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/datasets/xview/labels/train.cache... 719 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 719/719 137.1Mit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1594.8¬±513.6 MB/s, size: 27944.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/datasets/xview/labels/val_labeled.cache... 127 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 127/127 3.4Mit/s 0.0s\n",
      "Plotting labels to /home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/detect/train16/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misango/anaconda3/envs/research_env/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning:\n",
      "\n",
      "The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(abd799baf5ad403eb2da6207a12e6f3b) to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs/mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/runs/detect/train16\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      8.37G      3.148      6.019      1.935       4757       1024: 0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/90  40.4sWARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      9.19G      2.958      6.053       1.79       3006       1024: 2% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2/90 4.2s/it 58.3s<6:081:48WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      7.82G      3.014      6.083      1.783       3417       1024: 3% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/90 5.1s/it 1:09<7:24WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      9.09G      2.991      6.052      1.825       4213       1024: 4% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/90 6.4s/it 1:25<9:13WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100       9.6G      2.969      5.884      1.815       7238       1024: 6% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5/90 7.9s/it 1:42<11:11WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100       8.9G      2.943      5.629      1.782       3960       1024: 7% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/90 9.2s/it 1:57<12:50WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      9.89G       3.02      5.322      1.747       2473       1024: 9% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 8/90 1.4s/it 2:40<1:5436WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      7.86G      2.997      5.123      1.706       4855       1024: 10% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/90 1.9s/it 3:03<2:37WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      8.23G      2.967      4.897      1.668       9719       1024: 11% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 10/90 2.7s/it 3:28<3:34WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      9.44G      2.952      4.718      1.638       9914       1024: 12% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/90 3.7s/it 3:59<4:51WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      7.77G      2.937      4.577      1.613       5940       1024: 13% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 12/90 4.9s/it 4:20<6:21WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      8.38G      2.908      4.436      1.591       6376       1024: 14% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/90 5.9s/it 4:31<7:36WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      9.03G       2.89       4.29      1.551       3028       1024: 17% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 15/90 1.4s/it 4:57<1:44WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      8.48G       2.88       4.24      1.539       5199       1024: 18% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 16/90 1.9s/it 5:11<2:20WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n",
      "\u001b[K      1/100      8.33G      2.878      4.127      1.522       7346       1024: 19% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 17/90 2.6s/it 5:37<3:12WARNING ‚ö†Ô∏è CUDA OutOfMemoryError in TaskAlignedAssigner, using CPU\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "model = YOLO(\"yolo11s.pt\")  # Upgraded from yolo11n to yolo11s (better accuracy)\n",
    "results = model.train(\n",
    "    data=\"/home/misango/codechest/Algorithmic_Trading_and_HFT_Research/Satellite_Container_Analysis/datasets/xview/xView.yaml\", \n",
    "    epochs=100,  # Increased from 50 (xView winners trained 100+ epochs)\n",
    "    imgsz=1024,  # Reduced from 1024 to save memory (still good for satellite imagery)\n",
    "    batch=8,  # Reduced from 4 - will use gradient accumulation\n",
    "    device=0,\n",
    "    amp=True,  # Mixed precision to reduce memory usage\n",
    "    patience=50,  # Increased patience for larger model\n",
    "    save=True,  \n",
    "    save_period=5,  # Save every 5 epochs\n",
    "    optimizer='AdamW',  # Better than SGD for satellite imagery\n",
    "    lr0=0.001,  # Lower initial LR for AdamW\n",
    "    lrf=0.01,  # Final learning rate\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=5.0,  # Longer warmup for stability\n",
    "    warmup_momentum=0.8,\n",
    "    hsv_h=0.015,  # Minimal hue shift (satellite colors are consistent)\n",
    "    hsv_s=0.4,  # Moderate saturation variation\n",
    "    hsv_v=0.4,  # Moderate brightness variation\n",
    "    degrees=15.0,  # Small rotation (satellite imagery has some orientation variation)\n",
    "    translate=0.1,  # Image translation\n",
    "    scale=0.5,  # Scale augmentation for multi-scale objects\n",
    "    shear=0.0,  # No shear (objects are not perspective-warped)\n",
    "    perspective=0.0,  # No perspective transform\n",
    "    flipud=0.0,  # No vertical flip (satellite images have consistent orientation)\n",
    "    fliplr=0.5,  # Horizontal flip is OK\n",
    "    mosaic=1.0,  # Mosaic augmentation (helps with small objects)\n",
    "    mixup=0.0,  # Disabled to save memory\n",
    "    copy_paste=0.0,  # Disabled to save memory\n",
    "    box=7.5,  # Box loss weight (default 7.5)\n",
    "    cls=0.5,  # Class loss weight (default 0.5)\n",
    "    dfl=1.5,  # DFL loss weight (default 1.5)\n",
    "    multi_scale=False,  # Disabled to save memory and avoid size fluctuation\n",
    "    iou=0.5,  # IoU threshold for NMS (matches xView evaluation)\n",
    "    val=True,  # Validate every epoch (now with labeled validation set)\n",
    "    plots=True,  # Save training plots\n",
    "    verbose=True,  # Verbose output\n",
    "    close_mosaic=10,  # Disable mosaic augmentation in last 10 epochs for stability\n",
    "    cache=False,  # Don't cache images in memory to save RAM\n",
    "    workers=4,  # Reduce dataloader workers to save memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Google Earth Engine initialized with project: algorithmictrading-414808\n",
      "Loaded 5 major ports for analysis\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initialize Google Earth Engine Collector\n",
    "collector = GoogleEarthCollector(config_path='config.json', authenticate=False)\n",
    "\n",
    "ports = config['ports']\n",
    "print(f\"Loaded {len(ports)} major ports for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port Locations\n",
    "\n",
    "Let's visualize the major ports we're analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major Ports for Container Analysis:\n",
      "======================================================================\n",
      "1. Shanghai        | China           | Lat: 31.2304, Lon: 121.4737\n",
      "2. Singapore       | Singapore       | Lat:  1.2644, Lon: 103.8220\n",
      "3. Rotterdam       | Netherlands     | Lat: 51.9225, Lon:   4.4792\n",
      "4. Los Angeles     | USA             | Lat: 33.7405, Lon: -118.2720\n",
      "5. Hamburg         | Germany         | Lat: 53.5395, Lon:   9.9847\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "lat": [
          31.2304,
          1.2644,
          51.9225,
          33.7405,
          53.5395
         ],
         "lon": [
          121.4737,
          103.822,
          4.4792,
          -118.272,
          9.9847
         ],
         "marker": {
          "color": "red",
          "line": {
           "color": "white",
           "width": 2
          },
          "size": 15
         },
         "mode": "markers+text",
         "text": [
          "Shanghai<br>China",
          "Singapore<br>Singapore",
          "Rotterdam<br>Netherlands",
          "Los Angeles<br>USA",
          "Hamburg<br>Germany"
         ],
         "textfont": {
          "color": "black",
          "family": "Arial Black",
          "size": 12
         },
         "textposition": "top center",
         "type": "scattergeo"
        }
       ],
       "layout": {
        "geo": {
         "coastlinecolor": "rgb(204, 204, 204)",
         "countrycolor": "rgb(204, 204, 204)",
         "landcolor": "rgb(243, 243, 243)",
         "projection": {
          "type": "natural earth"
         },
         "showcountries": true,
         "showland": true
        },
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Major Ports for Container Analysis"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display port information\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"Major Ports for Container Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "for i, port in enumerate(ports, 1):\n",
    "    print(f\"{i}. {port['name']:15} | {port['country']:15} | Lat: {port['lat']:7.4f}, Lon: {port['lon']:8.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create world map with port locations\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "    lon=[p['lon'] for p in ports],\n",
    "    lat=[p['lat'] for p in ports],\n",
    "    text=[f\"{p['name']}<br>{p['country']}\" for p in ports],\n",
    "    mode='markers+text',\n",
    "    marker=dict(\n",
    "        size=15,\n",
    "        color='red',\n",
    "        line=dict(width=2, color='white')\n",
    "    ),\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=12, color='black', family='Arial Black')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Major Ports for Container Analysis',\n",
    "    geo=dict(\n",
    "        projection_type='natural earth',\n",
    "        showland=True,\n",
    "        landcolor='rgb(243, 243, 243)',\n",
    "        coastlinecolor='rgb(204, 204, 204)',\n",
    "        showcountries=True,\n",
    "        countrycolor='rgb(204, 204, 204)',\n",
    "    ),\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerDetector:\n",
    "    def __init__(self, model_type='xview'):\n",
    "        \"\"\"\n",
    "        Initialize container detector with satellite-specific models\n",
    "        \n",
    "        Args:\n",
    "            model_type: 'xview' (best for satellite), 'dota' (aerial), or 'yolo-coco' (ground-level)\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if model_type == 'xview':\n",
    "            # xView dataset - specifically for overhead satellite imagery\n",
    "            try:\n",
    "                # Try your trained xView model\n",
    "                self.model = YOLO('runs/detect/train/weights/best.pt')\n",
    "                print(\"‚úì Loaded your trained xView model\")\n",
    "                print(\"  xView classes include: Container Ship, Shipping Container, Maritime Vessel\")\n",
    "            except:\n",
    "                try:\n",
    "                    # Try pre-existing xView model\n",
    "                    self.model = YOLO('yolov8n-xview.pt')\n",
    "                    print(\"‚úì Loaded YOLOv8 trained on xView dataset\")\n",
    "                except:\n",
    "                    print(\"‚ö†Ô∏è  xView model not found\")\n",
    "                    print(\"   Train one with: model.train(data='xView.yaml', epochs=100)\")\n",
    "                    print(\"   Falling back to OBB model...\")\n",
    "                    self.model = YOLO('runs/obb/train/weights/best.pt')\n",
    "                    self.model_type = 'dota'\n",
    "        elif model_type == 'dota':\n",
    "            # DOTA dataset for aerial imagery\n",
    "            try:\n",
    "                self.model = YOLO('runs/obb/train/weights/best.pt')\n",
    "                print(\"‚úì Loaded your trained DOTA OBB model\")\n",
    "            except:\n",
    "                self.model = YOLO('yolov8n.pt')\n",
    "                self.model_type = 'yolo-optimized'\n",
    "        else:\n",
    "            # Standard COCO-trained model\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            print(\"‚úì Loaded standard YOLOv8 (COCO dataset)\")\n",
    "        \n",
    "        # Print available classes\n",
    "        print(f\"  Model classes ({len(self.model.names)}): {list(self.model.names.values())[:10]}...\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess satellite image for container detection\"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # For satellite imagery, enhance contrast\n",
    "        if self.model_type in ['xview', 'dota', 'yolo-optimized']:\n",
    "            # Convert to LAB color space for better contrast\n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            l = clahe.apply(l)\n",
    "            \n",
    "            # Merge and convert back\n",
    "            enhanced = cv2.merge([l, a, b])\n",
    "            img = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def detect_containers(self, image, show_all_classes=False):\n",
    "        \"\"\"Detect and count containers in satellite image\"\"\"\n",
    "        \n",
    "        # Define container-related classes for xView dataset\n",
    "        xview_container_classes = [\n",
    "            'Container Ship',       # Class 31\n",
    "            'Shipping Container',   # Class 57\n",
    "            'Shipping container lot', # Class 56\n",
    "            'Container Crane',      # Class 35\n",
    "            'Cargo Ship',          # Class 2\n",
    "            'Cargo Plane',         # Class 2\n",
    "            'Cargo Truck',         # Class 10\n",
    "            'Cargo Car',           # Class 19\n",
    "            'Maritime Vessel',     # Class 23\n",
    "            'Barge',               # Class 27\n",
    "            'Crane Truck',         # Class 16\n",
    "            'Reach Stacker',       # Class 36\n",
    "            'Straddle Carrier'     # Class 37\n",
    "        ]\n",
    "        \n",
    "        if self.model_type == 'xview':\n",
    "            conf_threshold = 0.15  # Reasonable threshold for xView\n",
    "            container_classes = xview_container_classes\n",
    "        elif self.model_type == 'dota':\n",
    "            conf_threshold = 0.10\n",
    "            container_classes = list(self.model.names.values())\n",
    "        else:\n",
    "            conf_threshold = 0.05\n",
    "            container_classes = [2, 5, 7, 8]  # car, bus, truck, boat for COCO\n",
    "        \n",
    "        # Use higher image size for better detection\n",
    "        results = self.model(image, conf=conf_threshold, verbose=False, imgsz=1280)\n",
    "        \n",
    "        containers = []\n",
    "        all_detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes if hasattr(result, 'boxes') else result.obb\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    cls = int(box.cls)\n",
    "                    conf = float(box.conf)\n",
    "                    class_name = self.model.names[cls]\n",
    "                    \n",
    "                    # Track all detections for analysis\n",
    "                    all_detections.append({\n",
    "                        'class_id': cls,\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf\n",
    "                    })\n",
    "                    \n",
    "                    # Filter for container-like objects\n",
    "                    is_container = False\n",
    "                    if self.model_type == 'xview':\n",
    "                        is_container = class_name in container_classes\n",
    "                    elif self.model_type == 'dota':\n",
    "                        is_container = True  # Accept all DOTA classes\n",
    "                    else:\n",
    "                        is_container = cls in container_classes\n",
    "                    \n",
    "                    if is_container and conf > conf_threshold:\n",
    "                        containers.append({\n",
    "                            'bbox': box.xyxy.cpu().numpy() if hasattr(box, 'xyxy') else box.xywhr.cpu().numpy(),\n",
    "                            'confidence': conf,\n",
    "                            'class': cls,\n",
    "                            'class_name': class_name\n",
    "                        })\n",
    "        \n",
    "        if show_all_classes:\n",
    "            return len(containers), containers, all_detections\n",
    "        return len(containers), containers\n",
    "    \n",
    "    def analyze_port_activity(self, image_dir, port_name):\n",
    "        \"\"\"Analyze container activity for a specific port\"\"\"\n",
    "        image_files = list(Path(image_dir).glob('*.jp*g')) + list(Path(image_dir).glob('*.png'))\n",
    "        results = []\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            img = self.preprocess_image(img_path)\n",
    "            count, detections = self.detect_containers(img)\n",
    "            \n",
    "            results.append({\n",
    "                'port': port_name,\n",
    "                'image': img_path.name,\n",
    "                'container_count': count,\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingSignalGenerator:\n",
    "    def __init__(self):\n",
    "        self.container_data = pd.DataFrame()\n",
    "        \n",
    "    def load_container_data(self, data):\n",
    "        \"\"\"Load container count data\"\"\"\n",
    "        self.container_data = data\n",
    "        \n",
    "    def calculate_signals(self):\n",
    "        \"\"\"Generate trading signals from container volume changes\"\"\"\n",
    "        if self.container_data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Group by port and calculate rolling statistics\n",
    "        signals = []\n",
    "        \n",
    "        for port in self.container_data['port'].unique():\n",
    "            port_data = self.container_data[self.container_data['port'] == port].copy()\n",
    "            port_data = port_data.sort_values('timestamp')\n",
    "            \n",
    "            # Calculate moving averages and changes\n",
    "            port_data['ma_7'] = port_data['container_count'].rolling(7).mean()\n",
    "            port_data['ma_30'] = port_data['container_count'].rolling(30).mean()\n",
    "            port_data['pct_change'] = port_data['container_count'].pct_change()\n",
    "            \n",
    "            # Generate signals\n",
    "            port_data['signal'] = 0\n",
    "            port_data.loc[port_data['ma_7'] > port_data['ma_30'], 'signal'] = 1  # Bullish\n",
    "            port_data.loc[port_data['ma_7'] < port_data['ma_30'], 'signal'] = -1  # Bearish\n",
    "            \n",
    "            # Warning signal for extremely high volumes\n",
    "            high_threshold = port_data['container_count'].quantile(0.95)\n",
    "            port_data['warning'] = port_data['container_count'] > high_threshold\n",
    "            \n",
    "            signals.append(port_data)\n",
    "        \n",
    "        return pd.concat(signals, ignore_index=True)\n",
    "    \n",
    "    def generate_global_signal(self, port_signals):\n",
    "        \"\"\"Generate global trading signal from all ports\"\"\"\n",
    "        global_signal = port_signals.groupby('timestamp').agg({\n",
    "            'container_count': 'sum',\n",
    "            'signal': 'mean',\n",
    "            'warning': 'any'\n",
    "        }).reset_index()\n",
    "        \n",
    "        global_signal['global_signal'] = np.where(\n",
    "            global_signal['signal'] > 0.2, 1,\n",
    "            np.where(global_signal['signal'] < -0.2, -1, 0)\n",
    "        )\n",
    "        \n",
    "        return global_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector and signal generator\n",
    "detector = ContainerDetector(model_type='dota')\n",
    "signal_gen = TradingSignalGenerator()\n",
    "\n",
    "print(\"‚úì Container detector initialized\")\n",
    "print(\"‚úì Trading signal generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DOTA-Trained Model\n",
    "\n",
    "Three options to get satellite-specific detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download satellite images using GoogleEarthCollector\n",
    "shanghai = ports[0]  # Shanghai port\n",
    "print(f\"\\nDownloading imagery of {shanghai['name']} port...\")\n",
    "print(f\"Using Google Earth Engine with Sentinel-2 satellite\")\n",
    "\n",
    "# Download images using GEE collector\n",
    "downloaded_df = collector.collect_port_images(\n",
    "    port_name=shanghai['name'],\n",
    "    days_back=30,\n",
    "    max_images=10,\n",
    "    max_cloud=10,\n",
    "    source='sentinel2'\n",
    ")\n",
    "\n",
    "if not downloaded_df.empty:\n",
    "    print(f\"\\n‚úì Downloaded {len(downloaded_df)} images\")\n",
    "    \n",
    "    # Convert DataFrame to list format for compatibility with visualization code\n",
    "    downloaded = [\n",
    "        {\n",
    "            'port': row['port'],\n",
    "            'filepath': Path(row['filepath']),\n",
    "            'date': row['date']\n",
    "        }\n",
    "        for _, row in downloaded_df.iterrows()\n",
    "    ]\n",
    "else:\n",
    "    print(\"No images downloaded\")\n",
    "    downloaded = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image Download and Visualization\n",
    "\n",
    "Now let's download actual satellite images and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ALL downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Downloaded {len(downloaded)} satellite images for {shanghai['name']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Calculate grid dimensions for all images\n",
    "    n_images = len(downloaded)\n",
    "    n_cols = min(5, n_images)  # Max 5 columns\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Create grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "    \n",
    "    # Flatten axes array for easy iteration\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    # Display all images\n",
    "    for idx, img_info in enumerate(downloaded):\n",
    "        img = Image.open(img_info['filepath'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_info['port']}\\n{img_info['date']}\", \n",
    "                           fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_images, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sentinel-2 Satellite Imagery - {shanghai[\"name\"]} Port ({n_images} images)', \n",
    "                 fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(f\"\\n Image Summary:\")\n",
    "    print(f\"  ‚Ä¢ Total images: {n_images}\")\n",
    "    print(f\"  ‚Ä¢ Date range: {downloaded[0]['date']} to {downloaded[-1]['date']}\")\n",
    "    print(f\"\\n Image Details:\")\n",
    "    for i, img_info in enumerate(downloaded, 1):\n",
    "        print(f\"  {i:2d}. {img_info['date']} - {img_info['filepath'].name}\")\n",
    "else:\n",
    "    print(\" No images downloaded yet. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on all downloaded satellite images using trained OBB model\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load the best trained OBB model\n",
    "model = YOLO(\"runs/obb/train/weights/best.pt\")\n",
    "\n",
    "# Directory containing satellite images\n",
    "image_dir = Path(\"data/images\")\n",
    "# GEE collector saves images as .png files\n",
    "image_files = list(image_dir.glob(\"*.png\")) + list(image_dir.glob(\"*.jpg\"))\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in {image_dir}\")\n",
    "    print(\"Please run the image download cell first (Cell 10)\")\n",
    "else:\n",
    "    print(f\"Found {len(image_files)} images to process\\n\")\n",
    "    \n",
    "    results_list = []\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        try:\n",
    "            results = model(str(img_path))\n",
    "            # Get results as DataFrame\n",
    "            result_data = results[0].to_df()\n",
    "            \n",
    "            # Handle both polars and pandas DataFrames\n",
    "            if hasattr(result_data, \"to_pandas\"):\n",
    "                df = result_data.to_pandas()\n",
    "            else:\n",
    "                df = pd.DataFrame(result_data)\n",
    "            \n",
    "            df[\"image\"] = img_path.name\n",
    "            results_list.append(df)\n",
    "            print(f\"‚úì Processed {img_path.name} - {len(df)} detections\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    # Combine all results into a single DataFrame\n",
    "    if results_list:\n",
    "        all_detections = pd.concat(results_list, ignore_index=True)\n",
    "        print(\"\\nDetection results for all images:\")\n",
    "        print(all_detections.head())\n",
    "        \n",
    "        # Save to CSV\n",
    "        Path(\"data/results\").mkdir(parents=True, exist_ok=True)\n",
    "        all_detections.to_csv(\"data/results/obb_detections.csv\", index=False)\n",
    "        print(f\"\\n‚úì All detection results saved to data/results/obb_detections.csv\")\n",
    "        print(f\"‚úì Total detections: {len(all_detections)}\")\n",
    "    else:\n",
    "        print(\"\\n No detections made from any images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Detection on Downloaded Images\n",
    "\n",
    "Apply YOLO model to detect containers in the satellite images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run container detection on downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(\"Running YOLO container detection...\")\n",
    "    print(\"NOTE: YOLO is trained on ground photos, not satellite imagery!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    detection_results = []\n",
    "    all_classes_found = {}\n",
    "    \n",
    "    for img_info in downloaded:\n",
    "        # Load and preprocess image\n",
    "        img = detector.preprocess_image(img_info['filepath'])\n",
    "        \n",
    "        # Detect containers and get all detections\n",
    "        count, detections, all_dets = detector.detect_containers(img, show_all_classes=True)\n",
    "        \n",
    "        # Track what classes were found\n",
    "        for det in all_dets:\n",
    "            class_name = det['class_name']\n",
    "            if class_name not in all_classes_found:\n",
    "                all_classes_found[class_name] = 0\n",
    "            all_classes_found[class_name] += 1\n",
    "        \n",
    "        detection_results.append({\n",
    "            'port': img_info['port'],\n",
    "            'date': img_info['date'],\n",
    "            'filepath': img_info['filepath'],\n",
    "            'container_count': count,\n",
    "            'detections': detections,\n",
    "            'all_detections': all_dets\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì {img_info['date']}: {count:3d} vehicles | {len(all_dets):3d} total objects\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Show what YOLO actually detected\n",
    "    print(f\"\\nAll Object Classes Detected (across all {len(downloaded)} images):\")\n",
    "    if all_classes_found:\n",
    "        for class_name, count in sorted(all_classes_found.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  ‚Ä¢ {class_name:20s}: {count:4d} instances\")\n",
    "    else:\n",
    "        print(\"  No objects detected at all!\")\n",
    "        print(\"  This is because:\")\n",
    "        print(\"    - Satellite images are taken from 700km altitude\")\n",
    "        print(\"    - YOLO expects ground-level photos (0-100m)\")\n",
    "        print(\"    - Objects are too small (< 5 pixels)\")\n",
    "    \n",
    "    # Visualize detections on image with most detections\n",
    "    if detection_results:\n",
    "        # Find image with most detections\n",
    "        best_result = max(detection_results, key=lambda x: len(x['all_detections']))\n",
    "        \n",
    "        img = cv2.imread(str(best_result['filepath']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw ALL detections (not just vehicles)\n",
    "        for det in best_result['all_detections'][:50]:  # Limit to 50 for clarity\n",
    "            # Find bounding boxes from the model results\n",
    "            pass\n",
    "        \n",
    "        # Draw vehicle detections with boxes\n",
    "        for det in best_result['detections']:\n",
    "            bbox = det['bbox'][0]\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "            cv2.putText(img, label, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Best Detection Result - {best_result['port']} ({best_result['date']})\\n{best_result['container_count']} vehicles | {len(best_result['all_detections'])} total objects\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        total_vehicles = sum(r['container_count'] for r in detection_results)\n",
    "        total_objects = sum(len(r['all_detections']) for r in detection_results)\n",
    "        print(f\"\\nDetection Summary:\")\n",
    "        print(f\"  ‚Ä¢ Total vehicles detected: {total_vehicles} (across {len(detection_results)} images)\")\n",
    "        print(f\"  ‚Ä¢ Total objects detected: {total_objects}\")\n",
    "        print(f\"  ‚Ä¢ Average per image: {total_vehicles/len(detection_results):.1f} vehicles, {total_objects/len(detection_results):.1f} objects\")\n",
    "        \n",
    "        if total_vehicles == 0:\n",
    "            print(f\"\\nRecommendation:\")\n",
    "            print(f\"  For satellite imagery, you need:\")\n",
    "            print(f\"  1. Models trained on aerial/satellite data (not COCO)\")\n",
    "            print(f\"  2. Higher resolution images (4096x4096 or larger)\")\n",
    "            print(f\"  3. Specialized container detection models\")\n",
    "            print(f\"  4. Or use synthetic data for demonstration (next cell)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images available for detection. Download images first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Signal Generation\n",
    "\n",
    "Generate trading signals from container volume analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trading signals\n",
    "signal_gen.load_container_data(df_containers)\n",
    "port_signals = signal_gen.calculate_signals()\n",
    "global_signals = signal_gen.generate_global_signal(port_signals)\n",
    "\n",
    "print(\"Trading signals generated:\")\n",
    "print(global_signals.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"\\nGenerating trading signal visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Container counts by port\n",
    "print(\"  ‚Ä¢ Plotting container counts by port...\")\n",
    "for port in ports:\n",
    "    port_data = df_containers[df_containers['port'] == port['name']]\n",
    "    axes[0,0].plot(port_data['timestamp'], port_data['container_count'], \n",
    "                   label=f\"{port['name']} ({port['country']})\", marker='o', markersize=3)\n",
    "axes[0,0].set_title('Container Counts by Port', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Date', fontsize=11)\n",
    "axes[0,0].set_ylabel('Container Count', fontsize=11)\n",
    "axes[0,0].legend(loc='best', fontsize=9)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Global container volume\n",
    "print(\"  ‚Ä¢ Plotting global container volume...\")\n",
    "axes[0,1].plot(global_signals['timestamp'], global_signals['container_count'], \n",
    "               color='blue', linewidth=2, marker='o', markersize=4)\n",
    "axes[0,1].set_title('Global Container Volume (All Ports)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Date', fontsize=11)\n",
    "axes[0,1].set_ylabel('Total Container Count', fontsize=11)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].fill_between(global_signals['timestamp'], global_signals['container_count'], \n",
    "                        alpha=0.3, color='blue')\n",
    "\n",
    "# Trading signals\n",
    "print(\"  ‚Ä¢ Plotting trading signals...\")\n",
    "signal_colors = {1: 'green', -1: 'red', 0: 'gray'}\n",
    "for signal_val, color in signal_colors.items():\n",
    "    mask = global_signals['global_signal'] == signal_val\n",
    "    axes[1,0].scatter(global_signals[mask]['timestamp'], \n",
    "                     global_signals[mask]['global_signal'],\n",
    "                     c=color, s=100, alpha=0.7, \n",
    "                     label=f\"{'Buy' if signal_val == 1 else 'Sell' if signal_val == -1 else 'Hold'}\")\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1,0].set_title('Global Trading Signal', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Date', fontsize=11)\n",
    "axes[1,0].set_ylabel('Signal (-1: Sell, 0: Hold, 1: Buy)', fontsize=11)\n",
    "axes[1,0].set_ylim(-1.5, 1.5)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].legend(loc='best')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Warning signals\n",
    "print(\"  ‚Ä¢ Plotting warning signals...\")\n",
    "warning_dates = global_signals[global_signals['warning']]['timestamp']\n",
    "normal_dates = global_signals[~global_signals['warning']]['timestamp']\n",
    "axes[1,1].scatter(warning_dates, [1]*len(warning_dates), \n",
    "                 color='red', s=150, alpha=0.8, marker='X', label='High Volume Warning')\n",
    "axes[1,1].scatter(normal_dates, [0]*len(normal_dates), \n",
    "                 color='green', s=50, alpha=0.5, marker='o', label='Normal Volume')\n",
    "axes[1,1].set_title('High Volume Warning Signals', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Date', fontsize=11)\n",
    "axes[1,1].set_ylabel('Status', fontsize=11)\n",
    "axes[1,1].set_ylim(-0.5, 1.5)\n",
    "axes[1,1].set_yticks([0, 1])\n",
    "axes[1,1].set_yticklabels(['Normal', 'Warning'])\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend(loc='best')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Satellite Container Analysis - Trading Dashboard', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = Path('data/results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save container data and signals\n",
    "df_containers.to_csv(output_dir / 'container_counts.csv', index=False)\n",
    "port_signals.to_csv(output_dir / 'port_signals.csv', index=False)\n",
    "global_signals.to_csv(output_dir / 'global_signals.csv', index=False)\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Total observations: {len(df_containers)}\")\n",
    "print(f\"- Ports analyzed: {df_containers['port'].nunique()}\")\n",
    "print(f\"- Date range: {df_containers['timestamp'].min()} to {df_containers['timestamp'].max()}\")\n",
    "print(f\"- Average daily global volume: {global_signals['container_count'].mean():.0f} containers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
