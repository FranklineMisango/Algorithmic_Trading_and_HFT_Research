{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Container Analysis for Trading Signals\n",
    "\n",
    "This notebook implements the satellite image analysis system described in the research to:\n",
    "1. Collect satellite imagery from major ports\n",
    "2. Use deep learning to count shipping containers\n",
    "3. Generate trading signals from container volume changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ee\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Import our new Google Earth Engine collector\n",
    "from gee_collector import GoogleEarthCollector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo26n-obb.pt\")  # load a pretrained model (recommended for training)\n",
    "results = model.train(data=\"dota8.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Initialize Google Earth Engine with OAuth authentication\n",
    "# Note: Run setup_gee.py first if this is your first time\n",
    "try:\n",
    "    ee.Initialize(project=config['GoogleOAuth']['ProjectId'])\n",
    "    print(\"‚úì Earth Engine initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è  Earth Engine not authenticated yet\")\n",
    "    print(\"Please run: python setup_gee.py\")\n",
    "    print(\"\\nAttempting OAuth authentication now...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project=config['GoogleOAuth']['ProjectId'])\n",
    "    print(\"‚úì Earth Engine authenticated and initialized\")\n",
    "\n",
    "ports = config['ports']\n",
    "print(f\"\\n‚úì Loaded {len(ports)} major ports for analysis:\")\n",
    "for port in ports:\n",
    "    print(f\"  ‚Ä¢ {port['name']:15} ({port['country']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Port Locations\n",
    "\n",
    "Let's visualize the major ports we're analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display port information\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(\"Major Ports for Container Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "for i, port in enumerate(ports, 1):\n",
    "    print(f\"{i}. {port['name']:15} | {port['country']:15} | Lat: {port['lat']:7.4f}, Lon: {port['lon']:8.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create world map with port locations\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "    lon=[p['lon'] for p in ports],\n",
    "    lat=[p['lat'] for p in ports],\n",
    "    text=[f\"{p['name']}<br>{p['country']}\" for p in ports],\n",
    "    mode='markers+text',\n",
    "    marker=dict(\n",
    "        size=15,\n",
    "        color='red',\n",
    "        line=dict(width=2, color='white')\n",
    "    ),\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=12, color='black', family='Arial Black')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Major Ports for Container Analysis',\n",
    "    geo=dict(\n",
    "        projection_type='natural earth',\n",
    "        showland=True,\n",
    "        landcolor='rgb(243, 243, 243)',\n",
    "        coastlinecolor='rgb(204, 204, 204)',\n",
    "        showcountries=True,\n",
    "        countrycolor='rgb(204, 204, 204)',\n",
    "    ),\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize downloaded images\n",
    "def show_port_images(df, max_images=6):\n",
    "    \"\"\"Display grid of downloaded satellite images\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No images to display\")\n",
    "        return\n",
    "    \n",
    "    # Take first max_images\n",
    "    sample_df = df.head(max_images)\n",
    "    \n",
    "    # Create subplot grid\n",
    "    n_images = len(sample_df)\n",
    "    cols = 3\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample_df.iterrows()):\n",
    "        ax = axes[idx // cols, idx % cols]\n",
    "        \n",
    "        # Load and display image\n",
    "        img = Image.open(row['filepath'])\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{row['port']}\\n{row['date']}\\nCloud: {row['cloud_cover']:.1f}%\", \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_images, rows * cols):\n",
    "        axes[idx // cols, idx % cols].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display images from all ports download\n",
    "if 'df_all_ports' in locals() and not df_all_ports.empty:\n",
    "    print(\"Sample of downloaded satellite images:\")\n",
    "    show_port_images(df_all_ports, max_images=6)\n",
    "elif 'df_shanghai' in locals() and not df_shanghai.empty:\n",
    "    print(\"Shanghai port satellite images:\")\n",
    "    show_port_images(df_shanghai, max_images=6)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images available. Run download cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Downloaded Images\n",
    "\n",
    "Let's preview the downloaded satellite images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images for all ports\n",
    "print(\"Downloading images for all ports...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "df_all_ports = collector.collect_port_images(\n",
    "    days_back=30,          # Last 30 days\n",
    "    max_images=3,          # 3 images per port\n",
    "    max_cloud=10,          # Max 10% cloud cover\n",
    "    source='sentinel2'     # Sentinel-2 (10m resolution)\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "if not df_all_ports.empty:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úì DOWNLOAD COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Summary by port\n",
    "    summary = df_all_ports.groupby('port').agg({\n",
    "        'date': 'count',\n",
    "        'cloud_cover': 'mean'\n",
    "    }).rename(columns={'date': 'images', 'cloud_cover': 'avg_cloud%'})\n",
    "    \n",
    "    print(\"\\nSummary by port:\")\n",
    "    display(summary)\n",
    "    \n",
    "    print(f\"\\nTotal images downloaded: {len(df_all_ports)}\")\n",
    "    print(f\"Date range: {df_all_ports['date'].min()} to {df_all_ports['date'].max()}\")\n",
    "    print(f\"Images saved to: data/images/\")\n",
    "    print(f\"Metadata saved to: data/results/image_metadata.csv\")\n",
    "    \n",
    "    # Show sample of downloaded files\n",
    "    print(\"\\nSample files:\")\n",
    "    display(df_all_ports[['port', 'country', 'date', 'cloud_cover', 'filepath']].head(10))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No images downloaded for any port\")\n",
    "    print(\"Check date range and cloud cover settings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Download Images for All Ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test download for Shanghai port\n",
    "print(\"Downloading images for Shanghai...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_shanghai = collector.collect_port_images(\n",
    "    port_name='Shanghai',\n",
    "    days_back=60,          # Look back 60 days\n",
    "    max_images=5,          # Download up to 5 images\n",
    "    max_cloud=15,          # Max 15% cloud cover\n",
    "    source='sentinel2'     # Use Sentinel-2 (10m resolution)\n",
    ")\n",
    "\n",
    "# Display results\n",
    "if not df_shanghai.empty:\n",
    "    print(\"\\n‚úì Download complete!\")\n",
    "    print(\"\\nDownloaded images:\")\n",
    "    display(df_shanghai[['port', 'date', 'cloud_cover', 'resolution_m', 'filepath']])\n",
    "    \n",
    "    # Show image count by date\n",
    "    print(f\"\\nTotal images: {len(df_shanghai)}\")\n",
    "    print(f\"Date range: {df_shanghai['date'].min()} to {df_shanghai['date'].max()}\")\n",
    "    print(f\"Average cloud cover: {df_shanghai['cloud_cover'].mean():.1f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No images found. Try:\")\n",
    "    print(\"  ‚Ä¢ Increasing days_back (e.g., 90)\")\n",
    "    print(\"  ‚Ä¢ Increasing max_cloud (e.g., 20)\")\n",
    "    print(\"  ‚Ä¢ Using a different port\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Download Images for a Single Port (Quick Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Google Earth Engine collector\n",
    "# authenticate=False because we already did OAuth authentication above\n",
    "collector = GoogleEarthCollector(authenticate=False)\n",
    "\n",
    "print(\"‚úì Google Earth Engine collector ready!\")\n",
    "print(\"\\nAvailable features:\")\n",
    "print(\"  ‚Ä¢ Sentinel-2 imagery (10m resolution)\")\n",
    "print(\"  ‚Ä¢ Landsat 8/9 imagery (30m resolution)\")\n",
    "print(\"  ‚Ä¢ Automatic cloud filtering\")\n",
    "print(\"  ‚Ä¢ Metadata tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Satellite Images with Google Earth Engine\n",
    "\n",
    "Now we'll use the new Google Earth Engine collector to download high-quality satellite imagery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Legacy Data Collector (Optional)\n",
    "\n",
    "The old SatelliteDataCollector is kept for reference, but we now use GoogleEarthCollector above.\n",
    "You can skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainerDetector:\n",
    "    def __init__(self, model_type='dota'):\n",
    "        \"\"\"\n",
    "        Initialize container detector with satellite-specific models\n",
    "        \n",
    "        Args:\n",
    "            model_type: 'dota' (aerial detection) or 'yolo-coco' (ground-level)\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        if model_type == 'dota':\n",
    "            # Try to load DOTA-trained YOLO model for aerial imagery\n",
    "            try:\n",
    "                # First try custom DOTA model if available\n",
    "                self.model = YOLO('yolov8n-dota.pt')\n",
    "                print(\"‚úì Loaded YOLOv8 trained on DOTA dataset\")\n",
    "            except:\n",
    "                try:\n",
    "                    # Try DOTAv2 model\n",
    "                    self.model = YOLO('yolov8n-dotav2.pt')\n",
    "                    print(\"‚úì Loaded YOLOv8 trained on DOTAv2 dataset\")\n",
    "                except:\n",
    "                    # Fall back to downloading from Ultralytics hub or training\n",
    "                    print(\"‚ö†Ô∏è  DOTA model not found locally\")\n",
    "                    print(\"   Attempting to use YOLOv8 with satellite-optimized settings...\")\n",
    "                    self.model = YOLO('yolov8n.pt')\n",
    "                    self.model_type = 'yolo-optimized'\n",
    "        else:\n",
    "            # Standard COCO-trained model\n",
    "            self.model = YOLO('yolov8n.pt')\n",
    "            print(\"‚úì Loaded standard YOLOv8 (COCO dataset)\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess satellite image for container detection\"\"\"\n",
    "        img = cv2.imread(str(image_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # For satellite imagery, enhance contrast\n",
    "        if self.model_type in ['dota', 'yolo-optimized']:\n",
    "            # Convert to LAB color space for better contrast\n",
    "            lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "            l, a, b = cv2.split(lab)\n",
    "            \n",
    "            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            l = clahe.apply(l)\n",
    "            \n",
    "            # Merge and convert back\n",
    "            enhanced = cv2.merge([l, a, b])\n",
    "            img = cv2.cvtColor(enhanced, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def detect_containers(self, image, show_all_classes=False):\n",
    "        \"\"\"Detect and count containers in satellite image\"\"\"\n",
    "        \n",
    "        if self.model_type == 'dota':\n",
    "            # DOTA dataset classes for aerial imagery\n",
    "            # Classes include: ship, harbor, vehicle, plane, storage-tank, etc.\n",
    "            conf_threshold = 0.25\n",
    "            container_classes = ['ship', 'harbor', 'large-vehicle', 'small-vehicle', 'storage-tank']\n",
    "        else:\n",
    "            # Standard COCO with optimized settings for satellite\n",
    "            conf_threshold = 0.05  # Very low threshold for tiny objects\n",
    "            container_classes = [2, 5, 7, 8]  # car, bus, truck, boat\n",
    "        \n",
    "        results = self.model(image, conf=conf_threshold, verbose=False, imgsz=1024)\n",
    "        \n",
    "        containers = []\n",
    "        all_detections = []\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for box in boxes:\n",
    "                    cls = int(box.cls)\n",
    "                    conf = float(box.conf)\n",
    "                    class_name = self.model.names[cls]\n",
    "                    \n",
    "                    # Track all detections for analysis\n",
    "                    all_detections.append({\n",
    "                        'class_id': cls,\n",
    "                        'class_name': class_name,\n",
    "                        'confidence': conf\n",
    "                    })\n",
    "                    \n",
    "                    # Filter for container-like objects\n",
    "                    is_container = False\n",
    "                    if self.model_type == 'dota':\n",
    "                        is_container = class_name in container_classes\n",
    "                    else:\n",
    "                        is_container = cls in container_classes\n",
    "                    \n",
    "                    if is_container and conf > conf_threshold:\n",
    "                        containers.append({\n",
    "                            'bbox': box.xyxy.cpu().numpy(),\n",
    "                            'confidence': conf,\n",
    "                            'class': cls,\n",
    "                            'class_name': class_name\n",
    "                        })\n",
    "        \n",
    "        if show_all_classes:\n",
    "            return len(containers), containers, all_detections\n",
    "        return len(containers), containers\n",
    "    \n",
    "    def analyze_port_activity(self, image_dir, port_name):\n",
    "        \"\"\"Analyze container activity for a specific port\"\"\"\n",
    "        image_files = list(Path(image_dir).glob('*.jp*g'))\n",
    "        results = []\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            img = self.preprocess_image(img_path)\n",
    "            count, detections = self.detect_containers(img)\n",
    "            \n",
    "            results.append({\n",
    "                'port': port_name,\n",
    "                'image': img_path.name,\n",
    "                'container_count': count,\n",
    "                'timestamp': datetime.now()\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingSignalGenerator:\n",
    "    def __init__(self):\n",
    "        self.container_data = pd.DataFrame()\n",
    "        \n",
    "    def load_container_data(self, data):\n",
    "        \"\"\"Load container count data\"\"\"\n",
    "        self.container_data = data\n",
    "        \n",
    "    def calculate_signals(self):\n",
    "        \"\"\"Generate trading signals from container volume changes\"\"\"\n",
    "        if self.container_data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Group by port and calculate rolling statistics\n",
    "        signals = []\n",
    "        \n",
    "        for port in self.container_data['port'].unique():\n",
    "            port_data = self.container_data[self.container_data['port'] == port].copy()\n",
    "            port_data = port_data.sort_values('timestamp')\n",
    "            \n",
    "            # Calculate moving averages and changes\n",
    "            port_data['ma_7'] = port_data['container_count'].rolling(7).mean()\n",
    "            port_data['ma_30'] = port_data['container_count'].rolling(30).mean()\n",
    "            port_data['pct_change'] = port_data['container_count'].pct_change()\n",
    "            \n",
    "            # Generate signals\n",
    "            port_data['signal'] = 0\n",
    "            port_data.loc[port_data['ma_7'] > port_data['ma_30'], 'signal'] = 1  # Bullish\n",
    "            port_data.loc[port_data['ma_7'] < port_data['ma_30'], 'signal'] = -1  # Bearish\n",
    "            \n",
    "            # Warning signal for extremely high volumes\n",
    "            high_threshold = port_data['container_count'].quantile(0.95)\n",
    "            port_data['warning'] = port_data['container_count'] > high_threshold\n",
    "            \n",
    "            signals.append(port_data)\n",
    "        \n",
    "        return pd.concat(signals, ignore_index=True)\n",
    "    \n",
    "    def generate_global_signal(self, port_signals):\n",
    "        \"\"\"Generate global trading signal from all ports\"\"\"\n",
    "        global_signal = port_signals.groupby('timestamp').agg({\n",
    "            'container_count': 'sum',\n",
    "            'signal': 'mean',\n",
    "            'warning': 'any'\n",
    "        }).reset_index()\n",
    "        \n",
    "        global_signal['global_signal'] = np.where(\n",
    "            global_signal['signal'] > 0.2, 1,\n",
    "            np.where(global_signal['signal'] < -0.2, -1, 0)\n",
    "        )\n",
    "        \n",
    "        return global_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install DOTA-Trained Model\n",
    "\n",
    "Three options to get satellite-specific detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "shanghai = ports[0]  # Shanghai port\n",
    "print(f\"\\nSearching for imagery of {shanghai['name']} port...\")\n",
    "print(f\"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Get collection info\n",
    "collection, roi = collector.get_port_imagery(\n",
    "    shanghai, \n",
    "    start_date.strftime('%Y-%m-%d'),\n",
    "    end_date.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "count = collection.size().getInfo()\n",
    "print(f\"‚úì Found {count} Sentinel-2 images with <20% cloud cover\")\n",
    "\n",
    "# Download more images (increased from 3 to 20)\n",
    "if count > 0:\n",
    "    print(\"\\nDownloading images...\")\n",
    "    downloaded = collector.collect_port_images(shanghai, \n",
    "                                                start_date.strftime('%Y-%m-%d'),\n",
    "                                                end_date.strftime('%Y-%m-%d'),\n",
    "                                                max_images=1000)  # Download up to 1000 images\n",
    "    print(f\"\\n‚úì Downloaded {len(downloaded)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Image Download and Visualization\n",
    "\n",
    "Now let's download actual satellite images and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ALL downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Downloaded {len(downloaded)} satellite images for {shanghai['name']}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Calculate grid dimensions for all images\n",
    "    n_images = len(downloaded)\n",
    "    n_cols = min(5, n_images)  # Max 5 columns\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Create grid of subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "    \n",
    "    # Flatten axes array for easy iteration\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else axes\n",
    "    \n",
    "    # Display all images\n",
    "    for idx, img_info in enumerate(downloaded):\n",
    "        img = Image.open(img_info['filepath'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"{img_info['port']}\\n{img_info['date']}\", \n",
    "                           fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_images, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Sentinel-2 Satellite Imagery - {shanghai[\"name\"]} Port ({n_images} images)', \n",
    "                 fontsize=14, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(f\"\\n Image Summary:\")\n",
    "    print(f\"  ‚Ä¢ Total images: {n_images}\")\n",
    "    print(f\"  ‚Ä¢ Date range: {downloaded[0]['date']} to {downloaded[-1]['date']}\")\n",
    "    print(f\"\\n Image Details:\")\n",
    "    for i, img_info in enumerate(downloaded, 1):\n",
    "        print(f\"  {i:2d}. {img_info['date']} - {img_info['filepath'].name}\")\n",
    "else:\n",
    "    print(\" No images downloaded yet. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on all downloaded satellite images using trained OBB model\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl  # Add polars for DataFrame conversion if needed\n",
    "\n",
    "# Load the best trained OBB model\n",
    "model = YOLO(\"runs/obb/train/weights/best.pt\")\n",
    "\n",
    "# Directory containing satellite images (update if needed)\n",
    "image_dir = Path(\"data/images\")\n",
    "image_files = list(image_dir.glob(\"*.jpg\"))\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = model(str(img_path))\n",
    "    df_polars = results[0].to_df()\n",
    "    # Convert Polars DataFrame to pandas DataFrame if possible\n",
    "    df = df_polars.to_pandas() if hasattr(df_polars, \"to_pandas\") else pd.DataFrame(df_polars)\n",
    "    df[\"image\"] = img_path.name\n",
    "    results_list.append(df)\n",
    "    print(f\"‚úì Processed {img_path.name} - {len(df)} detections\")\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "if results_list:\n",
    "    all_detections = pd.concat(results_list, ignore_index=True)\n",
    "    print(\"\\nDetection results for all images:\")\n",
    "    print(all_detections.head())\n",
    "    # Optionally, save to CSV\n",
    "    Path(\"data/results\").mkdir(parents=True, exist_ok=True)\n",
    "    all_detections.to_csv(\"data/results/obb_detections.csv\", index=False)\n",
    "    print(\"\\nAll detection results saved to data/results/obb_detections.csv\")\n",
    "else:\n",
    "    print(\"No images found or no detections made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container Detection on Downloaded Images\n",
    "\n",
    "Apply YOLO model to detect containers in the satellite images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run container detection on downloaded images\n",
    "if 'downloaded' in dir() and len(downloaded) > 0:\n",
    "    print(\"Running YOLO container detection...\")\n",
    "    print(\"‚ö†Ô∏è  NOTE: YOLO is trained on ground photos, not satellite imagery!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    detection_results = []\n",
    "    all_classes_found = {}\n",
    "    \n",
    "    for img_info in downloaded:\n",
    "        # Load and preprocess image\n",
    "        img = detector.preprocess_image(img_info['filepath'])\n",
    "        \n",
    "        # Detect containers and get all detections\n",
    "        count, detections, all_dets = detector.detect_containers(img, show_all_classes=True)\n",
    "        \n",
    "        # Track what classes were found\n",
    "        for det in all_dets:\n",
    "            class_name = det['class_name']\n",
    "            if class_name not in all_classes_found:\n",
    "                all_classes_found[class_name] = 0\n",
    "            all_classes_found[class_name] += 1\n",
    "        \n",
    "        detection_results.append({\n",
    "            'port': img_info['port'],\n",
    "            'date': img_info['date'],\n",
    "            'filepath': img_info['filepath'],\n",
    "            'container_count': count,\n",
    "            'detections': detections,\n",
    "            'all_detections': all_dets\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úì {img_info['date']}: {count:3d} vehicles | {len(all_dets):3d} total objects\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Show what YOLO actually detected\n",
    "    print(f\"\\nüîç All Object Classes Detected (across all {len(downloaded)} images):\")\n",
    "    if all_classes_found:\n",
    "        for class_name, count in sorted(all_classes_found.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  ‚Ä¢ {class_name:20s}: {count:4d} instances\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è  No objects detected at all!\")\n",
    "        print(\"  This is because:\")\n",
    "        print(\"    - Satellite images are taken from 700km altitude\")\n",
    "        print(\"    - YOLO expects ground-level photos (0-100m)\")\n",
    "        print(\"    - Objects are too small (< 5 pixels)\")\n",
    "    \n",
    "    # Visualize detections on image with most detections\n",
    "    if detection_results:\n",
    "        # Find image with most detections\n",
    "        best_result = max(detection_results, key=lambda x: len(x['all_detections']))\n",
    "        \n",
    "        img = cv2.imread(str(best_result['filepath']))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Draw ALL detections (not just vehicles)\n",
    "        for det in best_result['all_detections'][:50]:  # Limit to 50 for clarity\n",
    "            # Find bounding boxes from the model results\n",
    "            pass\n",
    "        \n",
    "        # Draw vehicle detections with boxes\n",
    "        for det in best_result['detections']:\n",
    "            bbox = det['bbox'][0]\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "            label = f\"{det['class_name']} {det['confidence']:.2f}\"\n",
    "            cv2.putText(img, label, (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        # Display\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Best Detection Result - {best_result['port']} ({best_result['date']})\\n{best_result['container_count']} vehicles | {len(best_result['all_detections'])} total objects\", \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        total_vehicles = sum(r['container_count'] for r in detection_results)\n",
    "        total_objects = sum(len(r['all_detections']) for r in detection_results)\n",
    "        print(f\"\\nüìä Detection Summary:\")\n",
    "        print(f\"  ‚Ä¢ Total vehicles detected: {total_vehicles} (across {len(detection_results)} images)\")\n",
    "        print(f\"  ‚Ä¢ Total objects detected: {total_objects}\")\n",
    "        print(f\"  ‚Ä¢ Average per image: {total_vehicles/len(detection_results):.1f} vehicles, {total_objects/len(detection_results):.1f} objects\")\n",
    "        \n",
    "        if total_vehicles == 0:\n",
    "            print(f\"\\nüí° Recommendation:\")\n",
    "            print(f\"  For satellite imagery, you need:\")\n",
    "            print(f\"  1. Models trained on aerial/satellite data (not COCO)\")\n",
    "            print(f\"  2. Higher resolution images (4096x4096 or larger)\")\n",
    "            print(f\"  3. Specialized container detection models\")\n",
    "            print(f\"  4. Or use synthetic data for demonstration (next cell)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images available for detection. Download images first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate container detection results (replace with actual image analysis)\n",
    "print(\"Generating synthetic container count data for demonstration...\")\n",
    "print(f\"Ports included: {', '.join([p['name'] for p in ports])}\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Generate synthetic container count data for demonstration\n",
    "container_data = []\n",
    "for port in ports:\n",
    "    base_count = np.random.randint(1000, 5000)\n",
    "    print(f\"  ‚Ä¢ {port['name']:15} - Base count: {base_count:,} containers\")\n",
    "    \n",
    "    for date in dates:\n",
    "        # Add trend and noise\n",
    "        trend = np.sin(len(container_data) * 0.1) * 500\n",
    "        noise = np.random.normal(0, 200)\n",
    "        count = max(0, int(base_count + trend + noise))\n",
    "        \n",
    "        container_data.append({\n",
    "            'port': port['name'],\n",
    "            'timestamp': date,\n",
    "            'container_count': count\n",
    "        })\n",
    "\n",
    "df_containers = pd.DataFrame(container_data)\n",
    "print(f\"\\n‚úì Generated {len(df_containers):,} container count observations\")\n",
    "print(f\"‚úì Date range: {dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nFirst 10 observations:\")\n",
    "print(df_containers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading Signal Generation\n",
    "\n",
    "Generate trading signals from container volume analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trading signals\n",
    "signal_gen.load_container_data(df_containers)\n",
    "port_signals = signal_gen.calculate_signals()\n",
    "global_signals = signal_gen.generate_global_signal(port_signals)\n",
    "\n",
    "print(\"Trading signals generated:\")\n",
    "print(global_signals.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"\\nGenerating trading signal visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Container counts by port\n",
    "print(\"  ‚Ä¢ Plotting container counts by port...\")\n",
    "for port in ports:\n",
    "    port_data = df_containers[df_containers['port'] == port['name']]\n",
    "    axes[0,0].plot(port_data['timestamp'], port_data['container_count'], \n",
    "                   label=f\"{port['name']} ({port['country']})\", marker='o', markersize=3)\n",
    "axes[0,0].set_title('Container Counts by Port', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Date', fontsize=11)\n",
    "axes[0,0].set_ylabel('Container Count', fontsize=11)\n",
    "axes[0,0].legend(loc='best', fontsize=9)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Global container volume\n",
    "print(\"  ‚Ä¢ Plotting global container volume...\")\n",
    "axes[0,1].plot(global_signals['timestamp'], global_signals['container_count'], \n",
    "               color='blue', linewidth=2, marker='o', markersize=4)\n",
    "axes[0,1].set_title('Global Container Volume (All Ports)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Date', fontsize=11)\n",
    "axes[0,1].set_ylabel('Total Container Count', fontsize=11)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "axes[0,1].fill_between(global_signals['timestamp'], global_signals['container_count'], \n",
    "                        alpha=0.3, color='blue')\n",
    "\n",
    "# Trading signals\n",
    "print(\"  ‚Ä¢ Plotting trading signals...\")\n",
    "signal_colors = {1: 'green', -1: 'red', 0: 'gray'}\n",
    "for signal_val, color in signal_colors.items():\n",
    "    mask = global_signals['global_signal'] == signal_val\n",
    "    axes[1,0].scatter(global_signals[mask]['timestamp'], \n",
    "                     global_signals[mask]['global_signal'],\n",
    "                     c=color, s=100, alpha=0.7, \n",
    "                     label=f\"{'Buy' if signal_val == 1 else 'Sell' if signal_val == -1 else 'Hold'}\")\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[1,0].set_title('Global Trading Signal', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Date', fontsize=11)\n",
    "axes[1,0].set_ylabel('Signal (-1: Sell, 0: Hold, 1: Buy)', fontsize=11)\n",
    "axes[1,0].set_ylim(-1.5, 1.5)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].legend(loc='best')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Warning signals\n",
    "print(\"  ‚Ä¢ Plotting warning signals...\")\n",
    "warning_dates = global_signals[global_signals['warning']]['timestamp']\n",
    "normal_dates = global_signals[~global_signals['warning']]['timestamp']\n",
    "axes[1,1].scatter(warning_dates, [1]*len(warning_dates), \n",
    "                 color='red', s=150, alpha=0.8, marker='X', label='High Volume Warning')\n",
    "axes[1,1].scatter(normal_dates, [0]*len(normal_dates), \n",
    "                 color='green', s=50, alpha=0.5, marker='o', label='Normal Volume')\n",
    "axes[1,1].set_title('High Volume Warning Signals', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Date', fontsize=11)\n",
    "axes[1,1].set_ylabel('Status', fontsize=11)\n",
    "axes[1,1].set_ylim(-0.5, 1.5)\n",
    "axes[1,1].set_yticks([0, 1])\n",
    "axes[1,1].set_yticklabels(['Normal', 'Warning'])\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend(loc='best')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('Satellite Container Analysis - Trading Dashboard', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Visualizations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_dir = Path('data/results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save container data and signals\n",
    "df_containers.to_csv(output_dir / 'container_counts.csv', index=False)\n",
    "port_signals.to_csv(output_dir / 'port_signals.csv', index=False)\n",
    "global_signals.to_csv(output_dir / 'global_signals.csv', index=False)\n",
    "\n",
    "print(f\"Results saved to {output_dir}\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"- Total observations: {len(df_containers)}\")\n",
    "print(f\"- Ports analyzed: {df_containers['port'].nunique()}\")\n",
    "print(f\"- Date range: {df_containers['timestamp'].min()} to {df_containers['timestamp'].max()}\")\n",
    "print(f\"- Average daily global volume: {global_signals['container_count'].mean():.0f} containers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
