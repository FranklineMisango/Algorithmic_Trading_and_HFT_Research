{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "377b6f40",
   "metadata": {},
   "source": [
    "# This simple snippet is to read the crypto_data folder and combine the checkpoints plus the final 2h dataset to a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36c7c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "339cad35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "                 timestamp  bid_price  ask_price  trade_price    volume  \\\n",
      "0  2025-04-16 18:41:26.309        NaN     0.0164          NaN    0.0000   \n",
      "1  2025-04-16 18:41:26.409        NaN     0.0164          NaN    0.0000   \n",
      "2  2025-04-16 18:41:26.509     0.0145     0.0164          NaN    0.0000   \n",
      "3  2025-04-16 18:41:26.609     0.0145     0.0167       0.0160  123.8672   \n",
      "4  2025-04-16 18:41:26.673     0.0145     0.0167       0.0160  123.8672   \n",
      "5  2025-04-16 18:41:26.709     0.0160     0.0161       0.0160   21.7105   \n",
      "6  2025-04-16 18:41:26.741     0.0160     0.0161       0.0160   21.7105   \n",
      "7  2025-04-16 18:41:26.784     0.0160     0.0161       0.0161   21.7105   \n",
      "8  2025-04-16 18:41:26.809     0.0160     0.0161       0.0161    0.0000   \n",
      "9  2025-04-16 18:41:26.909     0.0160     0.0161       0.0160  146.5408   \n",
      "\n",
      "   mid_price  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5    0.01605  \n",
      "6    0.01605  \n",
      "7    0.01605  \n",
      "8    0.01605  \n",
      "9    0.01605  \n"
     ]
    }
   ],
   "source": [
    "folder_path = 'crypto_data'\n",
    "if not os.path.exists(folder_path):\n",
    "    raise FileNotFoundError(f\"The folder '{folder_path}' does not exist.\")\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "if not csv_files:\n",
    "    raise ValueError(\"No CSV files found in the specified folder.\")\n",
    "csv_files_sorted = sorted(\n",
    "    csv_files,\n",
    "    key=lambda x: int(x.split('_checkpoint_')[1].split('_')[0]) if 'checkpoint' in x else float('inf')\n",
    ")\n",
    "combined_df = pd.DataFrame()\n",
    "for file in csv_files_sorted:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    try:\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file}: {e}\")\n",
    "print(\"Combined DataFrame:\")\n",
    "combined_df.to_csv('HFT_100ms_unresampled_data_combined_data.csv', index=False)\n",
    "print(combined_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89959d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b53cc83d",
   "metadata": {},
   "source": [
    "# Resampling to 1s for rapid check of a trend at a particular duration ie 2 hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79792a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  bid_price  ask_price  trade_price       volume  \\\n",
      "0 2025-04-16 18:41:26      0.016     0.0161        0.016    459.40670   \n",
      "1 2025-04-16 18:41:27      0.016     0.0161        0.016   3298.51151   \n",
      "2 2025-04-16 18:41:28      0.016     0.0161        0.016   2543.05790   \n",
      "3 2025-04-16 18:41:29      0.016     0.0161        0.016   1520.15988   \n",
      "4 2025-04-16 18:41:30      0.016     0.0160        0.016  24966.98970   \n",
      "\n",
      "   mid_price  \n",
      "0    0.01605  \n",
      "1    0.01605  \n",
      "2    0.01605  \n",
      "3    0.01605  \n",
      "4    0.01600  \n",
      "Original rows: 50223\n",
      "Resampled rows: 3600\n"
     ]
    }
   ],
   "source": [
    "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
    "combined_df = combined_df.set_index('timestamp')\n",
    "resampled_df = combined_df.resample('1s').agg({\n",
    "    'bid_price': 'last',      # Last bid price in the second\n",
    "    'ask_price': 'last',      # Last ask price in the second\n",
    "    'trade_price': 'last',    # Last trade price in the second\n",
    "    'volume': 'sum',          # Sum of volume within the second\n",
    "    'mid_price': 'last'       # Last mid price in the second\n",
    "})\n",
    "\n",
    "resampled_df = resampled_df.reset_index()\n",
    "\n",
    "# Show the result\n",
    "print(resampled_df.head())\n",
    "\n",
    "# Check the reduction in rows\n",
    "print(f\"Original rows: {len(combined_df)}\")\n",
    "print(f\"Resampled rows: {len(resampled_df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577f36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 1s data : \n",
    "resampled_df.to_csv('HFT_1_hr_combined_crypto_data_1s.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4c704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv('HFT_1_hr_combined_crypto_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
