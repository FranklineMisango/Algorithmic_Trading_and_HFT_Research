# -*- coding: utf-8 -*-
"""Classic_Benjamin_Graham_PE_Defensive_Strategy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ln2VSIK4CTI9xPta7fBik8rKdZxDEy_1
"""

!pip install yfinance pandas-datareader cvxpy statsmodels matplotlib scikit-learn

"""
Graham Defensive Stock Strategy Backtester
Version: 1.1 (2025-04-14)
"""
import numpy as np
import pandas as pd
import yfinance as yf
import pandas_datareader.data as web
from datetime import datetime
from cvxpy import Variable, Minimize, sum_squares, Problem
import matplotlib.pyplot as plt
from statsmodels.tsa.x13 import x13_arima_analysis

# Configuration
START_DATE = '2000-01-01'
END_DATE = '2025-04-14'
INITIAL_CAPITAL = 10000
CPI_SERIES = 'CPIAUCSL'

def fetch_inflation_data():
    """Fetch and preprocess CPI data from FRED"""
    cpi = web.DataReader(CPI_SERIES, 'fred', START_DATE, END_DATE)
    return x13_arima_analysis(cpi[CPI_SERIES].dropna()).results.actual

def adjust_for_inflation(series, cpi):
    """Adjust nominal values using CPI"""
    base_cpi = cpi.iloc[0]
    return series * (cpi / base_cpi).values

class GrahamBacktester:
    def __init__(self):
        self.cpi = fetch_inflation_data()
        self.sp500 = self._get_sp500_constituents()
        self.data = self._fetch_fundamental_data()
        self._preprocess_data()

    def _get_sp500_constituents(self):
        """Get current S&P 500 constituents"""
        return pd.read_html(
            'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        )[0]['Symbol'].tolist()

    def _fetch_fundamental_data(self):
        """Fetch historical fundamental data"""
        data = yf.download(
            self.sp500,
            start=START_DATE,
            end=END_DATE,
            threads=True,
            group_by='ticker'
        )
        return data.swaplevel(axis=1).sort_index(axis=1)

    def _preprocess_data(self):
        """Clean and normalize data"""
        # Inflation adjustment
        sales = self.data.xs('Revenue', axis=1, level=1)
        self.data['SalesAdj'] = adjust_for_inflation(sales, self.cpi)

        # Calculate financial ratios
        self.data['PE'] = self.data.xs('Close', axis=1) / self.data.xs('EPS', axis=1)
        self.data['PB'] = self.data.xs('Close', axis=1) / self.data.xs('Book Value', axis=1)
        self.data['CurrentRatio'] = (
            self.data.xs('Current Assets', axis=1) /
            self.data.xs('Current Liabilities', axis=1)
        )

    def _graham_filters(self, date):
        """Dynamic Graham criteria filters"""
        dt = pd.to_datetime(date)
        filtered = pd.DataFrame(index=self.sp500)

        # Size filter (inflation-adjusted)
        filtered['size'] = self.data['SalesAdj'].loc[:dt].iloc[-1] >= 2e9

        # Valuation filters
        pe_quantile = self.data['PE'].loc[:dt].expanding().quantile(0.25)
        filtered['pe'] = self.data['PE'].loc[dt] <= pe_quantile.iloc[-1]
        filtered['pb'] = self.data['PB'].loc[dt] <= 1.5

        # Financial health
        filtered['current_ratio'] = self.data['CurrentRatio'].loc[dt] >= 2

        return filtered.all(axis=1)

    def _risk_parity_weights(self, returns):
        """Risk parity portfolio optimization"""
        cov = returns.cov().values
        n = cov.shape[0]
        w = Variable(n)
        risk_contrib = (w @ cov) * w  # Marginal risk contribution

        prob = Problem(
            Minimize(sum_squares(risk_contrib - 1/n)),
            [sum(w) == 1, w >= 0]
        )
        prob.solve(solver='ECOS')
        return np.array(w.value).flatten()

    def backtest(self):
        """Main backtesting engine"""
        portfolio = pd.Series(index=self.data.index, dtype=float)
        portfolio.iloc[0] = INITIAL_CAPITAL

        for i in range(1, len(self.data.index)):
            dt = self.data.index[i]
            eligible = self._graham_filters(dt)

            if eligible.any():
                returns = self.data.xs('Close', axis=1).pct_change().loc[:dt]
                weights = self._risk_parity_weights(returns[eligible])
                port_return = np.dot(
                    returns.loc[dt, eligible].fillna(0).values,
                    weights
                )
                portfolio.iloc[i] = portfolio.iloc[i-1] * (1 + port_return)
            else:
                portfolio.iloc[i] = portfolio.iloc[i-1]

        return portfolio

    def analyze_performance(self, portfolio):
        """Performance analysis and visualization"""
        # Calculate metrics
        returns = portfolio.pct_change().dropna()
        sharpe = np.sqrt(252) * returns.mean() / returns.std()
        max_dd = (portfolio / portfolio.cummax() - 1).min()

        # Fama-French analysis
        ff = web.DataReader('F-F_Research_Data_Factors', 'famafrench')[0]
        merged = pd.concat([returns, ff], axis=1).dropna()
        model = sm.OLS(
            merged['Portfolio'] - merged['RF'],
            merged[['Mkt-RF', 'SMB', 'HML']]
        ).fit()

        # Plotting
        plt.figure(figsize=(12, 6))
        portfolio.plot(label='Graham Strategy')
        self.data.xs('Close', axis=1)['SPY'].plot(label='S&P 500')
        plt.title(f"Performance Comparison\nSharpe: {sharpe:.2f} | Max DD: {max_dd:.2%}")
        plt.legend()
        plt.show()

        return model.summary()

if __name__ == "__main__":
    backtester = GrahamBacktester()
    results = backtester.backtest()
    analysis = backtester.analyze_performance(results)
    print(analysis)