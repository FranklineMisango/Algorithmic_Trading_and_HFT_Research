{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536ff1ba",
   "metadata": {},
   "source": [
    "# Volts Volatility-Based Predictive Trading Strategy\n",
    "\n",
    "This notebook implements the complete Volts strategy pipeline:\n",
    "\n",
    "1. **Data Acquisition** - Download historical price data\n",
    "2. **Volatility Estimation** - Calculate historical volatility using multiple estimators\n",
    "3. **Volatility Clustering** - Group assets by volatility characteristics\n",
    "4. **Granger Causality Testing** - Identify predictive relationships\n",
    "5. **Signal Generation** - Generate trading signals based on trends\n",
    "6. **Backtesting** - Evaluate strategy performance\n",
    "\n",
    "Run each cell sequentially to execute the complete strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f10318",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8abcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import yaml\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Execution started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import strategy modules\n",
    "from volatility_estimators import VolatilityEstimator, calculate_volatility_for_assets\n",
    "from volatility_clustering import VolatilityClustering, cluster_assets_by_volatility\n",
    "from granger_causality import GrangerCausalityAnalyzer, identify_trading_pairs\n",
    "from signal_generator import SignalGenerator, SignalAnalyzer\n",
    "from backtester import VoltBacktester\n",
    "\n",
    "print(\"Strategy modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5807f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Assets: {config['data']['assets']}\")\n",
    "print(f\"Data period: {config['data']['start_date']} to {config['data']['end_date']}\")\n",
    "print(f\"Volatility estimator: {config['volatility']['primary_estimator']}\")\n",
    "print(f\"Rolling window: {config['volatility']['rolling_window']} days\")\n",
    "print(f\"Target cluster: Mid-volatility\")\n",
    "print(f\"Optimal lag: {config['granger']['optimal_lag']} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eb5467",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition\n",
    "\n",
    "Download historical OHLC price data for all assets in our universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c300659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 1: DATA ACQUISITION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tickers = config['data']['assets']\n",
    "start_date = config['data']['start_date']\n",
    "end_date = config['data']['end_date']\n",
    "\n",
    "print(f\"\\nDownloading data for {len(tickers)} tickers...\")\n",
    "print(f\"Period: {start_date} to {end_date}\\n\")\n",
    "\n",
    "data_dict = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        if len(df) > 0:\n",
    "            # Fix MultiIndex columns issue (yfinance returns columns like ('Close', 'MSFT'))\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            \n",
    "            data_dict[ticker] = df\n",
    "            print(f\"  {ticker}: {len(df)} days\")\n",
    "        else:\n",
    "            print(f\"  {ticker}: No data available\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {ticker}: Error - {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully downloaded data for {len(data_dict)} assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5494b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualization of price data\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Use a distinct color palette with enough colors\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(data_dict)))\n",
    "\n",
    "for idx, (ticker, df) in enumerate(data_dict.items()):\n",
    "    # Normalize to 100 for comparison\n",
    "    normalized = (df['Close'] / df['Close'].iloc[0]) * 100\n",
    "    ax.plot(normalized.index, normalized.values, label=ticker, \n",
    "            color=colors[idx], alpha=0.85, linewidth=2)\n",
    "\n",
    "ax.set_title('Normalized Price Evolution (Base = 100)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Normalized Price')\n",
    "ax.legend(loc='best', ncol=3, frameon=True, fancybox=True, shadow=True)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nData date range: {list(data_dict.values())[0].index[0]} to {list(data_dict.values())[0].index[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5fc83",
   "metadata": {},
   "source": [
    "## Step 2: Historical Volatility Estimation\n",
    "\n",
    "Calculate historical volatility using the Yang-Zhang estimator (robust to opening jumps and drift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 2: VOLATILITY ESTIMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "vol_config = config['volatility']\n",
    "print(f\"\\nUsing {vol_config['primary_estimator']} estimator\")\n",
    "print(f\"Rolling window: {vol_config['rolling_window']} days\")\n",
    "print(f\"Annualization factor: {vol_config['annualization_factor']}\\n\")\n",
    "\n",
    "# Calculate volatility for all assets\n",
    "volatility_df = calculate_volatility_for_assets(\n",
    "    data_dict,\n",
    "    estimator=vol_config['primary_estimator'],\n",
    "    rolling_window=vol_config['rolling_window'],\n",
    "    annualization_factor=vol_config['annualization_factor']\n",
    ")\n",
    "\n",
    "# Remove NaN values\n",
    "volatility_df = volatility_df.dropna()\n",
    "\n",
    "print(f\"Volatility calculated for period: {volatility_df.index[0]} to {volatility_df.index[-1]}\")\n",
    "print(f\"Data points: {len(volatility_df)}\")\n",
    "print(\"\\nMean volatility by asset:\")\n",
    "mean_vols = volatility_df.mean().sort_values(ascending=False)\n",
    "for ticker, vol in mean_vols.items():\n",
    "    print(f\"  {ticker}: {vol:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9130e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize volatility time series\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (ticker, vol_series) in enumerate(volatility_df.items()):\n",
    "    if idx < len(axes):\n",
    "        axes[idx].plot(vol_series.index, vol_series.values, linewidth=1.5)\n",
    "        axes[idx].set_title(f'{ticker} - Mean: {vol_series.mean():.2%}', fontweight='bold')\n",
    "        axes[idx].set_ylabel('Volatility')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        axes[idx].axhline(y=vol_series.mean(), color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.suptitle('Historical Volatility Time Series', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17611e6",
   "metadata": {},
   "source": [
    "## Step 3: Volatility Clustering\n",
    "\n",
    "Use K-means++ to cluster assets into low, mid, and high volatility groups.\n",
    "\n",
    "We focus on the **mid-volatility cluster** as it represents the optimal balance between risk and profit potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf874e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 3: VOLATILITY CLUSTERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_config = config['clustering']\n",
    "print(f\"\\nNumber of clusters: {cluster_config['n_clusters']}\")\n",
    "print(f\"Target cluster: Mid-volatility (cluster {cluster_config['target_cluster']})\\n\")\n",
    "\n",
    "# Perform clustering\n",
    "clustering, mid_cluster_members = cluster_assets_by_volatility(\n",
    "    volatility_df,\n",
    "    n_clusters=cluster_config['n_clusters'],\n",
    "    random_state=cluster_config['random_state'],\n",
    "    target_cluster='mid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d6f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results\n",
    "clustering.plot_clusters(volatility_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time series by cluster\n",
    "clustering.plot_time_series_by_cluster(volatility_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3155cb",
   "metadata": {},
   "source": [
    "## Step 4: Granger Causality Analysis\n",
    "\n",
    "Test for predictive relationships between volatility time series in the mid-cluster.\n",
    "\n",
    "If Stock A's volatility **Granger-causes** Stock B's volatility (A â†’ B), then past values of A's volatility help predict B's volatility beyond B's own past values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1382e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STEP 4: GRANGER CAUSALITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "granger_config = config['granger']\n",
    "print(f\"\\nTesting lags: {granger_config['min_lag']} to {granger_config['max_lag']}\")\n",
    "print(f\"Optimal lag: {granger_config['optimal_lag']}\")\n",
    "print(f\"Significance level: {granger_config['alpha']}\")\n",
    "print(f\"\\nTesting {len(mid_cluster_members)} assets in mid-cluster...\\n\")\n",
    "\n",
    "# Identify trading pairs\n",
    "trading_pairs, analyzer = identify_trading_pairs(\n",
    "    volatility_df,\n",
    "    mid_cluster_members,\n",
    "    target_lag=granger_config['optimal_lag'],\n",
    "    significance_level=granger_config['alpha'],\n",
    "    max_lag=granger_config['max_lag'],\n",
    "    remove_circular=True\n",
    ")\n",
    "\n",
    "if len(trading_pairs) == 0:\n",
    "    print(\"\\nWARNING: No significant Granger causality relationships found!\")\n",
    "    print(\"Consider:\")\n",
    "    print(\"  - Adjusting the significance level\")\n",
    "    print(\"  - Testing different lag ranges\")\n",
    "    print(\"  - Using a longer historical period\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(trading_pairs)} trading pairs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525962e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize causality network\n",
    "if len(trading_pairs) > 0:\n",
    "    analyzer.plot_causality_network(trading_pairs, figsize=(14, 10))\n",
    "else:\n",
    "    print(\"No trading pairs to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display trading pairs details\n",
    "if len(trading_pairs) > 0:\n",
    "    print(\"\\nTrading Pairs Details:\")\n",
    "    print(\"=\"*80)\n",
    "    display(trading_pairs)\n",
    "    \n",
    "    print(\"\\nInterpretation:\")\n",
    "    for _, row in trading_pairs.iterrows():\n",
    "        print(f\"\\n{row['predictor']} -> {row['target']}:\")\n",
    "        print(f\"  When {row['predictor']}'s volatility trends UP, BUY {row['target']}\")\n",
    "        print(f\"  When {row['predictor']}'s volatility trends DOWN, SELL {row['target']}\")\n",
    "        print(f\"  Optimal lag: {row['optimal_lag']} days\")\n",
    "        print(f\"  P-value: {row['p_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2c0fd",
   "metadata": {},
   "source": [
    "## Step 5: Signal Generation\n",
    "\n",
    "Generate trading signals using trend-following on the predictor stock's volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec39348",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trading_pairs) == 0:\n",
    "    print(\"Cannot generate signals without trading pairs.\")\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(\"STEP 5: SIGNAL GENERATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strategy_config = config['strategy']\n",
    "    print(f\"\\nStrategy type: {strategy_config['type']}\")\n",
    "    print(f\"Trend method: {strategy_config['trend_method']}\")\n",
    "    print(f\"Trend parameters: {strategy_config['trend_params']}\\n\")\n",
    "    \n",
    "    # Initialize signal generator\n",
    "    signal_gen = SignalGenerator(\n",
    "        trend_method=strategy_config['trend_method'],\n",
    "        trend_params=strategy_config['trend_params']\n",
    "    )\n",
    "    \n",
    "    # Generate signals for all pairs\n",
    "    signals = signal_gen.generate_signals_for_all_pairs(volatility_df, trading_pairs)\n",
    "    \n",
    "    # Analyze signals\n",
    "    stats = SignalAnalyzer.get_signal_statistics(signals)\n",
    "    print(\"Signal Statistics:\")\n",
    "    display(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signals for each pair\n",
    "if len(trading_pairs) > 0:\n",
    "    for pair_name, signals_df in signals.items():\n",
    "        print(f\"\\nPlotting signals for {pair_name}...\")\n",
    "        \n",
    "        target_ticker = pair_name.split('->')[1]\n",
    "        target_price = data_dict[target_ticker]['Close']\n",
    "        \n",
    "        SignalAnalyzer.plot_signals(\n",
    "            signals_df,\n",
    "            price_data=target_price,\n",
    "            title=pair_name\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a67c4d",
   "metadata": {},
   "source": [
    "## Step 6: Backtesting\n",
    "\n",
    "Evaluate strategy performance with realistic transaction costs and position sizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trading_pairs) == 0:\n",
    "    print(\"Cannot run backtest without trading pairs.\")\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(\"STEP 6: BACKTESTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    backtest_config = config['backtest']\n",
    "    strategy_config = config['strategy']\n",
    "    \n",
    "    print(f\"\\nBacktest period: {backtest_config['start_date']} to {backtest_config['end_date']}\")\n",
    "    print(f\"Initial capital per pair: ${strategy_config['initial_capital']}\")\n",
    "    print(f\"Total capital: ${strategy_config['initial_capital'] * len(trading_pairs)}\")\n",
    "    print(f\"Commission: ${strategy_config['commission']} per trade\")\n",
    "    print(f\"Slippage: {strategy_config['slippage']:.2%}\\n\")\n",
    "    \n",
    "    # Initialize backtester\n",
    "    backtester = VoltBacktester(\n",
    "        initial_capital_per_pair=strategy_config['initial_capital'],\n",
    "        commission=strategy_config['commission'],\n",
    "        slippage=strategy_config['slippage'],\n",
    "        position_size_pct=strategy_config['position_size_pct']\n",
    "    )\n",
    "    \n",
    "    # Run backtest\n",
    "    results = backtester.run_backtest(\n",
    "        data_dict,\n",
    "        signals,\n",
    "        start_date=pd.Timestamp(backtest_config['start_date']),\n",
    "        end_date=pd.Timestamp(backtest_config['end_date'])\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBacktest completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87523a",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed results\n",
    "if len(trading_pairs) > 0:\n",
    "    backtester.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "if len(trading_pairs) > 0:\n",
    "    backtester.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1129d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance summary DataFrame\n",
    "if len(trading_pairs) > 0:\n",
    "    agg_metrics = results['aggregated']['metrics']\n",
    "    \n",
    "    summary_df = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Total Return ($)',\n",
    "            'Total Return (%)',\n",
    "            'Number of Trades',\n",
    "            'Win Rate (%)',\n",
    "            'Profit Factor',\n",
    "            'Max Drawdown (%)',\n",
    "            'Sharpe Ratio',\n",
    "            'Sortino Ratio',\n",
    "            'Calmar Ratio'\n",
    "        ],\n",
    "        'Value': [\n",
    "            f\"${agg_metrics['total_return']:.2f}\",\n",
    "            f\"{agg_metrics['total_return_pct']:.2f}%\",\n",
    "            agg_metrics['n_trades'],\n",
    "            f\"{agg_metrics['win_rate']:.2f}%\",\n",
    "            f\"{agg_metrics['profit_factor']:.2f}\",\n",
    "            f\"{agg_metrics['max_drawdown']:.2f}%\",\n",
    "            f\"{agg_metrics['sharpe_ratio']:.2f}\",\n",
    "            f\"{agg_metrics['sortino_ratio']:.2f}\",\n",
    "            f\"{agg_metrics['calmar_ratio']:.2f}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nPerformance Summary:\")\n",
    "    print(\"=\"*80)\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-pair performance comparison\n",
    "if len(trading_pairs) > 0:\n",
    "    pair_metrics_list = []\n",
    "    for pair_name, result in results['pair_results'].items():\n",
    "        metrics = result['metrics']\n",
    "        pair_metrics_list.append({\n",
    "            'Pair': pair_name,\n",
    "            'Return ($)': f\"${metrics['total_return']:.2f}\",\n",
    "            'Return (%)': f\"{metrics['total_return_pct']:.2f}%\",\n",
    "            'Trades': metrics['n_trades'],\n",
    "            'Win Rate': f\"{metrics['win_rate']:.1f}%\",\n",
    "            'Max DD (%)': f\"{metrics['max_drawdown']:.2f}%\",\n",
    "            'Sharpe': f\"{metrics['sharpe_ratio']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    pair_comparison_df = pd.DataFrame(pair_metrics_list)\n",
    "    print(\"\\nPer-Pair Performance:\")\n",
    "    print(\"=\"*80)\n",
    "    display(pair_comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dec7f6",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV files\n",
    "if len(trading_pairs) > 0:\n",
    "    output_dir = Path(config['output']['results_dir'])\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save trading pairs\n",
    "    trading_pairs.to_csv(output_dir / 'trading_pairs.csv', index=False)\n",
    "    print(f\"Trading pairs saved to {output_dir / 'trading_pairs.csv'}\")\n",
    "    \n",
    "    # Save aggregated metrics\n",
    "    summary_df.to_csv(output_dir / 'performance_summary.csv', index=False)\n",
    "    print(f\"Performance summary saved to {output_dir / 'performance_summary.csv'}\")\n",
    "    \n",
    "    # Save per-pair metrics\n",
    "    pair_comparison_df.to_csv(output_dir / 'pair_comparison.csv', index=False)\n",
    "    print(f\"Pair comparison saved to {output_dir / 'pair_comparison.csv'}\")\n",
    "    \n",
    "    # Save equity curve\n",
    "    equity_df = pd.DataFrame({\n",
    "        'date': results['aggregated']['dates'],\n",
    "        'equity': results['aggregated']['equity_curve']\n",
    "    })\n",
    "    equity_df.to_csv(output_dir / 'equity_curve.csv', index=False)\n",
    "    print(f\"Equity curve saved to {output_dir / 'equity_curve.csv'}\")\n",
    "    \n",
    "    print(f\"\\nAll results saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
